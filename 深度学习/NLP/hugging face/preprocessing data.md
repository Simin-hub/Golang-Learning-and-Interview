# Preprocessing data

# 1.Tokenizer

Tokenizer（分类器）切分文本为一个个单词———分词。