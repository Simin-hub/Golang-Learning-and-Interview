# 项目排错

[参考]( https://debug-lixiwen.github.io/2021/07/18/shi-zhan/)

## 一、性能分析

### 1.1 性能分析

> 在软件工程中，性能分析（Performance Analysis，也称为Profiling），**是以收集程序运行时信息为手段研究程序行为的分析方法，是一种动态程序分析方法**
>
> –维基百科

在日常开发中，性能优化往往是一个长期的事情，在业务的不同阶段，会遇到各种各样的性能问题，迅速分析并定位程序的性能瓶颈，能让我们付出最小的努力，得到最大的回报。

### 1.2 代码开发上线步骤

1. 上线前

   a. 压测：我们通过压测可以获知系统的性能，例如每秒能处理的请求数，平均响应时间，错误率等指标。这样，我们对自己服务的性能算是有个底。

   b. 问题：但是压测是线下的模拟流量，如果到了线上呢？会遇到高并发、大流量，不靠谱的上下游，突发的尖峰流量等等场景，这些都是不可预知的。

2. 上线后

   1. 线上突然大量报警，接口超时，错误数增加
   2. 终极解决方案：`看日志`、`看监控`；`使用性能分析工具`分析程序的性能，找到瓶颈
   3. 临时解决方案：首先要`降级、限流、回滚`，先止损

3. 总结

   1. 性能分析很重要，尤其是要统计好性能数据，出问题了，可以随时拿出来看。

根据上面内容引出了性能分析，性能分析主要关注 `CPU、内存、磁盘 IO、网络`这些指标。

在软件工程中，性能分析（performance analysis，也称为 profiling），是以收集程序运行时信息为手段研究程序行为的分析方法，是一种动态程序分析的方法。

`profiling` 是指在程序执行过程中，收集能够反映程序执行状态的数据。

一般常规分析内容：

1. **cpu**：程序对cpu的使用情况 - 使用时长，占比等
2. **内存**：程序对cpu的使用情况 - 使用时长，占比，内存泄露等。如果在往里分，程序堆、栈使用情况
3. **I/O**：IO的使用情况 - 哪个程序IO占用时间比较长

golang 程序中分析内容：

1. **goroutine**：go的协程使用情况，调用链的情况
2. **goroutine leak**：goroutine泄露检查
3. **go dead lock**：死锁的检测分析
4. **data race detector**：数据竞争分析，其实也与死锁分析有关

### 1.3 golang 性能调试优化方法

比如 linux 中 cpu 性能调试，工具有 top，dstat，perf 等。

那么在 golang 中，有哪些分析方法？

**golang 性能调试优化方法：**

- **Benchmark**：**基准测试**，对特定代码的运行时间和内存信息等进行测试
- **Profiling**：**程序分析**，程序的运行画像，在程序执行期间，通过采样收集的数据对程序进行分析
- **Trace**：**跟踪**，在程序执行期间，通过采集发生的事件数据对程序进行分析

> profiling 和 trace 有啥区别？
>
> profiling 分析没有时间线，trace 分析有时间线。

在 golang 中，`应用方法的工具`呢？

这里介绍 pprof 这个 golang 工具，它可以帮助我们调试优化程序。

> 它的最原始程序是 [gperftools](https://github.com/gperftools/gperftools) - https://github.com/gperftools/gperftools，golang 的 pprof 是从它而来的。

## pprof

[参考](https://debug-lixiwen.github.io/2021/07/18/shi-zhan/)、[具体用法](https://github.com/Simin-hub/Learning-Programming/blob/main/Go/%E6%A0%87%E5%87%86%E5%BA%93/pprof.md#pprof)

在 Go 语言中，pprof 是用于可视化和分析性能分析数据的工具，pprof 以 profile.proto 读取分析样本的集合，并生成报告以可视化并帮助分析数据（支持文本和图形报告）。

而刚刚提到的 profile.proto 是一个 Protobuf v3 的描述文件，它描述了一组 callstack 和 symbolization 信息， 作用是统计分析的一组采样的调用栈，是很常见的 stacktrace 配置文件格式。

> **一句话描述**：Golang**自带**的一款开箱即用的**性能监控**和**分析**工具。

### pprof 作用

go的pprof提供了2个工具供我们使用，runtime/pprof中是它的源码，net/http/pprof对源码做了简单封装，能让你在http服务中直接使用。

它可以**采样程序运行时的CPU、堆内存、Goroutine、锁竞争、阻塞调用、系统线程的使用情况**。然后通过可视化终端或网页的形式展示给用户，用户可以**通过列表、调用图、源码、火焰图、反汇编等视图去展示采集到的性能指标**



![pprof 作用](https://cdn.jsdelivr.net/gh/debug-LiXiwen/blog_pics/img/image-20211128132832839.png)

### pprof指标采样的维度

1. **CPU（profile）**
   1. CPU Profiling：CPU 分析，按照一定的频率采集所监听的应用程序 CPU（含寄存器）的使用情况，可确定应用程序在主动消耗 CPU 周期时花费时间的位置。
   2. 报告CPU的使用情况，定位到热点（消耗CPU周期最多的）代码。默认情况下Go以100HZ的频率进行CPU采样
2. **Goroutine**
   1. Goroutine Profiling： Goroutine 分析，可以对当前应用程序正在运行的 Goroutine 进行堆栈跟踪和分析。这项功能在实际排查中会经常用到，因为很多问题出现时的表象就是 Goroutine 暴增，而这时候我们要做的事情之一就是查看应用程序中的 Goroutine 正在做什么事情，因为什么阻塞了，然后再进行下一步。
3. **系统线程**
   1. 获取导致创建 OS 线程的 goroutine 堆栈
4. **堆内存/内存剖析（heap）**
   1. Memory Profiling：内存分析，在应用程序进行堆分配时记录堆栈跟踪，用于监视当前和历史内存使用情况，以及检查内存泄漏。
   2. 包含每个 goroutine 分配大小，分配堆栈等。
   3. 每分配 runtime.MemProfileRate(默认为512K) 个字节进行一次数据采样。
5. **内存剖析（allocs）**：报告所有内存分配历史
6. **阻塞操作**
   1. Block Profiling：阻塞分析，记录 Goroutine 阻塞等待同步（包括定时器通道）的位置，默认不开启，需要调用 `runtime.SetBlockProfileRate` 进行设置。
   2. 获取导致阻塞的 goroutine 堆栈(如 channel, mutex 等)，使用前需要先调用 `runtime.SetBlockProfileRate`
7. **锁竞争**
   1. Mutex Profiling：互斥锁分析，报告互斥锁的竞争情况，默认不开启，需要调用 `runtime.SetMutexProfileFraction` 进行设置。
8. **执行追踪（trace）：**追踪当前应用程序的执行栈

### 原理

#### CPU采样

CPU采样会记录所有的调用栈和它们的占用时间。

在采样时，进程会每秒暂停一百次，每次会记录当前的调用栈信息。

汇总之后，根据调用栈在采样中出现的次数来推断函数的运行时间。 你需要手动地启动和停止采样。每秒100次的暂停频率也不能更改。

这个定时暂停机制在unix或类unix系统上是依赖信号机制实现的。

每次「暂停」都会接收到一个信号，通过系统计时器来保证这个信号是固定频率发送的。 接下来看看具体的流程。

一共有三个相关角色：进程本身、操作系统和写缓冲。

启动采样时，进程向OS注册一个定时器，OS会每隔10ms向进程发送一个SIGPROF信号，进程接收到信号后就会对当前的调用栈进行记录。

与此同时，进程会启动一个写缓冲的goroutine，它会每隔100ms从进程中读取已经记录的堆栈信息，并写入到输出流。

当采样停止时，进程向OS取消定时器，不再接收信号，写缓冲读取不到新的堆栈时，结束输出。

采样对象：函数调用和它们的占用时间

采样率：100次/秒

固定值采样时间：从手动启动到手动结束

- 操作系统：每10ms向进程发送一次SIGPROF信号
- 进程：每次接收到SIGPROF会记录调用栈
- 写缓冲：每100ms读取一次已经记录的调用栈并写入输出流

![image-20210801222450112](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/image-20210801222450112.png)

**image-20210801222450112**

![image-20210801222823463](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/image-20210801222823463.png)

#### Goroutine & ThreadCreate采样

接下来我们来看看goroutine和系统线程的采样。这两个采样指标在概念上和实现上都比较相似，所以在这里进行对比。

Goroutine采样会记录所有用户发起，也就是入口不是runtime开头的goroutine，以及main函数所在goroutine的信息和创建这些goroutine的调用栈；

ThreadCreate采样会记录由程序创建的所有系统线程的信息和调用栈。

他们在实现上非常的相似，都是会在STW之后，遍历所有goroutine/所有线程的列表（图中的m就是GMP模型中的m，在golang中和线程一一对应），并输出堆栈，最后Start The World继续运行。

这个采样是立刻触发的全量记录，你可以通过比较两个时间点的差值来得到某一时间段的指标。

Goroutine：记录所有用户发起且在运行中的goroutine（即入口非runtime开头的）和runtime.main的调用栈信息

ThreadCreate：记录程序创建的所有系统线程的信息

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/goroutine%2526tc.png)

#### Heap（堆内存）采样

接下来看看堆内存采样。 我在提到内存指标的时候说的都是「堆内存」而不是「内存」，这是因为pprof的内存采样是有局限性的。

内存采样在实现上依赖了内存分配器的记录，所以它只能记录在堆上分配，且会参与GC的内存，一些其他的内存分配，例如调用结束就会回收的栈内存、一些更底层使用cgo调用分配的内存，是不会被内存采样记录的。

它的采样率是一个大小，默认每分配512KB内存会采样一次，采样率是可以在运行开头调整的，设为1则为每次分配都会记录。

与CPU和goroutine都不同的是，内存的采样是一个持续的过程，它会记录从程序运行起的所有分配或释放的内存大小和对象数量，并在采样时遍历这些结果进行汇总。

还记得刚才的例子中，堆内存采样的四种指标吗？alloc的两项指标是从程序运行开始的累计指标，而inuse的两项指标是通过累计分配减去累计释放得到的程序当前持有的指标。

你也可以通过比较两次alloc的差值来得到某一段时间程序分配的内存【大小和数量】

采样程序通过内存分配器在`堆上`分配和释放的内存，记录分配/释放的`大小和数量`

采样率：每分配512KB记录一次，可在运行开头修改，1为每次分配均记录

采样时间：从程序运行开始到采样时

采样指标：alloc_space, alloc_objects, inuse_space, inuse_objects

计算方式：inuse=alloc-free

#### Block(阻塞) & Mutex(锁竞争)采样

讲完了堆内存，还剩下阻塞和锁竞争这两种采样。 这两个指标在流程和原理上也非常相似，我在这里也做了一个对比。

这两个采样记录的都是对应操作发生的调用栈、次数和耗时，不过这两个指标的采样率含义并不相同。

阻塞操作的采样率是一个「阈值」，消耗超过阈值时间的阻塞操作才会被记录，1为每次操作都会记录。

锁竞争的采样率是一个「比例」，运行时会通过随机数来只记录固定比例的锁操作，1为每次操作都会记录。

它们在实现上也是基本相同的。都是一个「主动上报」的过程。

在阻塞操作或锁操作发生时，会计算出消耗的时间，连同调用栈一起主动上报给采样器，采样器会根据采样率可能会丢弃一些记录。

在采样时，采样器会遍历已经记录的信息，统计出具体操作的次数、调用栈和总耗时。和堆内存一样，你可以对比两个时间点的差值计算出段时间内的操作指标。

阻塞操作

采样阻塞操作的次数和耗时

采样率：阻塞耗时超过阈值的才会被记录，1为每次阻塞均记录

锁竞争

采样争抢锁的次数和耗时

采样率：只记录固定比例的锁操作，1为每次加锁均记录



![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/image-20210801224628156.png)

## trace

[参考](https://github.com/Simin-hub/Learning-Programming/blob/main/Go/%E6%A0%87%E5%87%86%E5%BA%93/trace.md#trace)

**trace 和 pprof 的区别在于两者关注的维度不同，后者更关注代码栈层面，而 trace 更关注于 latency（延迟）**。

比如说一个请求在客户端观察从发送到完成经过了 5s，做 profile 可能发现这个请求的 CPU 时间只有 2s，那剩下的 3s 就不是很清楚了， profile 更侧重的是我们代码执行了多久，至于其他的，例如：网络 IO，系统调用，Goroutine 调度，GC 时间等，很难反映出来。这是就应该使用 trace 了。

## GODEBUG

[参考](https://golang2.eddycjy.com/posts/ch6/04-godebug-sched/)

让 Go 更强大的原因之一莫过于它的 GODEBUG 工具，GODEBUG 的设置可以让 Go 程序在运行时输出调试信息，可以根据你的要求很直观的**看到你想要的调度器或垃圾回收**等详细信息，并且还不需要加装其它的插件，非常方便

## gops

[参考](https://golang2.eddycjy.com/posts/ch6/06-gops/)

在类 Unix 系统中，我们常常会使用 ps 命令来查看系统当前所运行的进程信息，该命令为我们提供了较大的帮助，能够快速的定位到某些进程的运行情况和状态。

而在 Go 语言中，也有类似的命令工具，那就是 [gops](https://github.com/google/gops) （Go Process Status），gops 是由 Google 官方出品的一个命令行工具，与 ps 命令的功能类似，**能够查看并诊断当前系统中 Go 程序的运行状态及内部情况**，在一些使用场景中具有较大的存在意义，属于常用工具，因此在本章节中我们将对 gops 进行全面的使用和介绍。

## 公开和发布度量指标

[参考](https://golang2.eddycjy.com/posts/ch6/07-metrics/)

为了确定我们当前正在运行的 Go 程序其性能情况如何，我们常常需要借助各种手段去进行收集和查看指标，而这些指标我们常常称其为度量（Metrics）指标，这些指标能够更好的帮助我们确定应用程序中的问题区域和瓶颈在哪里，并且能够借助一些开源组件来绘制监控图表，非常的方便。

度量指标一般可以分为以下几种类别：

- 与网络带宽使用率有关的指标。
- 与处理器，内存，磁盘 I/O 和网络 I/O 相关的指标。
- 与应用各类执行时间有关的指标。
- 与应用的各类自定义指标有关。

### 通过 Expvar

### 通过 Prometheus

参考

## 逃逸分析

[参考](https://golang2.eddycjy.com/posts/ch6/08-stack-heap/)