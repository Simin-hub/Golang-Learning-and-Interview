# 项目相关问题

## 业务相关

### 禁止多次投票

三种方法：

1. 投票后把对方IP记住，然后再投的时候就去查询一下，如果有他的记录就提示不能投了。（即用数据库进行记录，提高效率，可以使用组合索引）
2. 使用Session，每个用户在登陆的时候都有一个SessID,对方投票后，给他一个新的session变量，证明他投票过了，那么下次投就不行了。
3. 使用cookie，对方投票后，就写入他电脑的cookie，程序去读取判断他投票没有

弊端：

1. 要频繁读去数据库，可能有时候存在不合理性。 但这个方法最合理
2. 对方关掉IE后重开一次再投，还能投，所以不是特别完善。
3. 清空Cookie后又能投

### 重复登录验证

登录的时候request会带一个sessionId过去，这是每个单独的访问特有的（我理解的是每个浏览器相当于单独的会话，如果你在这个浏览器登录了，再开别的标签页系统也是会认为你已经登录过了，原因是sessionid是一致的），那么我们需要保存sessionid和当前登录的用户信息就可以实现了。

大体的思路是这样的：

1. 在登录的接口中，用当前登录的userid去获取缓存中的sessionId，如果和当前访问的sessionId一致，那么放行。如果不一致，删除原缓存中的sessionId，换上新的sessionId。
2. 在登录拦截器中，获取用户信息，（如果获取不到，跳转到登录页，这个是常规操作）通过用户信息(userid) 在缓存中获得sessionId，比较获取的sessionId和本次拦截的sessionId，如果不一致，拦截请求，提示用户账号被顶替了。
3. 提示页跳转至登录页面（过一遍后台走一步登出流程）

### 实现单点登录

实现单点登录的思路很简单，就是**一个账号对应的token同一时间只有一个生效**，也就是说每次用户登录除了生成一个token保存起来，还要删除掉之前的token。

1. 用户登录，服务器生成token保存至 `redis` (设置有效时间)，并将token返回给前端，用户之后的每次请求需要携带token。
2. 在拦截器中校验请求头中的token，判断token是否有效，每一次有效的请求都刷新token的有效时间。
3. 同一个账号再次被登录时，删除之前的token，并生成新的token重复1操作。

步骤看起来都很简单，但有一个问题需要注意，每一次校验token是需要去`redis`中查询的，也就是说设置的key应该为token，value为`userId`(或者其它唯一标识)，那么这个时候如何在登录时做到删除当前的token呢？如果只是有一个token-id的对应关系好像确实没办法获取到该账号当前token，所以还需要一个id-token的对应关系，可以直接通过id拿到token。

### 评论回复功能

[参考](https://blog.csdn.net/ztchun/article/details/71106117)

#### 数据表设计

###### 1 一问一答模式

**(1)需求分析**

大部分APP采用简单的评论设计即可，即是一问一答模式，比如微信朋友圈的评论功能的设计。如：

```xml
A：今天天气真好！
B @ A :今天天气确实不错！12
```

这种设计简单、直接，也满足了用户评论、回复的基本要求，对于没有大量用户评论的APP需求足够。

**（2）数据库设计**
这种场景下一般评论较少，评论不活跃，可以不区分评论和回复，统一看成评论。区别是，有些评论是直接评论主题，而有些是@其他用户，使用一张表就可以达到效果，评论表设计如下：

| 表字段     | 字段说明       |
| ---------- | -------------- |
| id         | 主键           |
| topic_id   | 主题id         |
| topic_type | 主题类型       |
| content    | 评论内容       |
| from_uid   | 评论用户id     |
| to_uid     | 评论目标用户id |

topic_type：为了能复用评论模块，我们引入这个字段来区分主题的类别。

from_uid：表示评论人的id，通过该id我们可以检索到评论人的相关信息。

to_uid 是评论目标人的id，如果没有目标人，则该字段为空

出于性能的考虑，往往我们会冗余评人的相关信息到评论表中，比如评论人的nick、头像，目标用户也是如此。 这样一来我们就只用查询单表就可以达到显示的效果

有时，目标用户有多个，那么可以将to_uid字段修改为to_uids，保存时用分隔符来分割用户id，而目标用户的信息再去查询缓存或者数据库。也可以简单的将多个目标用户的信息一起存成json格式，可以应付简单的展现需求。

###### 2 评论为主模式

**(1)需求分析**

如果以评论为主的显示模式，类似于下面的CSDN的评论显示模式：
![这里写图片描述](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/20170503021558563)

这里将评论分为评论和回复，所有评论均挂在评论下面，类似于**树状结构**。

**（2）数据库设计**

在以评论为主的树形显示情况下，数据库的设计十分灵活，可以使用单表，添加一个parent_id字段来指向父评论，需要嵌套查询。

同时也可以**将评论拆分为评论表和回复表**，评论挂在各种主题下面，而回复挂在评论下面。

评论表设计如下：

| 表字段     | 字段说明   |
| ---------- | ---------- |
| id         | 主键       |
| topic_id   | 主题id     |
| topic_type | 主题类型   |
| content    | 评论内容   |
| from_uid   | 评论用户id |

回复表设计：

| 表字段     | 字段说明   |
| ---------- | ---------- |
| id         | 主键       |
| comment_id | 评论id     |
| reply_id   | 回复目标id |
| reply_type | 回复类型   |
| content    | 回复内容   |
| from_uid   | 回复用户id |
| to_uid     | 目标用户id |

由于我们拆分了评论和回复，那么评论表就不再需要目标用户字段了，因为评论均是用户对主题的评论，评论表的设计更佳简洁了。

回复表添加了一个comment_id字段来表示该回复挂在的**根评论id**，这样设计也是出于性能方面的考虑，我们可以直接通过评论id一次性的找出该评论下的所有回复，然后通过程序来编排回复的显示结构。 通过适当的冗余来提高性能也是常用的优化手段之一。

reply_type：表示回复的类型，因为回复可以是针对评论的回复(comment)，也可以是针对回复的回复(reply)， 通过这个字段来区分两种情景。

reply_id：表示回复目标的id，如果reply_type是comment的话，那么reply_id＝commit_id，如果reply_type是reply的话，这表示这条回复的父回复。

###### 3 网易新闻盖楼模式

**（1）需求分析**

这种场景中评论和回复是同级显示的，回复不在显示结构上不用挂在一个评论下面。 双表的设计在这里就不太合适了，因为涉及到评论和回复的混排，使用双表则会导致查询的逻辑过于复杂。 所以建议还是采用单表的设计，**不区分评论和回复会简化应用层的逻辑**。 我们统一都看成评论，而有些评论是可以引用其他评论的。

**（2）数据库设计**

本人推荐采用闭包表的设计，例如：

comment表设计：

| 表字段     | 字段说明   |
| ---------- | ---------- |
| id         | 主键       |
| topic_id   | 主题id     |
| topic_type | 主题类型   |
| content    | 评论内容   |
| from_uid   | 评论用户id |

parent_child表：

| 表字段    | 字段说明 |
| --------- | -------- |
| id        | 主键     |
| parent_id | 父id     |
| child_id  | 子id     |

comment表保存所有评论内容，而**parent_children表则记录评论表中各个评论的父子关系**。

查询时往往会按照时间排序，我们可以直接按id或者创建时间降序排列查询comment表即可。 如果用户想查询一条评论的完整引用，则可以通过parent_children来找到对应的路径。

闭包表在查询时非常方便，但是插入的性能稍差，因为除了插入评论表以外，还需要把该条评论所有的父子关系插入到父子关系表中。 插入性能会随着评论层级的加深而线性下降。

#### 数据库优化

如果你的系统每天都会拥有成千上万条评论，那么单表的设计肯定是不行，优化的方式有以下几种思路。

（1）**分库分表**。 分库分表是最为常用也最有效的优化方式，建议**按照主题来分库分表**。 这样同一个主题下面的评论就会落到同一张表里，避免了跨表查询。

（2）**适当的数据冗余**。 如果你需要显示评论人的相关信息，那么在插入评论时就把这些信息写入评论表中，避免多次查询。 实际上，如果是纪录数据，都可以冗余对应的数据信息，因为它们的数据的实时行和一致性要求并不高。

（3）**附加幂。数据只允许单项操作**。 因为从幂性的要求来说，每个赞全都是一条记录。 评论的赞数如果都从点赞表中统计得出，那么性能开销会十分巨大，而且点赞如此轻量级的一个操作一定会加剧点赞表的竞争操作。 所以建议直接在评论表中添加一个like_count的计数器，该字段只增不减。客户端，可以设置取消效果。

（4）**热门评论加缓存**。 类似于网易新闻的热门评论，读取频度非常高，可以专门开接口做缓存。

### 请求量这么高该如何优化

[参考](https://juejin.cn/post/7113730074595541023)

#### 本地缓存

当我们**遇到极端热点数据查询的时候，这个时候就要考虑本地缓存了**。热点本地缓存主要部署在应用服务器的代码中，用于阻挡热点查询对于Redis等分布式缓存或者数据库的压力。

### 如何处理每秒上万次的下单请求

[参考](https://juejin.cn/post/7114845947607121956)

#### 处理热点数据

秒杀的数据通常都是热点数据，处理热点数据一般有几种思路：一是优化，二是限制，三是隔离。

##### 优化

优化热点数据最有效的办法就是**缓存热点数据**，我们可以把热点数据缓存到内存缓存中。

##### 限制

限制更多的是一种保护机制，当秒杀开始后用户就会不断地刷新页面获取数据，这时候我们可以**限制单用户的请求次数**，比如一秒钟只能请求一次，超过限制直接返回错误，返回的错误尽量对用户友好，比如 "店小二正在忙" 等友好提示。

##### 隔离

秒杀系统设计的第一个原则就是**将这种热点数据隔离出来**，不要让1%的请求影响到另外的99%，隔离出来后也更方便对这1%的请求做针对性的优化。具体到实现上，我们需要做服务隔离，即秒杀功能独立为一个服务，通知要做数据隔离，秒杀所调用的大部分是热点数据，我们需要**使用单独的Redis集群和单独的Mysql**，目的也是不想让1%的数据有机会影响99%的数据。

#### 流量削峰

针对秒杀场景，它的特点是在秒杀开始那一刹那瞬间涌入大量的请求，这就会导致一个特别高的流量峰值。但最终能够抢到商品的人数是固定的，也就是不管是100人还是10000000人发起请求的结果都是一样的，并发度越高，无效的请求也就越多。但是从业务角度来说，秒杀活动是希望有更多的人来参与的，也就是秒杀开始的时候希望有更多的人来刷新页面，但是真正开始下单时，请求并不是越多越好。因此我们可以设计一些规则，让并发请求更多的延缓，甚至可以过滤掉一些无效的请求。

**削峰本质上是要更多的延缓用户请求的发出，以便减少和过滤掉一些无效的请求，它遵从请求数要尽量少的原则**。我们最容易想到的解决方案是用消息队列来缓冲瞬时的流量，把同步的直接调用转换成异步的间接推送，中间通过一个队列在一端承接瞬时的流量洪峰，在另一端平滑的将消息推送出去，如下图所示：

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/50232db2fd08447eaebf6b3067af3869~tplv-k3u1fbpfcp-zoom-in-crop-mark:3024:0:0:0.awebp)

采用消息队列异步处理后，那么秒杀的结果是不太好同步返回的，所以我们的思路是当用户发起秒杀请求后，同步返回响应用户 "秒杀结果正在计算中..." 的提示信息，当计算完之后我们如何返回结果给用户呢？其实也是有多种方案的。

- 一是**在页面中采用轮询的方式定时主动去服务端查询结果**，例如每秒请求一次服务端看看有没有处理结果，这种方式的缺点是服务端的请求数会增加不少。
- 二是**主动push的方式，这种就要求服务端和客户端保持长连接**了，服务端处理完请求后主动push给客户端，这种方式的缺点是服务端的连接数会比较多。

还有一个问题就是如果异步的请求失败了该怎么办？我觉得**对于秒杀场景来说，失败了就直接丢弃就好**了，最坏的结果就是这个用户没有抢到而已。如果想要尽量的保证公平的话，那么失败了以后也可以做重试。

#### 如何保证消息只被消费一次

**kafka是能够保证"At Least Once"的机制的，即消息不会丢失，但有可能会导致重复消费**，消息一旦被重复消费那么就会造成业务逻辑处理的错误，那么我们如何避免消息的重复消费呢？

我们只要保证即使消费到了重复的消息，从消费的最终结果来看和只消费一次的结果等同就好了，也就是保证在消息的生产和消费的过程是幂等的。什么是幂等呢？如果我们消费一条消息的时候，要给现有的库存数量减1，那么如果消费两条相同的消息就给库存的数量减2，这就不是幂等的。而如果消费一条消息后处理逻辑是将库存的数量设置为0，或者是如果当前库存的数量为10时则减1，这样在消费多条消息时所得到的结果就是相同的，这就是幂等的。说白了就是一件事无论你做多少次和做一次产生的结果都是一样的，那么这就是幂等性。

我们可以在消息被消费后，**把唯一id存储在数据库中，这里的唯一id可以使用用户id和商品id的组合**，在处理下一条消息之前先从数据库中查询这个id看是否被消费过，如果消费过就放弃。伪代码如下：

```go
isConsume := getByID(id)
if isConsume {
  return  
} 
process(message)
save(id)
```

还有一种方式是通过数据库中的唯一索引来保证幂等性，不过这个要看具体的业务，在这里不再赘述。

### 极致优化秒杀性能

[参考](https://juejin.cn/post/7116303230841126926)

#### 批量数据聚合

在**SeckillOrder**这个方法中，每来一次秒杀抢购请求都往往Kafka中发送一条消息。假如这个时候有一千万的用户同时来抢购，就算我们做了各种限流策略，一瞬间还是可能会有上百万的消息会发到Kafka，会产生大量的网络IO和磁盘IO成本，大家都知道Kafka是基于日志的消息系统，写消息虽然大多情况下都是顺序IO，但当海量的消息同时写入的时候还是可能会扛不住。

那怎么解决这个问题呢？答案是做**消息的聚合**。**之前发送一条消息就会产生一次网络IO和一次磁盘IO，我们做消息聚合后，比如聚合100条消息后再发送给Kafka，这个时候100条消息才会产生一次网络IO和磁盘IO，对整个Kafka的吞吐和性能是一个非常大的提升**。其实这就是一种小包聚合的思想，或者叫Batch或者批量的思想。这种思想也随处可见，比如我们使用Mysql插入批量数据的时候，可以通过一条SQL语句执行而不是循环的一条一条插入，还有Redis的Pipeline操作等等。

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/328a9518f3544f22aef1ea32085e5c2b~tplv-k3u1fbpfcp-zoom-in-crop-mark:3024:0:0:0.awebp)

那怎么来聚合呢，聚合策略是啥呢？**聚合策略有两个维度分别是聚合消息条数和聚合时间**，比如聚合消息达到100条我们就往Kafka发送一次，这个条数是可以配置的，那如果一直也达不到100条消息怎么办呢？通过聚合时间来兜底，这个聚合时间也是可以配置的，比如配置聚合时间为1秒钟，也就是无论目前聚合了多少条消息只要聚合时间达到1秒，那么就往Kafka发送一次数据。聚合条数和聚合时间是或的关系，也就是只要有一个条件满足就触发。

#### 降低消息的消费延迟

通过批量消息处理的思想，我们提供了Batcher工具，提升了性能，但这主要是针对生产端而言的。当我们消费到批量的数据后，还是需要串行的一条条的处理数据，那有没有办法能加速消费从而降低消费消息的延迟呢？有两种方案分别是：

- **增加消费者的数量**
- **在一个消费者中增加消息处理的并行度**

因为在Kafka中，一个Topci可以配置多个Partition，数据会被平均或者按照生产者指定的方式写入到多个分区中，那么在消费的时候，Kafka约定一个分区只能被一个消费者消费，为什么要这么设计呢？我理解的是如果有多个Consumer同时消费一个分区的数据，那么在操作这个消费进度的时候就需要加锁，对性能影响比较大。所以说当消费者数量小于分区数量的时候，我们可以增加消费者的数量来增加消息处理能力，但当消费者数量大于分区的时候再继续增加消费者数量就没有意义了。

![img](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/9a9023773ad74840a35b45b66522c83b~tplv-k3u1fbpfcp-zoom-in-crop-mark:3024:0:0:0.awebp)

不能增加Consumer的时候，可以在同一个Consumer中提升处理消息的并行度，即通过多个goroutine来并行的消费数据，我们一起来看看如何通过多个goroutine来消费消息。

#### 怎么保证不会超卖

当秒杀活动开始后，大量用户点击商品详情页上的秒杀按钮，会产生大量的并发请求查询库存，一旦某个请求查询到有库存，紧接着系统就会进行库存的扣减。然后，系统生成实际的订单，并进行后续的处理。如果请求查不到库存，就会返回，用户通常会继续点击秒杀按钮，继续查询库存。简单来说，这**个阶段的操作就是三个：检查库存，库存扣减、和订单处**理。因为**每个秒杀请求都会查询库存**，而请求只有查到库存有余量后，后续的库存扣减和订单处理才会被执行，所以，这个阶段中**最大的并发压力都在库存检查操作**上。

为了支撑大量高并发的库存检查请求，我们需要使用Redis单独保存库存量。那么，库存扣减和订单处理是否都可以交给Mysql来处理呢？其实，订单的处理是可以在数据库中执行的，但库存扣减操作不能交给Mysql直接处理。因为到了实际的订单处理环节，请求的压力已经不大了，数据库完全可以支撑这些订单处理请求。那为什么库存扣减不能直接在数据库中执行呢？这是因为，一旦请求查到有库存，就意味着该请求获得购买资格，紧接着就会进行下单操作，同时库存量会减一，这个时候如果直接操作数据库来扣减库存可能就会导致超卖问题。

直接操作数据库扣减库存为什么会导致超卖呢？由于**数据库的处理速度较慢，不能及时更新库存余量，这就会导致大量的查询库存的请求读取到旧的库存值，并进行下单**，此时就会出现下单数量大于实际的库存量，导致超卖。所以，就需要**直接在Redis中进行库存扣减**，具体的操作是，当库存检查完后，一旦库存有余量，我们就立即在Redis中扣减库存，同时，为了避免请求查询到旧的库存值，**库存检查和库存扣减这两个操作需要保证原子性**。