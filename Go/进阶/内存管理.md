# 内存管理

## 概念

[参考2](https://draveness.me/golang/docs/part3-runtime/ch07-memory/golang-memory-allocator/)

[参考](https://segmentfault.com/a/1190000020338427)

Golang 程序在启动时，会向操作系统申请一定区域的内存，分为栈（Stack）和堆（Heap），栈内存会随着函数的调用分配和回收；堆内存由程序申请分配，由垃圾回收器（Garbage Collector）负责回收。

程序中的**数据和变量都会被分配到程序所在的虚拟内存**中，内存空间包含两个重要区域：**栈区（Stack）和堆区（Heap）**。**函数调用的参数、返回值以及局部变量**大都会被分配到栈上，**这部分内存会由编译器进行管理**；不同编程语言使用不同的方法管理堆区的内存，C++ 等编程语言会由工程师主动申请和释放内存，Go 以及 Java 等编程语言会由工程师和编译器共同管理，**堆中的对象由内存分配器分配并由垃圾收集器回收**。

内存管理一般包含三个不同的组件，分别是用户程序（`Mutator`）、分配器（`Allocator`）和收集器（Collector），当用户程序申请内存时，它会通过内存分配器申请新内存，而分配器会负责从堆中初始化相应的内存区域。

![mutator-allocator-collector](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/2020-02-29-15829868066411-mutator-allocator-collector.png)

Go 语言的内存分配器实现非常复杂，在分析内存分配器的实现之前，我们需要了解内存分配的设计原理，掌握内存的分配过程。这里会详细介绍内存分配器的分配方法以及 Go 语言内存分配器的分级分配、虚拟内存布局和地址空间。

### 分配方法

编程语言的内存分配器一般包含两种分配方法，一种是**线性分配器**（Sequential Allocator，Bump Allocator），另一种是**空闲链表分配器**（Free-List Allocator），这两种分配方法有着不同的实现机制和特性。

#### 线性分配器

线性分配（Bump Allocator）是一种高效的内存分配方法，但是有较大的局限性。当我们使用线性分配器时，只需要在内存中维护一个指向内存特定位置的指针，如果用户程序向分配器申请内存，分配器只需要检查剩余的空闲内存、返回分配的内存区域并修改指针在内存中的位置，即移动下图中的指针：

![bump-allocator](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/2020-02-29-15829868066435-bump-allocator.png)

虽然线性分配器实现为它带来了较快的执行速度以及较低的实现复杂度，但是**线性分配器无法在内存被释放时重用内存**。如下图所示，如果已经分配的内存被回收，线性分配器无法重新利用红色的内存：

![bump-allocator-reclaim-memory](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/2020-02-29-15829868066441-bump-allocator-reclaim-memory.png)

因为线性分配器具有上述特性，所以需要与合适的垃圾回收算法配合使用，例如：标记压缩（Mark-Compact）、复制回收（Copying GC）和分代回收（Generational GC）等算法，它们可以通过拷贝的方式整理存活对象的碎片，将空闲内存定期合并，这样就能利用线性分配器的效率提升内存分配器的性能了。

因为**线性分配器需要与具有拷贝特性的垃圾回收算法配合**，所以 C 和 C++ 等需要直接对外暴露指针的语言就无法使用该策略，我们会在下一节详细介绍常见垃圾回收算法的设计原理。

#### 空闲链表分配器

**空闲链表分配器（Free-List Allocator）可以重用已经被释放的内存，它在内部会维护一个类似链表的数据结构**。当用户程序申请内存时，空闲链表分配器会依次遍历空闲的内存块，找到足够大的内存，然后申请新的资源并修改链表：

![free-list-allocator](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/2020-02-29-15829868066446-free-list-allocator.png)

因为不同的内存块通过指针构成了链表，所以使用这种方式的分配器可以重新利用回收的资源，但是**因为分配内存时需要遍历链表**，所以它的时间复杂度是 O(n)。空闲链表分配器可以选择不同的策略在链表中的内存块中进行选择，最常见的是以下四种：

- **首次适应（First-Fit）**— 从链表头开始遍历，选择第一个大小大于申请内存的内存块；
- **循环首次适应（Next-Fit）**— 从上次遍历的结束位置开始遍历，选择第一个大小大于申请内存的内存块；
- **最优适应（Best-Fit）**— 从链表头遍历整个链表，选择最合适的内存块；
- **隔离适应（Segregated-Fit）**— 将内存分割成多个链表，每个链表中的内存块大小相同，申请内存时先找到满足条件的链表，再从链表中选择合适的内存块；

上述四种策略的前三种就不过多介绍了，Go 语言使用的内存分配策略与第四种策略有些相似，我们通过下图了解该策略的原理：

![segregated-list](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/2020-02-29-15829868066452-segregated-list.png)

如上图所示，该策略会将内存分割成由 4、8、16、32 字节的内存块组成的链表，当我们向内存分配器申请 8 字节的内存时，它会在上图中找到满足条件的空闲内存块并返回。隔离适应的分配策略减少了需要遍历的内存块数量，提高了内存分配的效率。

### 分级分配 

**线程缓存分配（Thread-Caching Malloc，`TCMalloc`）是用于分配内存的机制**，它比 `glibc` 中的 `malloc` 还要快很多。Go 语言的内存分配器就借鉴了 `TCMalloc `的设计实现高速的内存分配，它的核心理念是使用多级缓存将对象根据大小分类，并按照类别实施不同的分配策略。

`TCMalloc`的做法是什么呢？**为每个线程预分配一块缓存，线程申请小内存时，可以从缓存分配内存**，这样有2个好处：

1. 为线程预分配缓存需要进行1次系统调用，后续线程申请小内存时，从缓存分配，都是在用户态执行，没有系统调用，**缩短了内存总体的分配和释放时间，这是快速分配内存的第二个层次**。
2. 多个线程同时申请小内存时，从各自的缓存分配，访问的是不同的地址空间，无需加锁，**把内存并发访问的粒度进一步降低了，这是快速分配内存的第三个层次**。

#### 对象大小

Go 语言的内存分配器会根据申请分配的内存大小选择不同的处理逻辑，运行时根据对象的大小将对象分成微对象、小对象和大对象三种：

|  类别  |     大小      |
| :----: | :-----------: |
| 微对象 |  `(0, 16B)`   |
| 小对象 | `[16B, 32KB]` |
| 大对象 | `(32KB, +∞)`  |

因为程序中的绝大多数对象的大小都在 32KB 以下，而申请的内存大小影响 Go 语言运行时分配内存的过程和开销，所以分别处理大对象和小对象有利于提高内存分配器的性能。

#### 多级缓存

内存分配器不仅会区别对待大小不同的对象，还会将内存分成不同的级别分别管理，`TCMalloc `和 Go 运行时分配器都会引入线程**缓存（Thread Cache）、中心缓存（Central Cache）和页堆（Page Heap）**三个组件分级管理内存：

![multi-level-cache](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/2020-02-29-15829868066457-multi-level-cache.png)

**线程缓存属于每一个独立的线程**，它能够满足线程上绝大多数的内存分配需求，因为不涉及多线程，所以也**不需要使用互斥锁来保护内存**，这能够减少锁竞争带来的性能损耗。当线程缓存不能满足需求时，运行时会使用中心缓存作为补充解决小对象的内存分配，在遇到 32KB 以上的对象时，内存分配器会选择页堆直接分配大内存。

这种多层级的内存分配设计与计算机操作系统中的多级缓存有些类似，因为多数的对象都是小对象，我们可以通过线程缓存和中心缓存提供足够的内存空间，发现资源不足时从上一级组件中获取更多的内存资源。

![Go内存管理](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/1460000020338441)

#### Page

与TCMalloc中的Page相同，x64下**1个Page的大小是8KB**。上图的最下方，1个浅蓝色的长方形代表1个Page。

#### Span

与TCMalloc中的Span相同，**Span是内存管理的基本单位**，代码中为`mspan`，**一组连续的Page组成1个Span**，所以上图一组连续的浅蓝色长方形代表的是一组Page组成的1个Span，另外，1个淡紫色长方形为1个Span。

#### mcache

mcache与TCMalloc中的ThreadCache类似，**mcache保存的是各种大小的Span，并按Span class分类，小对象直接从mcache分配内存，它起到了缓存的作用，并且可以无锁访问**。

但mcache与ThreadCache也有不同点，TCMalloc中是每个线程1个ThreadCache，Go中是**每个P拥有1个mcache**，因为在Go程序中，当前最多有GOMAXPROCS个线程在用户态运行，所以最多需要GOMAXPROCS个mcache就可以保证各线程对mcache的无锁访问，线程的运行又是与P绑定的，把mcache交给P刚刚好。

#### mcentral

mcentral与TCMalloc中的CentralCache类似，**是所有线程共享的缓存，需要加锁访问**，它按Span class对Span分类，串联成链表，当mcache的某个级别Span的内存被分配光时，它会向mcentral申请1个当前级别的Span。

但mcentral与CentralCache也有不同点，CentralCache是每个级别的Span有1个链表，mcache是每个级别的Span有2个链表，这和mcache申请内存有关，稍后我们再解释。

#### mheap

mheap与TCMalloc中的PageHeap类似，**它是堆内存的抽象，把从OS申请出的内存页组织成Span，并保存起来**。当mcentral的Span不够用时会向mheap申请，mheap的Span不够用时会向OS申请，向OS的内存申请是按页来的，然后把申请来的内存页生成Span组织起来，同样也是需要加锁访问的。

但mheap与PageHeap也有不同点：mheap把Span组织成了树结构，而不是链表，并且还是2棵树，然后把Span分配到heapArena进行管理，它包含地址映射和span是否包含指针等位图，这样做的主要原因是为了更高效的利用内存：分配、回收和再利用。

#### 大小转换

除了以上内存块组织概念，还有几个重要的大小概念，一定要拿出来讲一下，不要忽视他们的重要性，他们是内存分配、组织和地址转换的基础。

![Go内存大小转换](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/1460000020338442)

1. **object size**：代码里简称`size`，指申请内存的对象大小。
2. **size class**：代码里简称`class`，它是size的级别，相当于把size归类到一定大小的区间段，比如size[1,8]属于size class 1，size(8,16]属于size class 2。
3. **span class**：指span的级别，但span class的大小与span的大小并没有正比关系。span class主要用来和size class做对应，1个size class对应2个span class，2个span class的span大小相同，只是功能不同，1个用来存放包含指针的对象，一个用来存放不包含指针的对象，不包含指针对象的Span就无需GC扫描了。
4. **num of page**：代码里简称`npage`，代表Page的数量，其实就是Span包含的页数，用来分配内存。

### 虚拟内存布局 

这里会介绍 Go 语言堆区内存地址空间的设计以及演进过程，在 Go 语言 1.10 以前的版本，堆区的内存空间都是连续的；但是在 1.11 版本，Go 团队使用稀疏的堆内存空间替代了连续的内存，解决了连续内存带来的限制以及在特殊场景下可能出现的问题。

#### 线性内存

Go 语言程序的 1.10 版本在启动时会初始化整片虚拟内存区域，如下所示的三个区域 `spans`、`bitmap` 和 `arena` 分别预留了 512MB、16GB 以及 512GB 的内存空间，这些内存并不是真正存在的物理内存，而是虚拟内存：

![heap-before-go-1-10](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/heap-before-go-1-10.png)

- `spans` 区域存储了指向内存管理单元 [`runtime.mspan`](https://draveness.me/golang/tree/runtime.mspan) 的指针，每个内存单元会管理几页的内存空间，每页大小为 8KB；
- `bitmap` 用于标识 `arena` 区域中的那些地址保存了对象，位图中的每个字节都会表示堆区中的 32 字节是否空闲；
- `arena` 区域是真正的堆区，运行时会将 8KB 看做一页，这些内存页中存储了所有在堆上初始化的对象；

对于任意一个地址，我们都可以根据 `arena` 的基地址计算该地址所在的页数并通过 `spans` 数组获得管理该片内存的管理单元 [`runtime.mspan`](https://draveness.me/golang/tree/runtime.mspan)，`spans` 数组中多个连续的位置可能对应同一个 [`runtime.mspan`](https://draveness.me/golang/tree/runtime.mspan) 结构。

Go 语言在垃圾回收时会根据指针的地址判断对象是否在堆中，并通过上一段中介绍的过程找到管理该对象的 [`runtime.mspan`](https://draveness.me/golang/tree/runtime.mspan)。这些都建立在**堆区的内存是连续的**这一假设上。这种设计虽然简单并且方便，但是在 C 和 Go 混合使用时会导致程序崩溃：

1. 分配的内存地址会发生冲突，导致堆的初始化和扩容失败[3](https://draveness.me/golang/docs/part3-runtime/ch07-memory/golang-memory-allocator/#fn:3)；
2. 没有被预留的大块内存可能会被分配给 C 语言的二进制，导致扩容后的堆不连续[4](https://draveness.me/golang/docs/part3-runtime/ch07-memory/golang-memory-allocator/#fn:4)；

线性的堆内存需要预留大块的内存空间，但是申请大块的内存空间而不使用是不切实际的，不预留内存空间却会在特殊场景下造成程序崩溃。虽然连续内存的实现比较简单，但是这些问题也没有办法忽略。

#### 稀疏内存 

稀疏内存是 Go 语言在 1.11 中提出的方案，使用稀疏的内存布局不仅能移除堆大小的上限，还能解决 C 和 Go 混合使用时的地址空间冲突问题。不过因为基于稀疏内存的内存管理失去了内存的连续性这一假设，这也使内存管理变得更加复杂：

![heap-after-go-1-11](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/2020-02-29-15829868066468-heap-after-go-1-11.png)

如上图所示，运行时使用二维的 [`runtime.heapArena`](https://draveness.me/golang/tree/runtime.heapArena) 数组管理所有的内存，每个单元都会管理 64MB 的内存空间：

```go
type heapArena struct {
	bitmap       [heapArenaBitmapBytes]byte
	spans        [pagesPerArena]*mspan
	pageInUse    [pagesPerArena / 8]uint8
	pageMarks    [pagesPerArena / 8]uint8
	pageSpecials [pagesPerArena / 8]uint8
	checkmarks   *checkmarksMap
	zeroedBase   uintptr
}
```

该结构体中的 `bitmap` 和 `spans` 与线性内存中的 `bitmap` 和 `spans` 区域一一对应，`zeroedBase` 字段指向了该结构体管理的内存的基地址。上述设计将原有的连续大内存切分成稀疏的小内存，而用于管理这些内存的元信息也被切成了小块。

不同平台和架构的二维数组大小可能完全不同，如果我们的 Go 语言服务在 Linux 的 x86-64 架构上运行，二维数组的一维大小会是 1，而二维大小是 4,194,304，因为每一个指针占用 8 字节的内存空间，所以元信息的总大小为 32MB。由于每个 [`runtime.heapArena`](https://draveness.me/golang/tree/runtime.heapArena) 都会管理 64MB 的内存，整个堆区最多可以管理 256TB 的内存，这比之前的 512GB 多好几个数量级。

Go 语言团队在 1.11 版本中通过以下几个提交将线性内存变成稀疏内存，移除了 512GB 的内存上限以及堆区内存连续性的假设：

- [runtime: use sparse mappings for the heap](https://github.com/golang/go/commit/2b415549b813ba36caafa34fc34d72e47ee8335c)
- [runtime: fix various contiguous bitmap assumptions](https://github.com/golang/go/commit/f61057c497e9ccb88dae093778d97aeee941af13)
- [runtime: make the heap bitmap sparse](https://github.com/golang/go/commit/c0392d2e7fbdcd38aafb959e94daf6bbafe2e4e9)
- [runtime: abstract remaining mheap.spans access](https://github.com/golang/go/commit/0de5324d61ba6d4c362f9fa76b6522e28155c83d)
- [runtime: make span map sparse](https://github.com/golang/go/commit/d6e821858157b7cb4ece22fcc1a5c8604478ebaa)
- [runtime: eliminate most uses of mheap_.arena_*](https://github.com/golang/go/commit/45ffeab549fa4b03b231a0872025364e13c7f7f0)
- [runtime: remove non-reserved heap logic](https://github.com/golang/go/commit/51ae88ee2f9a1063c272a497527751d786291c89)
- [runtime: move comment about address space sizes to malloc.go](https://github.com/golang/go/commit/90666b8a3d5545f4295d9c2517ad607ce5d45e52)

由于内存的管理变得更加复杂，上述改动对垃圾回收稍有影响，大约会增加 1% 的垃圾回收开销，不过这也是我们为了解决已有问题必须付出的成本。

### 地址空间

因为所有的内存最终都是要从操作系统中申请的，所以 Go 语言的运行时构建了操作系统的内存管理抽象层，该抽象层将运行时管理的地址空间分成以下四种状态：

|    状态    |                             解释                             |
| :--------: | :----------------------------------------------------------: |
|   `None`   |         内存没有被保留或者映射，是地址空间的默认状态         |
| `Reserved` |        运行时持有该地址空间，但是访问该内存会导致错误        |
| `Prepared` | 内存被保留，一般没有对应的物理内存访问该片内存的行为是未定义的可以快速转换到 `Ready` 状态 |
|  `Ready`   |                        可以被安全访问                        |

每个不同的操作系统都会包含一组用于管理内存的特定方法，这些方法可以让内存地址空间在不同的状态之间转换，我们可以通过下图了解不同状态之间的转换过程：

![memory-regions-states-and-transitions](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/2020-02-29-15829868066474-memory-regions-states-and-transitions.png)

运行时中包含多个操作系统实现的状态转换方法，所有的实现都包含在以 `mem_` 开头的文件中，本节将介绍 Linux 操作系统对上图中方法的实现：

- [`runtime.sysAlloc`](https://draveness.me/golang/tree/runtime.sysAlloc) 会从操作系统中获取一大块可用的内存空间，可能为几百 KB 或者几 MB；
- [`runtime.sysFree`](https://draveness.me/golang/tree/runtime.sysFree) 会在程序发生内存不足（Out-of Memory，OOM）时调用并无条件地返回内存；
- [`runtime.sysReserve`](https://draveness.me/golang/tree/runtime.sysReserve) 会保留操作系统中的一片内存区域，访问这片内存会触发异常；
- [`runtime.sysMap`](https://draveness.me/golang/tree/runtime.sysMap) 保证内存区域可以快速转换至就绪状态；
- [`runtime.sysUsed`](https://draveness.me/golang/tree/runtime.sysUsed) 通知操作系统应用程序需要使用该内存区域，保证内存区域可以安全访问；
- [`runtime.sysUnused`](https://draveness.me/golang/tree/runtime.sysUnused) 通知操作系统虚拟内存对应的物理内存已经不再需要，可以重用物理内存；
- [`runtime.sysFault`](https://draveness.me/golang/tree/runtime.sysFault) 将内存区域转换成保留状态，主要用于运行时的调试；

运行时使用 Linux 提供的 `mmap`、`munmap` 和 `madvise` 等系统调用实现了操作系统的内存管理抽象层，抹平了不同操作系统的差异，为运行时提供了更加方便的接口，除了 Linux 之外，运行时还实现了 BSD、Darwin、Plan9 以及 Windows 等平台上抽象层

## 内存分配原理

[span、mcache、mcenter、mheap](https://github.com/Simin-hub/Golang-Learning-and-Interview/blob/main/Go/%E8%BF%9B%E9%98%B6/%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86.md)

![Go内存对象分类](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/1460000020338446)

小对象是在mcache中分配的，而大对象是直接从mheap分配的，从小对象的内存分配看起。

<img src="https://raw.githubusercontent.com/Simin-hub/Picture/master/img/1460000020338441" alt="Go内存管理" style="zoom:200%;" />

### 小对象分配内存

[`numSpanClasses`](https://github.com/Simin-hub/Golang-Learning-and-Interview/blob/main/Go/%E8%BF%9B%E9%98%B6/%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86.md#cache)为span class(总共有67 种 class，又分为包含指针和不包含指针两种，因此为134)的数量为134个，所以span class的下标是从0到133，所以上图中mcache标注了的span class是，`span class 0`到`span class 133`。每1个span class都指向1个span，也就是mcache最多有134个span。

##### 为对象寻找span

寻找span的流程如下：

1. 计算对象所需内存大小size
2. 根据size到size class映射，计算出所需的size class
3. 根据size class和对象是否包含指针计算出span class
4. 获取该span class指向的span。

以分配一个不包含指针的，大小为24Byte的对象为例。

根据映射表：

```go
// class  bytes/obj  bytes/span  objects  tail waste  max waste
//     1          8        8192     1024           0     87.50%
//     2         16        8192      512           0     43.75%
//     3         32        8192      256           0     46.88%
//     4         48        8192      170          32     31.52%
```

size class 3，它的对象大小范围是(16,32]Byte，24Byte刚好在此区间，所以此对象的size class为3。

Size class到span class的计算如下：

```go
// noscan为true代表对象不包含指针
func makeSpanClass(sizeclass uint8, noscan bool) spanClass {
    return spanClass(sizeclass<<1) | spanClass(bool2int(noscan))
}
```

所以，对应的span class为：

```go
span class = 3 << 1 | 1 = 7
```

所以该对象需要的是span class 7指向的span。

##### 从span分配对象空间

Span可以按对象大小切成很多份，这些都可以从映射表上计算出来，以size class 3对应的span为例，span大小是8KB，每个对象实际所占空间为32Byte，这个span就被分成了256块，可以根据span的起始地址计算出每个对象块的内存地址。

![Span内对象](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/1460000020338447)

随着内存的分配，span中的对象内存块，有些被占用，有些未被占用，比如上图，整体代表1个span，蓝色块代表已被占用内存，绿色块代表未被占用内存。

当分配内存时，只要快速找到第一个可用的绿色块，并计算出内存地址即可，如果需要还可以对内存块数据清零。

##### span没有空间怎么分配对象

span内的所有内存块都被占用时，没有剩余空间继续分配对象，**mcache会向mcentral申请1个span**，mcache拿到span后继续分配对象。

##### mcentral向mcache提供span

mcentral和mcache一样，都是0~133这134个span class级别，但每个级别都保存了2个span list，即2个span链表：

1. `nonempty`：**这个链表里的span，所有span都至少有1个空闲的对象空间**。这些span是mcache释放span时加入到该链表的。
2. `empty`：**这个链表里的span，所有的span都不确定里面是否有空闲的对象空间**。当一个span交给mcache的时候，就会加入到empty链表。

这2个东西名称一直有点绕，建议直接把empty理解为没有对象空间就好了。

![mcentral](https://segmentfault.com/img/remote/1460000020338448)

*实际代码中**每1个span class对应1个mcentral**，图里把所有mcentral抽象成1个整体了。*

mcache向mcentral要span时，mcentral会先从`nonempty`搜索满足条件的span，如果每找到再从`emtpy`搜索满足条件的span，然后把找到的span交给mcache。

##### mheap的span管理

mheap里保存了2棵**二叉排序树**，按span的page数量进行排序：

1. `free`：free中保存的span是**空闲并且非垃圾回收的span**。
2. `scav`：scav中保存的是**空闲并且已经垃圾回收的span**。

如果是垃圾回收导致的span释放，span会被加入到`scav`，否则加入到`free`，比如刚从OS申请的的内存也组成的Span。

![mheap](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/1460000020338449)

mheap中还有arenas，有一组heapArena组成，每一个heapArena都包含了连续的`pagesPerArena`个span，这个主要是为mheap管理span和垃圾回收服务。

mheap本身是一个全局变量，它其中的数据，也都是从OS直接申请来的内存，并不在mheap所管理的那部分内存内。

##### mcentral向mheap要span

**mcentral向mcache提供span时，如果`emtpy`里也没有符合条件的span，mcentral会向mheap申请span**。

mcentral需要向mheap提供需要的内存页数和span class级别，然后它优先从`free`中搜索可用的span，如果没有找到，会从`scav`中搜索可用的span，如果还没有找到，它会向OS申请内存，再重新搜索2棵树，必然能找到span。如果找到的span比需求的span大，则把span进行分割成2个span，其中1个刚好是需求大小，把剩下的span再加入到`free`中去，然后设置需求span的基本信息，然后交给mcentral。

##### mheap向OS申请内存

当mheap没有足够的内存时，mheap会向OS申请内存，把申请的内存页保存到span，然后把span插入到`free`树 。

在32位系统上，mheap还会预留一部分空间，当mheap没有空间时，先从预留空间申请，如果预留空间内存也没有了，才向OS申请。

### 大对象分配

大对象的分配比小对象省事多了，99%的流程与mcentral向mheap申请内存的相同，所以不重复介绍了，不同的一点在于mheap会记录一点大对象的统计信息，见`mheap.alloc_m()`。



## [栈管理](https://github.com/Simin-hub/Golang-Learning-and-Interview/blob/main/Go/%E8%BF%9B%E9%98%B6/%E6%A0%88%E7%AE%A1%E7%90%86.md)



## 逃逸分析

[逃逸分析](https://github.com/Simin-hub/Golang-Learning-and-Interview/blob/main/Go/%E8%BF%9B%E9%98%B6/%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90.md)

[参考](https://www.cnblogs.com/qcrao-2018/p/10453260.html)

### 为什么需要逃逸分析

C/C++中动态分配的内存需要我们手动释放，导致猿们平时在写程序时，如履薄冰。这样做有他的好处：程序员可以完全掌控内存。但是缺点也是很多的：经常出现忘记释放内存，导致内存泄露。所以，很多现代语言都加上了垃圾回收机制。

Go的垃圾回收，让堆和栈对程序员保持透明。真正解放了程序员的双手，让他们可以专注于业务，“高效”地完成代码编写。把那些内存管理的复杂机制交给编译器，而程序员可以去享受生活。

`逃逸分析`这种“骚操作”把变量合理地分配到它该去的地方，“找准自己的位置”。即使你是用new申请到的内存，如果我发现你竟然在退出函数后没有用了，那么就把你丢到栈上，毕竟栈上的内存分配比堆上快很多；反之，即使你表面上只是一个普通的变量，但是经过逃逸分析后发现在退出函数之后还有其他地方在引用，那我就把你分配到堆上。真正地做到“按需分配”，提前实现共产主义！

如果变量都分配到堆上，堆不像栈可以自动清理。它会引起Go频繁地进行垃圾回收，而垃圾回收会占用比较大的系统开销（占用CPU容量的25%）。

堆和栈相比，堆适合不可预知大小的内存分配。但是为此付出的代价是分配速度较慢，而且会形成内存碎片。栈内存分配则会非常快。栈分配内存只需要两个CPU指令：“PUSH”和“RELEASSE”，分配和释放；而堆分配内存首先需要去找到一块大小合适的内存块，之后要通过垃圾回收才能释放。

**通过逃逸分析，可以尽量把那些不需要分配到堆上的变量直接分配到栈上，堆上的变量少了，会减轻分配堆内存的开销，同时也会减少gc的压力，提高程序的运行速度。**

### 逃逸分析是怎么完成的

Go逃逸分析最基本的原则是：**如果一个函数返回对一个变量的引用，那么它就会发生逃逸**。

简单来说，编译器会分析代码的特征和代码生命周期，Go中的变量只有在编译器可以证明在函数返回后不会再被引用的，才分配到栈上，其他情况下都是分配到堆上。

Go语言里没有一个关键字或者函数可以直接让变量被编译器分配到堆上，相反，编译器通过分析代码来决定将变量分配到何处。

对一个变量取地址，可能会被分配到堆上。但是编译器进行逃逸分析后，如果考察到在函数返回后，此变量不会被引用，那么还是会被分配到栈上。套个取址符，就想骗补助？Too young！

简单来说，编译器会根据变量是否被外部引用来决定是否逃逸：

> 1. 如果函数外部没有引用，则优先放到栈中；
> 2. 如果函数外部存在引用，则必定放到堆中；

针对第一条，**可能放到堆上的情形：定义了一个很大的数组，需要申请的内存过大，超过了栈的存储能力**。

### **内存分配过程分析**

本部分，将以代码的形式，分别介绍栈内存分配、指针作为参数情况下的栈内存分配、指针作为返回值情况下的栈内存分配并逐步引出逃逸分析和几个内存逃逸的基本原则。

正文开始，Talk is cheap，show me the code。

#### **栈内存分配**

我将以一段简单的代码作为示例，分析这段代码的内存分配过程。

```javascript
package main
import "fmt"
func main() {  n := 4  n2 := square(n)  fmt.Println(n2)}
func square(n int) int{  return n * n}
```

代码的功能很简单，一个 main 函数作为程序入口，定义了一个变量n，定义了另一个函数 squire ，返回乘方操作后的 int 值。最后，将返回的值打印到控制台。程序输出为16。

下面开始逐行进行分析，解析调用时，go 运行时是如何对内存进行分配的。

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/479e83aa67b17d920bd71f6625afe1c9.webp)

当代码运行到第6行，进入 main 函数时，会在栈上创建一个 Stack frame，存放**本函数中的变量信息。包括函数名称，变量**等。

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/h4jok0khik.png)

当代码运行到第7行时，go 会在栈中压入一个新的 Stack Frame，用于存放调用 square 函数的信息；包括函数名、变量 n 的值等。此时，计算4 * 4 的值，并返回。

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/e595bc8e8421e68646c147ea1cb411ab.webp)

当 square 函数调用完成，返回16到 main 函数后，将16赋值给 n2变量。注意，**原来的 stack frame 并不会被 go 清理掉，而是如栈左侧的箭头所示，被标记为不合法**。上图夹在红色箭头和绿色箭头之间的横线可以理解为 go 汇编代码中的 SP 栈寄存器的值，当程序申请或释放栈内存时，只需要修改 SP 寄存器的值，这种栈内存分配方式省掉了清理栈内存空间的耗时。



![img](https://ask.qcloudimg.com/developer-images/article/5469577/m6ls2qtdbl.png)

接下来，调用 fmt.Println 时，SP 寄存器的值会进一步增加，覆盖掉原来 square 函数的 stack frame，完成 print 后，程序正常退出。

#### **指针作为参数情况下的栈内存分配**

还是同样的过程，看如下这段代码。

```javascript
package main
import "fmt"
func main() {  n := 4  increase(&n)  fmt.Println(n)}
func increase(i *int) {  *i++}
```

main 作为程序入口，声明了一个变量 n，赋值为4。声明了一个函数  increase，使用一个 int 类型的指针 `i` 作为参数，increase 函数内，对指针 `i` 对应的值进行自增操作。最后 main 函数中打印了 n 的值。程序输出为5。

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/7snaopjz26.png)

当程序运行到 main 函数的第6行时，go 在栈上分配了一个 stack frame ，对变量 n 进行了赋值，n 在内存中对应的地址为0xc0008771，此时程序将继续向下执行，调用 increase 函数。

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/nzbfzfdkup.png)

这时，increase 函数对应的 stack fream 被创建，i 被赋值为变量 n对应的地址值0xc0008771，然后进行自增操作。

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/u14njxdglz.png)

当 increase 函数运行结束后，SP 寄存器会上移，将之前分配的 stack freme 标记为不合法。此时，程序运行正常，并没有因为 SP 寄存器的改动而影响程序的正确性，内存中的值也被正确的修改了。

#### **指针作为返回值情况下的栈内存分配**

文章之前的部分分别介绍了普通变量作为参数和将指针作为参数情况下的栈内存使用，本部分来介绍将**指针作为返回值**，返回给调用方的情况下，内存是如何分配的，并引出内存逃逸相关内容。来看这段代码：

```javascript
package main
import "fmt"
func main() {  n := initValue()  fmt.Println(*n/2)}
func initValue() *int {  i := 4  return &i}
```

main 函数中，调用了 `initValue` 函数，该函数返回一个 int 指针并赋值给 n，指针对应的值为4。随后，main 函数调用 fmt.Println 打印了指针 n / 2对应的值。程序输出为2。

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/945gf1ih2a.png)

程序调用 `initValue` 后，将 `i` 的地址赋值给变量 n 。注意，如果这时，变量 `i` 的位置在栈上，则可能会随时被覆盖掉。

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/8ydk3bi2lv.png)

在调用 fmt.Println 时，Stack Frame 会被重新创建，变量 i 被赋值为*n/2也就是2，会覆盖掉原来 n 所指向的变量值。这会导致及其严重的问题。在面对 sharing up 场景时，go 通常会将变量分配到堆中，如下图所示：

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/16ab1617ecd4832e038e07e9a612fd69.webp)

通过上面的分析，可以看到在面对被调用的函数返回一个指针类型时将对象分配到栈上会带来严重的问题，因此 Go 将变量分配到了堆上。这种分配方式保证了程序的安全性，但也不可避免的增加了堆内存创建，并需要在将来的某个时候，需要 GC 将不再使用的内存清理掉。

### **内存分配原则**

经过上述分析，可以简单的归纳几条原则。

- Sharing down typically stays on the stack 在调用方创建的变量或对象，通过参数的形式传递给被调用函数，这时，在调用方创建的内存空间通常在栈上。这种在调用方创建内存，在被调用方使用该内存的“内存共享”方式，称之为 Sharing down。
- Sharing up typically escapes to the heap 在被调用函数内创建的对象，以指针的形式返回给调用方的情况下，通常，创建的内存空间在堆上。这种在被调用方创建，在调用方使用的“内存共享”方式，称之为 Sharing up。
- Only the compiler knows 之所以上面两条原则都加了通常，因为具体的分配方式，是由编译器确定的，一些编译器后端优化，可能会突破这两个原则，因此，具体的分配逻辑，只有编译器（或开发编译器的人）知道。



## 垃圾回收GC

[GC原理](https://github.com/Simin-hub/Golang-Learning-and-Interview/blob/main/Go/%E8%BF%9B%E9%98%B6/GC.md)

如果只申请和分配内存，内存终将枯竭，Go使用垃圾回收收集不再使用的span，调用`mspan.scavenge()`把span释放给OS（并非真释放，只是告诉OS这片内存的信息无用了，如果你需要的话，收回去好了），然后交给mheap，mheap对span进行span的合并，把合并后的span加入`scav`树中，等待再分配内存时，由mheap进行内存再分配，Go垃圾回收也是一个很强的主题，计划后面单独写一篇文章介绍。

现在我们关注一下，Go程序是怎么把内存释放给操作系统的？

释放内存的函数是`sysUnused`，它会被`mspan.scavenge()`调用:

```go
// MAC下的实现
func sysUnused(v unsafe.Pointer, n uintptr) {
    // MADV_FREE_REUSABLE is like MADV_FREE except it also propagates
    // accounting information about the process to task_info.
    madvise(v, n, _MADV_FREE_REUSABLE)
}
```

注释说`_MADV_FREE_REUSABLE`与`MADV_FREE`的功能类似，它的功能是给内核提供一个建议：**这个内存地址区间的内存已经不再使用，可以回收。但内核是否回收，以及什么时候回收，这就是内核的事情了**。如果内核真把这片内存回收了，当Go程序再使用这个地址时，内核会重新进行虚拟地址到物理地址的映射。所以在内存充足的情况下，内核也没有必要立刻回收内存。
