# 内存管理

## 概念

[参考2](https://draveness.me/golang/docs/part3-runtime/ch07-memory/golang-memory-allocator/)

[参考](https://segmentfault.com/a/1190000020338427)

Go 有两个地方可以分配内存：一个**全局堆空间**用来*动态分配*内存，另一个是每个 `goroutine `都有的**自身栈空间**。

内存分配分配的就是全局堆空间。

### 内存泄漏和内存溢出

内存泄漏（Memory Leak）是指程序中**已动态分配的堆内存由于某种原因程序未释放或无法释放**，造成系统内存的浪费，导致程序运行速度减慢甚至系统崩溃等严重后果。

内存溢出(Out Of Memory，简称OOM)是**指应用系统中存在无法回收的[内存](https://baike.baidu.com/item/内存/103614)或使用的[内存](https://baike.baidu.com/item/内存/103614)过多，最终使得程序运行要用到的[内存](https://baike.baidu.com/item/内存/103614)大于能提供的最大内存。此时[程序](https://baike.baidu.com/item/程序/13831935)就运行不了，系统会提示内存溢出**，有时候会[自动](https://baike.baidu.com/item/自动/9374325)[关闭](https://baike.baidu.com/item/关闭/2901526)软件，重启电脑或者软件后释放掉一部分内存又可以正常运行该软件，而由[系统配置](https://baike.baidu.com/item/系统配置/558913)、[数据流](https://baike.baidu.com/item/数据流/3002243)、用户代码等原因而导致的内存溢出错误，即使用户重新执行任务依然无法避免 [1] 。

### 虚拟内存

Golang 程序在启动时，会向操作系统申请一定区域的内存，分为栈（Stack）和堆（Heap），栈内存会随着函数的调用分配和回收；堆内存由程序申请分配，由垃圾回收器（Garbage Collector）负责回收。

程序中的**数据和变量都会被分配到程序所在的虚拟内存**中，内存空间包含两个重要区域：**栈区（Stack）和堆区（Heap）**。**函数调用的参数、返回值以及局部变量**大都会被分配到栈上，**这部分内存会由编译器进行管理**；不同编程语言使用不同的方法管理堆区的内存，C++ 等编程语言会由工程师主动申请和释放内存，Go 以及 Java 等编程语言会由工程师和编译器共同管理，**堆中的对象由内存分配器分配并由垃圾收集器回收**。

内存管理一般包含三个不同的组件，分别是用户程序（`Mutator`）、分配器（`Allocator`）和收集器（Collector），当用户程序申请内存时，它会通过内存分配器申请新内存，而分配器会负责从堆中初始化相应的内存区域。

![mutator-allocator-collector](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/2020-02-29-15829868066411-mutator-allocator-collector.png)

Go 语言的内存分配器实现非常复杂，在分析内存分配器的实现之前，我们需要了解内存分配的设计原理，掌握内存的分配过程。这里会详细介绍内存分配器的分配方法以及 Go 语言内存分配器的分级分配、虚拟内存布局和地址空间。

### 分配方法

编程语言的内存分配器一般包含两种分配方法，一种是**线性分配器**（Sequential Allocator，Bump Allocator），另一种是**空闲链表分配器**（Free-List Allocator），这两种分配方法有着不同的实现机制和特性。

#### 线性分配器

线性分配（Bump Allocator）是一种高效的内存分配方法，但是有较大的局限性。当我们使用线性分配器时，只需要在内存中维护一个指向内存特定位置的指针，如果用户程序向分配器申请内存，分配器只需要检查剩余的空闲内存、返回分配的内存区域并修改指针在内存中的位置，即移动下图中的指针：

![bump-allocator](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/2020-02-29-15829868066435-bump-allocator.png)

虽然线性分配器实现为它带来了较快的执行速度以及较低的实现复杂度，但是**线性分配器无法在内存被释放时重用内存**。如下图所示，如果已经分配的内存被回收，线性分配器无法重新利用红色的内存：

![bump-allocator-reclaim-memory](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/2020-02-29-15829868066441-bump-allocator-reclaim-memory.png)

因为线性分配器具有上述特性，所以需要与合适的垃圾回收算法配合使用，例如：标记压缩（Mark-Compact）、复制回收（Copying GC）和分代回收（Generational GC）等算法，它们可以通过拷贝的方式整理存活对象的碎片，将空闲内存定期合并，这样就能利用线性分配器的效率提升内存分配器的性能了。

因为**线性分配器需要与具有拷贝特性的垃圾回收算法配合**，所以 C 和 C++ 等需要直接对外暴露指针的语言就无法使用该策略，我们会在下一节详细介绍常见垃圾回收算法的设计原理。

#### 空闲链表分配器

**空闲链表分配器（Free-List Allocator）可以重用已经被释放的内存，它在内部会维护一个类似链表的数据结构**。当用户程序申请内存时，空闲链表分配器会依次遍历空闲的内存块，找到足够大的内存，然后申请新的资源并修改链表：

![free-list-allocator](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/2020-02-29-15829868066446-free-list-allocator.png)

因为不同的内存块通过指针构成了链表，所以使用这种方式的分配器可以重新利用回收的资源，但是**因为分配内存时需要遍历链表**，所以它的时间复杂度是 O(n)。空闲链表分配器可以选择不同的策略在链表中的内存块中进行选择，最常见的是以下四种：

- **首次适应（First-Fit）**— 从链表头开始遍历，选择第一个大小大于申请内存的内存块；
- **循环首次适应（Next-Fit）**— 从上次遍历的结束位置开始遍历，选择第一个大小大于申请内存的内存块；
- **最优适应（Best-Fit）**— 从链表头遍历整个链表，选择最合适的内存块；
- **隔离适应（Segregated-Fit）**— 将内存分割成多个链表，每个链表中的内存块大小相同，申请内存时先找到满足条件的链表，再从链表中选择合适的内存块；

上述四种策略的前三种就不过多介绍了，Go 语言使用的内存分配策略与第四种策略有些相似，我们通过下图了解该策略的原理：

![segregated-list](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/2020-02-29-15829868066452-segregated-list.png)

如上图所示，该策略会将内存分割成由 4、8、16、32 字节的内存块组成的链表，当我们向内存分配器申请 8 字节的内存时，它会在上图中找到满足条件的空闲内存块并返回。隔离适应的分配策略减少了需要遍历的内存块数量，提高了内存分配的效率。

### 分级分配 

**线程缓存分配（Thread-Caching Malloc，`TCMalloc`）是用于分配内存的机制**，它比 `glibc` 中的 `malloc` 还要快很多。Go 语言的内存分配器就借鉴了 `TCMalloc `的设计实现高速的内存分配，它的核心理念是使用多级缓存将对象根据大小分类，并按照类别实施不同的分配策略。

`TCMalloc`的做法是什么呢？**为每个线程预分配一块缓存，线程申请小内存时，可以从缓存分配内存**，这样有2个好处：

1. 为线程预分配缓存需要进行1次系统调用，后续线程申请小内存时，从缓存分配，都是在用户态执行，没有系统调用，**缩短了内存总体的分配和释放时间，这是快速分配内存的第二个层次**。
2. 多个线程同时申请小内存时，从各自的缓存分配，访问的是不同的地址空间，无需加锁，**把内存并发访问的粒度进一步降低了，这是快速分配内存的第三个层次**。

#### 对象大小

Go 语言的内存分配器会根据申请分配的内存大小选择不同的处理逻辑，运行时根据对象的大小将对象分成微对象、小对象和大对象三种：

|  类别  |     大小      |
| :----: | :-----------: |
| 微对象 |  `(0, 16B)`   |
| 小对象 | `[16B, 32KB]` |
| 大对象 | `(32KB, +∞)`  |

因为程序中的绝大多数对象的大小都在 32KB 以下，而申请的内存大小影响 Go 语言运行时分配内存的过程和开销，所以分别处理大对象和小对象有利于提高内存分配器的性能。

#### 多级缓存

内存分配器不仅会区别对待大小不同的对象，还会将内存分成不同的级别分别管理，`TCMalloc `和 Go 运行时分配器都会引入线程**缓存（Thread Cache）、中心缓存（Central Cache）和页堆（Page Heap**三个组件分级管理内存：

![multi-level-cache](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/2020-02-29-15829868066457-multi-level-cache.png)

**线程缓存属于每一个独立的线程**，它能够满足线程上绝大多数的内存分配需求，因为不涉及多线程，所以也**不需要使用互斥锁来保护内存**，这能够减少锁竞争带来的性能损耗。当线程缓存不能满足需求时，运行时会使用中心缓存作为补充解决小对象的内存分配，在遇到 32KB 以上的对象时，内存分配器会选择页堆直接分配大内存。

这种多层级的内存分配设计与计算机操作系统中的多级缓存有些类似，因为多数的对象都是小对象，我们可以通过线程缓存和中心缓存提供足够的内存空间，发现资源不足时从上一级组件中获取更多的内存资源。

![Go内存管理](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/1460000020338441)

#### Page

与TCMalloc中的Page相同，x64下**1个Page的大小是8KB**。上图的最下方，1个浅蓝色的长方形代表1个Page。

#### Span

与TCMalloc中的Span相同，**Span是内存管理的基本单位**，代码中为`mspan`，**一组连续的Page组成1个Span**，所以上图一组连续的浅蓝色长方形代表的是一组Page组成的1个Span，另外，1个淡紫色长方形为1个Span。

#### mcache

mcache与TCMalloc中的ThreadCache类似，**mcache保存的是各种大小的Span，并按Span class分类，小对象直接从mcache分配内存，它起到了缓存的作用，并且可以无锁访问**。

但mcache与ThreadCache也有不同点，TCMalloc中是每个线程1个ThreadCache，Go中是**每个P拥有1个mcache**，因为在Go程序中，当前最多有GOMAXPROCS个线程在用户态运行，所以最多需要GOMAXPROCS个mcache就可以保证各线程对mcache的无锁访问，线程的运行又是与P绑定的，把mcache交给P刚刚好。

#### mcentral

mcentral与TCMalloc中的CentralCache类似，**是所有线程共享的缓存，需要加锁访问**，它按Span class对Span分类，串联成链表，当mcache的某个级别Span的内存被分配光时，它会向mcentral申请1个当前级别的Span。

但mcentral与CentralCache也有不同点，CentralCache是每个级别的Span有1个链表，mcache是每个级别的Span有2个链表，这和mcache申请内存有关，稍后我们再解释。

#### mheap

mheap与TCMalloc中的PageHeap类似，**它是堆内存的抽象，把从OS申请出的内存页组织成Span，并保存起来**。当mcentral的Span不够用时会向mheap申请，mheap的Span不够用时会向OS申请，向OS的内存申请是按页来的，然后把申请来的内存页生成Span组织起来，同样也是需要加锁访问的。

但mheap与PageHeap也有不同点：mheap把Span组织成了树结构，而不是链表，并且还是2棵树，然后把Span分配到heapArena进行管理，它包含地址映射和span是否包含指针等位图，这样做的主要原因是为了更高效的利用内存：分配、回收和再利用。

#### 大小转换

除了以上内存块组织概念，还有几个重要的大小概念，一定要拿出来讲一下，不要忽视他们的重要性，他们是内存分配、组织和地址转换的基础。

![Go内存大小转换](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/1460000020338442)

1. **object size**：代码里简称`size`，指申请内存的对象大小。
2. **size class**：代码里简称`class`，它是size的级别，相当于把size归类到一定大小的区间段，比如size[1,8]属于size class 1，size(8,16]属于size class 2。
3. **span class**：指span的级别，但span class的大小与span的大小并没有正比关系。span class主要用来和size class做对应，1个size class对应2个span class，2个span class的span大小相同，只是功能不同，1个用来存放包含指针的对象，一个用来存放不包含指针的对象，不包含指针对象的Span就无需GC扫描了。
4. **num of page**：代码里简称`npage`，代表Page的数量，其实就是Span包含的页数，用来分配内存。

### 虚拟内存布局 

这里会介绍 Go 语言堆区内存地址空间的设计以及演进过程，在 Go 语言 1.10 以前的版本，堆区的内存空间都是连续的；但是在 1.11 版本，Go 团队使用稀疏的堆内存空间替代了连续的内存，解决了连续内存带来的限制以及在特殊场景下可能出现的问题。

#### 线性内存

Go 语言程序的 1.10 版本在启动时会初始化整片虚拟内存区域，如下所示的三个区域 `spans`、`bitmap` 和 `arena` 分别预留了 512MB、16GB 以及 512GB 的内存空间，这些内存并不是真正存在的物理内存，而是虚拟内存：

![heap-before-go-1-10](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/heap-before-go-1-10.png)

- `spans` 区域存储了指向内存管理单元 [`runtime.mspan`](https://draveness.me/golang/tree/runtime.mspan) 的指针，每个内存单元会管理几页的内存空间，每页大小为 8KB；
- `bitmap` 用于标识 `arena` 区域中的那些地址保存了对象，位图中的每个字节都会表示堆区中的 32 字节是否空闲；
- `arena` 区域是真正的堆区，运行时会将 8KB 看做一页，这些内存页中存储了所有在堆上初始化的对象；

对于任意一个地址，我们都可以根据 `arena` 的基地址计算该地址所在的页数并通过 `spans` 数组获得管理该片内存的管理单元 [`runtime.mspan`](https://draveness.me/golang/tree/runtime.mspan)，`spans` 数组中多个连续的位置可能对应同一个 [`runtime.mspan`](https://draveness.me/golang/tree/runtime.mspan) 结构。

Go 语言在垃圾回收时会根据指针的地址判断对象是否在堆中，并通过上一段中介绍的过程找到管理该对象的 [`runtime.mspan`](https://draveness.me/golang/tree/runtime.mspan)。这些都建立在**堆区的内存是连续的**这一假设上。这种设计虽然简单并且方便，但是在 C 和 Go 混合使用时会导致程序崩溃：

1. 分配的内存地址会发生冲突，导致堆的初始化和扩容失败[3](https://draveness.me/golang/docs/part3-runtime/ch07-memory/golang-memory-allocator/#fn:3)；
2. 没有被预留的大块内存可能会被分配给 C 语言的二进制，导致扩容后的堆不连续[4](https://draveness.me/golang/docs/part3-runtime/ch07-memory/golang-memory-allocator/#fn:4)；

线性的堆内存需要预留大块的内存空间，但是申请大块的内存空间而不使用是不切实际的，不预留内存空间却会在特殊场景下造成程序崩溃。虽然连续内存的实现比较简单，但是这些问题也没有办法忽略。

#### 稀疏内存 

稀疏内存是 Go 语言在 1.11 中提出的方案，使用稀疏的内存布局不仅能移除堆大小的上限，还能解决 C 和 Go 混合使用时的地址空间冲突问题。不过因为基于稀疏内存的内存管理失去了内存的连续性这一假设，这也使内存管理变得更加复杂：

![heap-after-go-1-11](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/2020-02-29-15829868066468-heap-after-go-1-11.png)

如上图所示，运行时使用二维的 [`runtime.heapArena`](https://draveness.me/golang/tree/runtime.heapArena) 数组管理所有的内存，每个单元都会管理 64MB 的内存空间：

```go
type heapArena struct {
	bitmap       [heapArenaBitmapBytes]byte
	spans        [pagesPerArena]*mspan
	pageInUse    [pagesPerArena / 8]uint8
	pageMarks    [pagesPerArena / 8]uint8
	pageSpecials [pagesPerArena / 8]uint8
	checkmarks   *checkmarksMap
	zeroedBase   uintptr
}
```

该结构体中的 `bitmap` 和 `spans` 与线性内存中的 `bitmap` 和 `spans` 区域一一对应，`zeroedBase` 字段指向了该结构体管理的内存的基地址。上述设计将原有的连续大内存切分成稀疏的小内存，而用于管理这些内存的元信息也被切成了小块。

不同平台和架构的二维数组大小可能完全不同，如果我们的 Go 语言服务在 Linux 的 x86-64 架构上运行，二维数组的一维大小会是 1，而二维大小是 4,194,304，因为每一个指针占用 8 字节的内存空间，所以元信息的总大小为 32MB。由于每个 [`runtime.heapArena`](https://draveness.me/golang/tree/runtime.heapArena) 都会管理 64MB 的内存，整个堆区最多可以管理 256TB 的内存，这比之前的 512GB 多好几个数量级。

Go 语言团队在 1.11 版本中通过以下几个提交将线性内存变成稀疏内存，移除了 512GB 的内存上限以及堆区内存连续性的假设：

- [runtime: use sparse mappings for the heap](https://github.com/golang/go/commit/2b415549b813ba36caafa34fc34d72e47ee8335c)
- [runtime: fix various contiguous bitmap assumptions](https://github.com/golang/go/commit/f61057c497e9ccb88dae093778d97aeee941af13)
- [runtime: make the heap bitmap sparse](https://github.com/golang/go/commit/c0392d2e7fbdcd38aafb959e94daf6bbafe2e4e9)
- [runtime: abstract remaining mheap.spans access](https://github.com/golang/go/commit/0de5324d61ba6d4c362f9fa76b6522e28155c83d)
- [runtime: make span map sparse](https://github.com/golang/go/commit/d6e821858157b7cb4ece22fcc1a5c8604478ebaa)
- [runtime: eliminate most uses of mheap_.arena_*](https://github.com/golang/go/commit/45ffeab549fa4b03b231a0872025364e13c7f7f0)
- [runtime: remove non-reserved heap logic](https://github.com/golang/go/commit/51ae88ee2f9a1063c272a497527751d786291c89)
- [runtime: move comment about address space sizes to malloc.go](https://github.com/golang/go/commit/90666b8a3d5545f4295d9c2517ad607ce5d45e52)

由于内存的管理变得更加复杂，上述改动对垃圾回收稍有影响，大约会增加 1% 的垃圾回收开销，不过这也是我们为了解决已有问题必须付出的成本。

### 地址空间

因为所有的内存最终都是要从操作系统中申请的，所以 Go 语言的运行时构建了操作系统的内存管理抽象层，该抽象层将运行时管理的地址空间分成以下四种状态：

|    状态    |                             解释                             |
| :--------: | :----------------------------------------------------------: |
|   `None`   |         内存没有被保留或者映射，是地址空间的默认状态         |
| `Reserved` |        运行时持有该地址空间，但是访问该内存会导致错误        |
| `Prepared` | 内存被保留，一般没有对应的物理内存访问该片内存的行为是未定义的可以快速转换到 `Ready` 状态 |
|  `Ready`   |                        可以被安全访问                        |

每个不同的操作系统都会包含一组用于管理内存的特定方法，这些方法可以让内存地址空间在不同的状态之间转换，我们可以通过下图了解不同状态之间的转换过程：

![memory-regions-states-and-transitions](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/2020-02-29-15829868066474-memory-regions-states-and-transitions.png)

运行时中包含多个操作系统实现的状态转换方法，所有的实现都包含在以 `mem_` 开头的文件中，本节将介绍 Linux 操作系统对上图中方法的实现：

- [`runtime.sysAlloc`](https://draveness.me/golang/tree/runtime.sysAlloc) 会从操作系统中获取一大块可用的内存空间，可能为几百 KB 或者几 MB；
- [`runtime.sysFree`](https://draveness.me/golang/tree/runtime.sysFree) 会在程序发生内存不足（Out-of Memory，OOM）时调用并无条件地返回内存；
- [`runtime.sysReserve`](https://draveness.me/golang/tree/runtime.sysReserve) 会保留操作系统中的一片内存区域，访问这片内存会触发异常；
- [`runtime.sysMap`](https://draveness.me/golang/tree/runtime.sysMap) 保证内存区域可以快速转换至就绪状态；
- [`runtime.sysUsed`](https://draveness.me/golang/tree/runtime.sysUsed) 通知操作系统应用程序需要使用该内存区域，保证内存区域可以安全访问；
- [`runtime.sysUnused`](https://draveness.me/golang/tree/runtime.sysUnused) 通知操作系统虚拟内存对应的物理内存已经不再需要，可以重用物理内存；
- [`runtime.sysFault`](https://draveness.me/golang/tree/runtime.sysFault) 将内存区域转换成保留状态，主要用于运行时的调试；

运行时使用 Linux 提供的 `mmap`、`munmap` 和 `madvise` 等系统调用实现了操作系统的内存管理抽象层，抹平了不同操作系统的差异，为运行时提供了更加方便的接口，除了 Linux 之外，运行时还实现了 BSD、Darwin、Plan9 以及 Windows 等平台上抽象层

## 内存分配原理

[span、mcache、mcenter、mheap](https://github.com/Simin-hub/Golang-Learning-and-Interview/blob/main/Go/%E8%BF%9B%E9%98%B6/%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86.md)

![Go内存对象分类](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/1460000020338446)

小对象是在mcache中分配的，而大对象是直接从mheap分配的，从小对象的内存分配看起。

<img src="https://raw.githubusercontent.com/Simin-hub/Picture/master/img/1460000020338441" alt="Go内存管理" style="zoom:200%;" />

### 小对象分配内存

[`numSpanClasses`](https://github.com/Simin-hub/Golang-Learning-and-Interview/blob/main/Go/%E8%BF%9B%E9%98%B6/%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E5%8E%9F%E7%90%86.md#cache)为span class(总共有67 种 class，又分为包含指针和不包含指针两种，因此为134)的数量为134个，所以span class的下标是从0到133，所以上图中mcache标注了的span class是，`span class 0`到`span class 133`。每1个span class都指向1个span，也就是mcache最多有134个span。

##### 为对象寻找span

寻找span的流程如下：

1. 计算对象所需内存大小size
2. 根据size到size class映射，计算出所需的size class
3. 根据size class和对象是否包含指针计算出span class
4. 获取该span class指向的span。

以分配一个不包含指针的，大小为24Byte的对象为例。

根据映射表：

```go
// class  bytes/obj  bytes/span  objects  tail waste  max waste
//     1          8        8192     1024           0     87.50%
//     2         16        8192      512           0     43.75%
//     3         32        8192      256           0     46.88%
//     4         48        8192      170          32     31.52%
```

size class 3，它的对象大小范围是(16,32]Byte，24Byte刚好在此区间，所以此对象的size class为3。

Size class到span class的计算如下：

```go
// noscan为true代表对象不包含指针
func makeSpanClass(sizeclass uint8, noscan bool) spanClass {
    return spanClass(sizeclass<<1) | spanClass(bool2int(noscan))
}
```

所以，对应的span class为：

```go
span class = 3 << 1 | 1 = 7
```

所以该对象需要的是span class 7指向的span。

##### 从span分配对象空间

Span可以按对象大小切成很多份，这些都可以从映射表上计算出来，以size class 3对应的span为例，span大小是8KB，每个对象实际所占空间为32Byte，这个span就被分成了256块，可以根据span的起始地址计算出每个对象块的内存地址。

![Span内对象](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/1460000020338447)

随着内存的分配，span中的对象内存块，有些被占用，有些未被占用，比如上图，整体代表1个span，蓝色块代表已被占用内存，绿色块代表未被占用内存。

当分配内存时，只要快速找到第一个可用的绿色块，并计算出内存地址即可，如果需要还可以对内存块数据清零。

##### span没有空间怎么分配对象

span内的所有内存块都被占用时，没有剩余空间继续分配对象，**mcache会向mcentral申请1个span**，mcache拿到span后继续分配对象。

##### mcentral向mcache提供span

mcentral和mcache一样，都是0~133这134个span class级别，但每个级别都保存了2个span list，即2个span链表：

1. `nonempty`：**这个链表里的span，所有span都至少有1个空闲的对象空间**。这些span是mcache释放span时加入到该链表的。
2. `empty`：**这个链表里的span，所有的span都不确定里面是否有空闲的对象空间**。当一个span交给mcache的时候，就会加入到empty链表。

这2个东西名称一直有点绕，建议直接把empty理解为没有对象空间就好了。

![mcentral](https://segmentfault.com/img/remote/1460000020338448)

*实际代码中**每1个span class对应1个mcentral**，图里把所有mcentral抽象成1个整体了。*

mcache向mcentral要span时，mcentral会先从`nonempty`搜索满足条件的span，如果每找到再从`emtpy`搜索满足条件的span，然后把找到的span交给mcache。

##### mheap的span管理

mheap里保存了2棵**二叉排序树**，按span的page数量进行排序：

1. `free`：free中保存的span是**空闲并且非垃圾回收的span**。
2. `scav`：scav中保存的是**空闲并且已经垃圾回收的span**。

如果是垃圾回收导致的span释放，span会被加入到`scav`，否则加入到`free`，比如刚从OS申请的的内存也组成的Span。

![mheap](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/1460000020338449)

mheap中还有arenas，有一组heapArena组成，每一个heapArena都包含了连续的`pagesPerArena`个span，这个主要是为mheap管理span和垃圾回收服务。

mheap本身是一个全局变量，它其中的数据，也都是从OS直接申请来的内存，并不在mheap所管理的那部分内存内。

##### mcentral向mheap要span

**mcentral向mcache提供span时，如果`emtpy`里也没有符合条件的span，mcentral会向mheap申请span**。

mcentral需要向mheap提供需要的内存页数和span class级别，然后它优先从`free`中搜索可用的span，如果没有找到，会从`scav`中搜索可用的span，如果还没有找到，它会向OS申请内存，再重新搜索2棵树，必然能找到span。如果找到的span比需求的span大，则把span进行分割成2个span，其中1个刚好是需求大小，把剩下的span再加入到`free`中去，然后设置需求span的基本信息，然后交给mcentral。

##### mheap向OS申请内存

当mheap没有足够的内存时，mheap会向OS申请内存，把申请的内存页保存到span，然后把span插入到`free`树 。

在32位系统上，mheap还会预留一部分空间，当mheap没有空间时，先从预留空间申请，如果预留空间内存也没有了，才向OS申请。

### 大对象分配

大对象的分配比小对象省事多了，99%的流程与mcentral向mheap申请内存的相同，所以不重复介绍了，不同的一点在于mheap会记录一点大对象的统计信息，见`mheap.alloc_m()`。



## 栈管理

[参考](https://github.com/Simin-hub/Golang-Learning-and-Interview/blob/main/Go/%E8%BF%9B%E9%98%B6/%E6%A0%88%E7%AE%A1%E7%90%86.md)

栈区的内存一般由**编译器自动进行分配和释放**，其中存储着函数的**入参**以及**局部**变量，这些参数会随着函数的创建而创建，函数的返回而销毁。(通过 `CPU push & release`)。

## 逃逸分析

[逃逸分析](https://github.com/Simin-hub/Golang-Learning-and-Interview/blob/main/Go/%E8%BF%9B%E9%98%B6/%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90.md)

[参考](https://www.cnblogs.com/qcrao-2018/p/10453260.html)

### 什么是内存逃逸

`golang程序变量`会携带有一组校验数据，用来证明它的整个生命周期是否在运行时完全可知。如果变量通过了这些校验，它就可以在`栈上`分配。否则就说它 `逃逸` 了，必须在`堆上分配`。

> 在一段程序中，每一个函数都会有自己的内存区域存放自己的局部变量、返回地址等，这些内存会由编译器在栈中进行分配，每一个函数都会分配一个栈桢，在函数运行结束后进行销毁，但是有些变量我们想在函数运行结束后仍然使用它，那么就需要把这个变量在堆上分配，这种从"栈"上逃逸到"堆"上的现象就成为内存逃逸。

### 为什么需要逃逸分析

因为对一个程序来说，**使用栈内存还是堆内存他们的效率差别很大**。

#### 栈内存：

1. **操作系统管理内存的分配和释放**，不用golang的垃圾回收操心
2. 内存的存储结构类似于数据结构中的栈，**读写位置都在栈顶**。
3. **栈内存可有效放入cpu的缓存**，这样读写效率就比实际内存中少1-2个数量级的时间。
4. 缺点就是不会太大（linux 系统可以使用`ulimit -s`查看，目前我的实验环境是ubuntu20.04,栈内存的最大值是8M）
5. 一般局部变量，函数参数都会放在栈内存中（罗嗦一句：为什么这里使用一般呢，在C语言中，我可以告诉你是一定，但是golang里面，如果你返回了局部变量的地址，这个时候局部变量就会放在堆了，因为这个局部变量逃出了函数的作用域）。

#### 堆内存：

1. **需要程序自己进行管理，可以是手动申请释放**，如C/C++;也可以是语言提供的垃圾回收机制释放的
2. 堆内存的存储结构和数据结构中的堆没有半毛钱关系，它是用链表结构实现的
3. 堆内存申请还要去内存中寻找，还会**产生内存碎片**
4. **堆内存的优点就是申请内存大小可以很**大-----64位系统：理论最大能支持2147483648GB，实际上取决于你用的系统上没有被使用的的内存大小 ;32位系统：最大2^32 ，一个进程能够使用的一共4GB的内存，还需要留一部分给栈内存，代码段，数据段，实际能申请的最大约3.5G
5. 未知大小的变量，未知作用域的变量等。

C/C++中动态分配的内存需要我们手动释放，导致猿们平时在写程序时，如履薄冰。这样做有他的好处：**程序员可以完全掌控内存。但是缺点也是很多的：经常出现忘记释放内存，导致内存泄露**。所以，很多现代语言都加上了垃圾回收机制。

Go的垃圾回收，让堆和栈对程序员保持透明。真正解放了程序员的双手，让他们可以专注于业务，“高效”地完成代码编写。把那些内存管理的复杂机制交给编译器，而程序员可以去享受生活。

`逃逸分析`这种“骚操作”**把变量合理地分配到它该去的地方**，“找准自己的位置”。即使你是用new申请到的内存，如果我发现你竟然在退出函数后没有用了，那么就把你丢到栈上，毕竟栈上的内存分配比堆上快很多；反之，即使你表面上只是一个普通的变量，但是经过逃逸分析后发现在退出函数之后还有其他地方在引用，那我就把你分配到堆上。真正地做到“按需分配”，提前实现共产主义！

如果变量都分配到堆上，堆不像栈可以自动清理。它会引起Go频繁地进行垃圾回收，而垃圾回收会占用比较大的系统开销（占用CPU容量的25%）。

> 堆和栈相比，**堆适合不可预知大小的内存分配**。但是为此付出的代价是分配速度较慢，而且会形成内存碎片。栈内存分配则会非常快。栈分配内存只需要两个CPU指令：“PUSH”和“RELEASSE”，分配和释放；而堆分配内存首先需要去找到一块大小合适的内存块，之后要通过垃圾回收才能释放。

#### 总结

根据堆和栈各自的优缺点后，逃逸分析存在的目的如下：

1. 区分对象使用堆栈内存，栈内存的对象不管了,**减轻垃圾回收(gc)的压力**
2. **减少内存碎片的产生**。
3. **减轻分配堆内存的开销**，提高程序的运行速度。

**通过逃逸分析，可以尽量把那些不需要分配到堆上的变量直接分配到栈上，堆上的变量少了，会减轻分配堆内存的开销，同时也会减少gc的压力，提高程序的运行速度。**

### 逃逸分析是怎么完成的

Go逃逸分析最基本的原则是：**如果一个函数返回对一个变量的引用，那么它就会发生逃逸**。

简单来说，编译器会分析代码的特征和代码生命周期，Go中的变量只有在编译器可以证明在函数返回后不会再被引用的，才分配到栈上，其他情况下都是分配到堆上。

Go语言里没有一个关键字或者函数可以直接让变量被编译器分配到堆上，相反，编译器通过分析代码来决定将变量分配到何处。

对一个变量取地址，可能会被分配到堆上。但是编译器进行逃逸分析后，如果考察到在函数返回后，此变量不会被引用，那么还是会被分配到栈上。套个取址符，就想骗补助？Too young！

简单来说，编译器会根据变量是否被外部引用来决定是否逃逸：

> 1. 如果函数外部没有引用，则优先放到栈中；
> 2. 如果函数外部存在引用，则必定放到堆中；

针对第一条，**可能放到堆上的情形：定义了一个很大的数组，需要申请的内存过大，超过了栈的存储能力**。

### **内存分配过程分析**

本部分，将以代码的形式，分别介绍栈内存分配、指针作为参数情况下的栈内存分配、指针作为返回值情况下的栈内存分配并逐步引出逃逸分析和几个内存逃逸的基本原则。

正文开始，Talk is cheap，show me the code。

#### **栈内存分配**

我将以一段简单的代码作为示例，分析这段代码的内存分配过程。

```javascript
package main
import "fmt"
func main() {  n := 4  n2 := square(n)  fmt.Println(n2)}
func square(n int) int{  return n * n}
```

代码的功能很简单，一个 main 函数作为程序入口，定义了一个变量n，定义了另一个函数 squire ，返回乘方操作后的 int 值。最后，将返回的值打印到控制台。程序输出为16。

下面开始逐行进行分析，解析调用时，go 运行时是如何对内存进行分配的。

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/479e83aa67b17d920bd71f6625afe1c9.webp)

当代码运行到第6行，进入 main 函数时，会在栈上创建一个 Stack frame，存放**本函数中的变量信息。包括函数名称，变量**等。

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/h4jok0khik.png)

当代码运行到第7行时，go 会在栈中压入一个新的 Stack Frame，用于存放调用 square 函数的信息；包括函数名、变量 n 的值等。此时，计算4 * 4 的值，并返回。

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/e595bc8e8421e68646c147ea1cb411ab.webp)

当 square 函数调用完成，返回16到 main 函数后，将16赋值给 n2变量。注意，**原来的 stack frame 并不会被 go 清理掉，而是如栈左侧的箭头所示，被标记为不合法**。上图夹在红色箭头和绿色箭头之间的横线可以理解为 go 汇编代码中的 SP 栈寄存器的值，当程序申请或释放栈内存时，只需要修改 SP 寄存器的值，这种栈内存分配方式省掉了清理栈内存空间的耗时。



![img](https://ask.qcloudimg.com/developer-images/article/5469577/m6ls2qtdbl.png)

接下来，调用 fmt.Println 时，SP 寄存器的值会进一步增加，覆盖掉原来 square 函数的 stack frame，完成 print 后，程序正常退出。

#### **指针作为参数情况下的栈内存分配**

还是同样的过程，看如下这段代码。

```javascript
package main
import "fmt"
func main() {  n := 4  increase(&n)  fmt.Println(n)}
func increase(i *int) {  *i++}
```

main 作为程序入口，声明了一个变量 n，赋值为4。声明了一个函数  increase，使用一个 int 类型的指针 `i` 作为参数，increase 函数内，对指针 `i` 对应的值进行自增操作。最后 main 函数中打印了 n 的值。程序输出为5。

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/7snaopjz26.png)

当程序运行到 main 函数的第6行时，go 在栈上分配了一个 stack frame ，对变量 n 进行了赋值，n 在内存中对应的地址为0xc0008771，此时程序将继续向下执行，调用 increase 函数。

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/nzbfzfdkup.png)

这时，increase 函数对应的 stack fream 被创建，i 被赋值为变量 n对应的地址值0xc0008771，然后进行自增操作。

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/u14njxdglz.png)

当 increase 函数运行结束后，SP 寄存器会上移，将之前分配的 stack freme 标记为不合法。此时，程序运行正常，并没有因为 SP 寄存器的改动而影响程序的正确性，内存中的值也被正确的修改了。

#### **指针作为返回值情况下的栈内存分配**

文章之前的部分分别介绍了普通变量作为参数和将指针作为参数情况下的栈内存使用，本部分来介绍将**指针作为返回值**，返回给调用方的情况下，内存是如何分配的，并引出内存逃逸相关内容。来看这段代码：

```javascript
package main
import "fmt"
func main() {  n := initValue()  fmt.Println(*n/2)}
func initValue() *int {  i := 4  return &i}
```

main 函数中，调用了 `initValue` 函数，该函数返回一个 int 指针并赋值给 n，指针对应的值为4。随后，main 函数调用 fmt.Println 打印了指针 n / 2对应的值。程序输出为2。

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/945gf1ih2a.png)

程序调用 `initValue` 后，将 `i` 的地址赋值给变量 n 。注意，如果这时，变量 `i` 的位置在栈上，则可能会随时被覆盖掉。

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/8ydk3bi2lv.png)

在调用 fmt.Println 时，Stack Frame 会被重新创建，变量 i 被赋值为*n/2也就是2，会覆盖掉原来 n 所指向的变量值。这会导致及其严重的问题。在面对 sharing up 场景时，go 通常会将变量分配到堆中，如下图所示：

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/16ab1617ecd4832e038e07e9a612fd69.webp)

通过上面的分析，可以看到在面对被调用的函数返回一个指针类型时将对象分配到栈上会带来严重的问题，因此 Go 将变量分配到了堆上。这种分配方式保证了程序的安全性，但也不可避免的增加了堆内存创建，并需要在将来的某个时候，需要 GC 将不再使用的内存清理掉。

### **内存分配原则**

经过上述分析，可以简单的归纳几条原则。

- Sharing down typically stays on the stack 在调用方创建的变量或对象，**通过参数的形式传递给被调用函数**，这时，在调用方创建的内存空间通常在栈上。这种在调用方创建内存，在被调用方使用该内存的“内存共享”方式，称之为 Sharing down。
- Sharing up typically escapes to the heap 在被调用函数内创建的对象，**以指针的形式返回给调用方的情况下**，通常，创建的内存空间在堆上。这种在被调用方创建，在调用方使用的“内存共享”方式，称之为 Sharing up。
- Only the compiler knows 之所以上面两条原则都加了通常，因为具体的分配方式，是由编译器确定的，一些编译器后端优化，可能会突破这两个原则，因此，具体的分配逻辑，只有编译器（或开发编译器的人）知道。

### 逃逸总结

- 栈上分配内存比在堆中分配内存有更高的效率
- 栈上分配的内存不需要GC处理
- 堆上分配的内存使用完毕会交给GC处理
- 逃逸分析目的是决定内分配地址是栈还是堆
- 逃逸分析在编译阶段完成
- 逃逸判定的规则
  - 假如函数外部没有引用，则优先放到栈中；
  - 假如函数外部存在引用，则放到堆中；
  - 假如栈上容纳不下，则会放到堆上

- 逃逸场景
  - **指针逃逸**（函数返回局部变量的指针）
  - **栈空间不足逃逸**（申请大对象造成的逃逸）
  - **申请可变长空间造成的逃逸**
  - **返回局部引用的 slice、map 造成的逃逸**
  - 动态类型逃逸（函数参数为interface类型）
  - 闭包引用对象逃逸
  - **返回函数造成的逃逸**

### 如何确定逃逸

```
// main_pointer.go
package main

import "fmt"

type Demo struct {
	name string
}

func createDemo(name string) *Demo {
	d := new(Demo) // 局部变量 d 逃逸到堆
	d.name = name
	return d
}

func main() {
	demo := createDemo("demo")
	fmt.Println(demo)
}
```

这个例子中，函数 `createDemo` 的局部变量 `d` 发生了逃逸。d 作为返回值，在 main 函数中继续使用，因此 d 指向的内存不能够分配在栈上，随着函数结束而回收，只能分配在堆上。

编译时可以借助选项 `-gcflags=-m`，查看变量逃逸的情况：

```
$ go build -gcflags=-m main_pointer.go 
./main_pointer.go:10:6: can inline createDemo
./main_pointer.go:17:20: inlining call to createDemo
./main_pointer.go:18:13: inlining call to fmt.Println
./main_pointer.go:10:17: leaking param: name
./main_pointer.go:11:10: new(Demo) escapes to heap
./main_pointer.go:17:20: new(Demo) escapes to heap
./main_pointer.go:18:13: demo escapes to heap
./main_pointer.go:18:13: main []interface {} literal does not escape
./main_pointer.go:18:13: io.Writer(os.Stdout) escapes to heap
<autogenerated>:1: (*File).close .this does not escape
```

`new(Demo) escapes to heap` 即表示 `new(Demo)` 逃逸到堆上了。

## 垃圾回收GC

[GC原理](https://github.com/Simin-hub/Golang-Learning-and-Interview/blob/main/Go/%E8%BF%9B%E9%98%B6/GC.md)



如果只申请和分配内存，内存终将枯竭，Go使用垃圾回收收集不再使用的span，调用`mspan.scavenge()`把span释放给OS（并非真释放，只是告诉OS这片内存的信息无用了，如果你需要的话，收回去好了），然后交给mheap，mheap对span进行span的合并，把合并后的span加入`scav`树中，等待再分配内存时，由mheap进行内存再分配，Go垃圾回收也是一个很强的主题，计划后面单独写一篇文章介绍。

现在我们关注一下，Go程序是怎么把内存释放给操作系统的？

释放内存的函数是`sysUnused`，它会被`mspan.scavenge()`调用:

```go
// MAC下的实现
func sysUnused(v unsafe.Pointer, n uintptr) {
    // MADV_FREE_REUSABLE is like MADV_FREE except it also propagates
    // accounting information about the process to task_info.
    madvise(v, n, _MADV_FREE_REUSABLE)
}
```

注释说`_MADV_FREE_REUSABLE`与`MADV_FREE`的功能类似，它的功能是给内核提供一个建议：**这个内存地址区间的内存已经不再使用，可以回收。但内核是否回收，以及什么时候回收，这就是内核的事情了**。如果内核真把这片内存回收了，当Go程序再使用这个地址时，内核会重新进行虚拟地址到物理地址的映射。所以在内存充足的情况下，内核也没有必要立刻回收内存。



## 内存泄露

[参考](https://github.com/Simin-hub/Learning-Programming/blob/main/Go/%E8%BF%9B%E9%98%B6/%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F.md#%E5%86%85%E5%AD%98%E6%B3%84%E6%BC%8F)

### 定义

内存泄漏（Memory Leak）是指程序中**已动态分配的堆内存由于某种原因程序未释放或无法释放**，造成系统内存的浪费，导致程序运行速度减慢甚至系统崩溃等严重后果。

内存泄漏，**最可能的影响就是内存申请失败**。但实际上操作系统更聪明，结合系统整体负载情况，它会为每个进程计算一个 oom_score，并在内存资源紧张时选择一个合适的进程杀死并回收内存资源。所以，**内存泄露的最终结果，大概率会被操作系统 kill**，通常进程挂掉后，确认其是否是因为 oom 问题被 kill，可以通过查看 `/proc/messages` 来确认是否有对应日志。有的话，那就坐实了 oom killed（但是被 oom killed 的进程不一定意味着存在内存泄露）。

### **内存泄漏场景**

实际情况是，编码中确实存在一些场景，会造成“**临时性**”或者“**永久性**”内存泄露，是需要开发人员加深对编程语言设计实现、编译器特性的理解之后才能优化掉的，see：**[go memory leaking scenarios](https://go101.org/article/memory-leaking.html)**。

即便是临时性内存泄漏，考虑到有限的内存资源、内存申请大小、申请频率、释放频率因素，也会造成进程 oom killed 的结果。所以，开发人员对待每一行代码还是要心存敬畏，对待内存资源也还是要慎重。

常见的内存泄露场景

简单归纳一下，还是“临时性”内存泄露和“永久性”内存泄露：

- 临时性泄露，指的是**该释放的内存资源没有及时释放**，对应的内存资源仍然有机会在更晚些时候被释放，即便如此在内存资源紧张情况下，也会是个问题。这类主要是 **string、slice 底层 buffer 的错误共享，导致无用数据对象无法及时释放，或者 defer 函数导致的资源没有及时释放**。
- **永久性泄露**，指的是**在进程后续生命周期内，泄露的内存都没有机会回收**，如 **goroutine** 内部预期之外的**`for-loop`或者`chan select-case`导致的无法退出的情况**，导致协程栈及引用内存永久泄露问题。

### **内存泄露排查**

内存泄漏（Memory Leak）是指程序中**已动态分配的堆内存由于某种原因程序未释放或无法释放**，造成系统内存的浪费，导致程序运行速度减慢甚至系统崩溃等严重后果。

初步怀疑程序存在内存泄露问题，可能是因为进程 oom killed，或者是因为 top 显示内存占用持续增加无法稳定在一个合理值。不管如何发现的，明确存在这一问题之后，就需要及时选择合适的方法定位到问题的根源，并及时修复。

#### **借助 pprof 排查**

##### **pprof 类型**

go 提供了 pprof 工具方便对运行中的 go 程序进行采样分析，支持对多种类型的采样分析：

- goroutine - stack traces of all current goroutines
- heap - a sampling of all heap allocations
- threadcreate - stack traces that led to the creation of new OS threads
- block - stack traces that led to blocking on synchronization primitives
- mutex - stack traces of holders of contended mutexes
- profile - cpu profile
- trace - allows collecting all the profiles for a certain duration

##### **pprof 操作**

go tool pprof 可以收集两类采样数据：

- in_use，收集进程当前仍在使用中的内存；

- alloc，收集自进程启动后的总的内存分配情况，包括已经释放掉的内存；

go tool pprof 展示采样信息时，申请内存以“**红色**”显示，释放内存以“**绿色**”显示。

允许采样完成后打开一个浏览器页面（通过 ip:port 访问），交互式地查看采样结果信息，例如 callgraph、flamegraph、top 信息。

#### **借助 bcc 排查**

##### **pprof：这个我干不了**

pprof 对于分析纯 go 程序是非常有帮助的，但是对于 cgo 有点无能为力，cgo 部分的代码已经跳出了 go 内存分配器的范围，采样也没用，那 cgo 部分出现内存泄露该如何排查呢？

- 要确定进程是否出现了内存泄露，可以观察进程运行期间的内存占用情况，如借助 top、free -m，或者其他运维平台的监控系统，一般 k8s 都集成了 prometheus 对容器运行情况进行了监视。如果内存占用随着时间延长一直增长，没有在合理的内存占用值附近稳定下来，或者已经出现了 oom killed、容器重启的问题出现，则可以初步判定进程存在内存泄露；
- 继续借助 pprof 工具排查 go 程序，如果 pprof 可以排查出明显的内存泄露问题，则内存泄漏问题可能是纯 go 部分代码引起，采用前面描述的分析、定位方法来解决；
- 如果 pprof 工具采样之后，没有发现明显的内存泄露的端倪，且程序中存在 cgo 部分的代码，怀疑 cgo 部分的代码存在内存泄露，此时则需借助其他手段（pprof 无能为力了）来进一步分析 cgo 部分的可能异常；

##### **BCC (eBPF toolkit)：测量、性能分析**

如何基于 eBPF 写 eBPF program 来完成希望的测量、分析呢，see **[iovisor/bcc](https://github.com/iovisor/bcc)**：

BCC 算是一个开发套件，在它基础上开发 eBPF program 会更简单，该仓库内当前已经拥有了非常丰富的测量、分析工具，工具之丰富，只差我能不能全部掌握了，也想成为像**[Brendan Gregg](http://www.brendangregg.com/blog/index.html)**一样的性能分析专家。

#### **借助 pmap/gdb 排查**

这也是一种比较通用的排查方式，在排查内存泄露问题时，根据实际情况（比如环境问题无法安装 go，bcc 之类分析工具等等）甚至可考虑先通过 pmap 这种方式来分析一下。总之，灵活选择合适的方式吧。

#### **其他方式**

内存泄露的排查方式有很多，工具也有很多，比如比较有名的 valgrind，但是我测试过程中，valgrind 没有像 bcc 那样精确地定位到内存泄露的位置，可能是我的使用方式有问题。see **[debugging cgo memory leaks](https://www.youtube.com/watch?v=jiSWxpcuGPw)**，感兴趣的可以自己研究下。这里就不再展开了。

## 内存对齐

[参考](https://geektutu.com/post/hpg-struct-alignment.html)

### 1 如何计算结构体占用的空间

在 Go 语言中，我们可以使用 `unsafe.Sizeof` 计算出一个数据类型实例需要占用的字节数。

```
package main

import (
	"fmt"
	"unsafe"
)

type Args struct {
    num1 int
    num2 int
}

type Flag struct {
    num1 int16
    num2 int32
}

func main() {
    fmt.Println(unsafe.Sizeof(Args{}))
    fmt.Println(unsafe.Sizeof(Flag{}))
}
```

运行上面的例子将会输出：

```
$ go run main.go
16
8
```

- `Args` 由 2 个 int 类型的字段构成，在 64位机器上，一个 int 占 8 字节，因此存储一个 `Args` 实例需要 16 字节。
- `Flag` 由一个 int32 和 一个 int16 的字段构成，成员变量占据的字节数为 4+2 = 6，但是 `unsafe.Sizeof` 返回的结果为 8 字节，多出来的 2 字节是内存对齐的结果。

因此，一个结构体实例所占据的空间等于各字段占据空间之和，再加上内存对齐的空间大小。

### 2 内存对齐

#### 2.1 为什么需要内存对齐

**CPU 访问内存时，并不是逐个字节访问，而是以字长（word size）为单位访问**。比如 32 位的 CPU ，字长为 4 字节，那么 CPU 访问内存的单位也是 4 字节。

这么设计的目的，是减少 CPU 访问内存的次数，加大 CPU 访问内存的吞吐量。比如同样读取 8 个字节的数据，一次读取 4 个字节那么只需要读取 2 次。

CPU 始终以字长访问内存，如果不进行内存对齐，很可能增加 CPU 访问内存的次数，例如：

![memory alignment](https://geektutu.com/post/hpg-struct-alignment/memory_alignment.png)

变量 a、b 各占据 3 字节的空间，内存对齐后，a、b 占据 4 字节空间，CPU 读取 b 变量的值只需要进行一次内存访问。如果不进行内存对齐，CPU 读取 b 变量的值需要进行 2 次内存访问。第一次访问得到 b 变量的第 1 个字节，第二次访问得到 b 变量的后两个字节。

从这个例子中也可以看到，内存对齐对实现变量的原子性操作也是有好处的，每次内存访问是原子的，如果变量的大小不超过字长，那么内存对齐后，对该变量的访问就是原子的，这个特性在并发场景下至关重要。

简言之：**合理的内存对齐可以提高内存读写的性能，并且便于实现变量操作的原子性**。

> 参考 [Purpose of memory alignment](https://stackoverflow.com/questions/381244/purpose-of-memory-alignment)



#### 2.2 unsafe.Alignof

在上面的例子中，`Flag{}` 两个字段占据了 6 个字节，但是最终对齐后的结果是 8 字节。Go 语言中内存对齐需要遵循什么规律呢？

`unsafe` 标准库提供了 `Alignof` 方法，可以返回一个类型的对齐值，也可以叫做对齐系数或者对齐倍数。例如：

```
unsafe.Alignof(Args{}) // 8
unsafe.Alignof(Flag{}) // 4
```

- `Args{}` 的对齐倍数是 8，`Args{}` 两个字段占据 16 字节，是 8 的倍数，无需占据额外的空间对齐。
- `Flag{}` 的对齐倍数是 4，因此 `Flag{}` 占据的空间必须是 4 的倍数，因此，6 内存对齐后是 8 字节。

#### 2.3 对齐保证(align guarantee)

Go 官方文档 [Size and alignment guarantees - golang spec](https://golang.org/ref/spec#Size_and_alignment_guarantees) 描述了 `unsafe.Alignof` 的规则。

> 1. For a variable x of any type: unsafe.Alignof(x) is at least 1.
> 2. For a variable x of struct type: unsafe.Alignof(x) is the largest of all the values unsafe.Alignof(x.f) for each field f of x, but at least 1.
> 3. For a variable x of array type: unsafe.Alignof(x) is the same as the alignment of a variable of the array’s element type.

- 对于任意类型的变量 x ，`unsafe.Alignof(x)` 至少为 1。
- 对于 struct 结构体类型的变量 x，计算 x 每一个字段 f 的 `unsafe.Alignof(x.f)`，`unsafe.Alignof(x)` 等于其中的最大值。
- 对于 array 数组类型的变量 x，`unsafe.Alignof(x)` 等于构成数组的元素类型的对齐倍数。

> A struct or array type has size zero if it contains no fields (or elements, respectively) that have a size greater than zero. Two distinct zero-size variables may have the same address in memory.

没有任何字段的空 struct{} 和没有任何元素的 array 占据的内存空间大小为 0，不同的大小为 0 的变量可能指向同一块地址。

### 3 struct 内存对齐的技巧

#### 3.1 合理布局减少内存占用

假设一个 struct 包含三个字段，`a int8`、`b int16`、`c int64`，顺序会对 struct 的大小产生影响吗？我们来做一个实验：

```
type demo1 struct {
	a int8
	b int16
	c int32
}

type demo2 struct {
	a int8
	c int32
	b int16
}

func main() {
	fmt.Println(unsafe.Sizeof(demo1{})) // 8
	fmt.Println(unsafe.Sizeof(demo2{})) // 12
}
```

答案是会产生影响。每个字段按照自身的对齐倍数来确定在内存中的偏移量，字段排列顺序不同，上一个字段因偏移而浪费的大小也不同。

接下来逐个分析，首先是 demo1：

- a 是第一个字段，默认是已经对齐的，从第 0 个位置开始占据 1 字节。
- b 是第二个字段，对齐倍数为 2，因此，必须空出 1 个字节，偏移量才是 2 的倍数，从第 2 个位置开始占据 2 字节。
- c 是第三个字段，对齐倍数为 4，此时，内存已经是对齐的，从第 4 个位置开始占据 4 字节即可。

因此 demo1 的内存占用为 8 字节。

其实是 demo2：

- a 是第一个字段，默认是已经对齐的，从第 0 个位置开始占据 1 字节。
- c 是第二个字段，对齐倍数为 4，因此，必须空出 3 个字节，偏移量才是 4 的倍数，从第 4 个位置开始占据 4 字节。
- b 是第三个字段，对齐倍数为 2，从第 8 个位置开始占据 2 字节。

demo2 的对齐倍数由 c 的对齐倍数决定，也是 4，因此，demo2 的内存占用为 12 字节。

![memory alignment](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/memory_alignment_order.png)

因此，在对内存特别敏感的结构体的设计上，我们可以通过调整字段的顺序，减少内存的占用。

#### 3.2 空 struct{} 的对齐

**空 `struct{}` 大小为 0，作为其他 struct 的字段时，一般不需要内存对齐。但是有一种情况除外：即当 `struct{}` 作为结构体最后一个字段时，需要内存对齐。**因为如果有指针指向该字段, 返回的地址将在结构体之外，如果此指针一直存活不释放对应的内存，就会有内存泄露的问题（该内存不因结构体释放而释放）。

因此，当 `struct{}` 作为其他 struct 最后一个字段时，需要填充额外的内存保证安全。我们做个试验，验证下这种情况。

```
type demo3 struct {
	c int32
	a struct{}
}

type demo4 struct {
	a struct{}
	c int32
}

func main() {
	fmt.Println(unsafe.Sizeof(demo3{})) // 8
	fmt.Println(unsafe.Sizeof(demo4{})) // 4
}
```

可以看到，`demo4{}` 的大小为 4 字节，与字段 c 占据空间一致，而 `demo3{}` 的大小为 8 字节，即额外填充了 4 字节的空间。

## 相关面试题

### 什么样的行为会导致很多内存碎片，内存碎片为什么会导致GC的压力增加和性能下降

频繁申请很小的内存空间，容易出现大量内存碎片，增大操作系统整理碎片的压力
