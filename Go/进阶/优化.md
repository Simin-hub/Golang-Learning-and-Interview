# 优化

## 性能优化

性能优化的目的是让程序更好、更快地运行，但是它不是必要的，这一点一定要记住。所以在程序开始的时候，你不必刻意追求性能优化，先大胆地写你的代码就好了，**写正确的代码是性能优化的前提**。

### pprof

[参考](https://github.com/Simin-hub/Learning-Programming/blob/main/Go/package/pprof.md)

#### PProf 是什么

在 Go 语言中，PProf 是**用于可视化和分析性能分析数据的工具**，PProf 以 profile.proto 读取分析样本的集合，并生成报告以可视化并帮助分析数据（支持文本和图形报告）。

而刚刚提到的 profile.proto 是一个 Protobuf v3 的描述文件，它描述了一组 callstack 和 symbolization 信息， 作用是统计分析的一组采样的调用栈，是很常见的 stacktrace 配置文件格式。

#### 有哪几种采样方式

- runtime/pprof：采集程序（非 Server）的指定区块的运行数据进行分析。
- net/http/pprof：基于 HTTP Server 运行，并且可以采集运行时数据进行分析。
- go test：通过运行测试用例，并指定所需标识来进行采集。

#### 支持什么使用模式

- Report generation：报告生成。
- Interactive terminal use：交互式终端使用。
- Web interface：Web 界面。

#### 可以做什么

- CPU Profiling：**CPU 分析**，按照一定的频率采集所监听的应用程序 CPU（含寄存器）的使用情况，可确定应用程序在主动消耗 CPU 周期时花费时间的位置。
- Memory Profiling：**内存分析**，在应用程序进行堆分配时记录堆栈跟踪，用于监视当前和历史内存使用情况，以及检查内存泄漏。
- Block Profiling：**阻塞分析**，记录 Goroutine 阻塞等待同步（包括定时器通道）的位置，默认不开启，需要调用 `runtime.SetBlockProfileRate` 进行设置。
- Mutex Profiling：**互斥锁分析**，报告互斥锁的竞争情况，默认不开启，需要调用 `runtime.SetMutexProfileFraction` 进行设置。
- Goroutine Profiling： **Goroutine 分析**，可以**对当前应用程序正在运行的 Goroutine 进行堆栈跟踪和分析**。这项功能在实际排查中会经常用到，因为很多问题出现时的表象就是 Goroutine 暴增，而这时候我们要做的事情之一就是查看应用程序中的 Goroutine 正在做什么事情，因为什么阻塞了，然后再进行下一步。

### trace

[参考](https://github.com/Simin-hub/Learning-Programming/blob/main/Go/package/trace.md)

原理是：**监听 Go 运行时的一些特定的事件**，如：

1. goroutine的创建、开始和结束。
2. 阻塞/解锁goroutine的一些事件（系统调用，channel，锁）
3. 网络I/O相关事件
4. 系统调用
5. 垃圾回收

追踪器会原原本本地收集这些信息，不做任何聚合或者抽样操作。对于负载高的应用来说，就可能会生成一个比较大的文件，该文件后面可以通过 `go tool trace` 命令来进行解析。

在引入执行trace程序之前，已经有了pprof内存和CPU分析器，那么为什么它还会被添加到官方的工具链中呢？虽然CPU分析器做了一件很好的工作，告诉你什么函数占用了最多的CPU时间，但它**并不能帮助你确定是什么阻止了goroutine运行，或者在可用的OS线程上如何调度goroutines**。这正是跟踪器真正起作用的地方。trace[设计文档](https://docs.google.com/document/u/1/d/1FP5apqzBgr7ahCCgFO-yoVhk4YZrNIDNf9RybngBc14/pub)很好地解释了跟踪程序背后的动机以及它是如何被设计和工作的。

有时候单单使用 pprof 还不一定足够完整观查并解决问题，因为在真实的程序中还包含许多的隐藏动作，例如 Goroutine 在执行时会做哪些操作？执行/阻塞了多长时间？在什么时候阻止？在哪里被阻止的？谁又锁/解锁了它们？GC 是怎么影响到 Goroutine 的执行的？这些东西用 pprof 是很难分析出来的，但如果你又想知道上述的答案的话，你可以用本章节的主角 `go tool trace` 来打开新世界的大门。

#### trace 和 pprof 的区别

**trace 和 pprof 的区别在于两者关注的维度不同，后者更关注代码栈层面，而 trace 更关注于 latency（延迟）**。

比如说一个请求在客户端观察从发送到完成经过了 5s，做 profile 可能发现这个请求的 CPU 时间只有 2s，那剩下的 3s 就不是很清楚了， **profile 更侧重的是我们代码执行了多久**，至于其他的，例如：网络 IO，系统调用，Goroutine 调度，GC 时间等，很难反映出来。这是就应该使用 trace 了。

### 基准测试

[参考](https://learn.lianglianglee.com/%E4%B8%93%E6%A0%8F/22%20%E8%AE%B2%E9%80%9A%E5%85%B3%20Go%20%E8%AF%AD%E8%A8%80-%E5%AE%8C/19%20%20%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%EF%BC%9AGo%20%E8%AF%AD%E8%A8%80%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E4%BB%A3%E7%A0%81%E6%A3%80%E6%9F%A5%E5%92%8C%E4%BC%98%E5%8C%96%EF%BC%9F.md)、[参考](https://juejin.cn/post/6963919796115079176)

##### 基准测试需要关注的几个前提条件：

1. **基准测试的代码文件必须以_test.go结尾**
2. **基准测试的函数必须以Benchmark开头**
3. **基准测试函数必须接受一个testing.B的指针作为唯一参数, 且基准测试函数不能有返回值**
4. b.ResetTimer是重置计时器，这样可以避免for循环之前的初始化代码的干扰
5. 如果每次循环迭代内部都有一些高成本的其他逻辑，请使用`b.StopTimer()`和`b.StartTimer()`来暂停基准计时器，更关注于我们想要测试的函数
6. 最后的for循环很重要，被测试的代码要放到循环里
7. b.N是基准测试框架提供的，表示循环的次数，具体次数是按照机器性能在默认的1s的运行次数，因为需要反复调用测试的代码，才可以评估性能。
8. 要显式地执行基准测试请使用 `-bench` 标识。 `-bench` 接收一个与待运行的基准测试名称相匹配的正则表达式，因此，如果要运行包中所有的基准测试，最常见的方法是这样写 `-bench=.`

```bash
➜  go test -bench=. -run=none
BenchmarkSprintf-12     13088973                78.8 ns/op
PASS
ok      github.com/simonhgao/testsrv       1.536s
```

在运行 go test 命令时，使用 -benchmem 这个 Flag 进行内存统计。命令如下所示：

```bash
➜ go test -bench=. -benchmem  ./ch18
```

运行这一命令就可以查看内存统计的结果了。这种通过 -benchmem 查看内存的方法**适用于所有的基准测试用例**。

##### 常用flag

- `-bench regexp`:性能测试，支持表达式对测试函数进行筛选。-bench .则是对所有的benchmark函数测试
- `-benchmem`:性能测试的时候显示测试函数的内存分配的统计信息
- `-cpu=n`：指定GOMAXPROCS
- `-count n`:运行测试和性能多少此，默认一次
- `-run regexp`:只运行特定的测试函数， 比如-run ABC只测试函数名中包含ABC的测试函数
- `-timeout t`:测试时间如果超过t, panic,默认10分钟
- `-v`:显示测试的详细信息，也会把Log、Logf方法的日志显示出来
- `-cpuprofile=$FILE` 将 CPU 分析结果写入 `$FILE`.
- `-memprofile=$FILE` 将内存分析结果写入 `$FILE`, `-memprofilerate=N` 调整记录速率为 `1/N`.
- `-blockprofile=$FILE`, 将块分析结果写入 `$FILE`.

因为默认情况下 `go test` 会运行单元测试，为了防止单元测试的输出影响我们查看基准测试的结果，可以使用`-run=`匹配单元测试方法，过滤掉单元测试的输出，我们这里使用`none`，因为我们不会创建这个名字的单元测试方法。

##### 性能对比（benchmem）：

上面那个基准测试的例子，其实是一个int类型转为string类型的例子，标准库里还有几种方法，我们看下哪种性能更加.

```go
func BenchmarkSprintf(b *testing.B){
	num:=10
	b.ResetTimer()
	for i:=0;i<b.N;i++{
		fmt.Sprintf("%d",num)
	}
}

func BenchmarkFormat(b *testing.B){
	num:=int64(10)
	b.ResetTimer()
	for i:=0;i<b.N;i++{
		strconv.FormatInt(num,10)
	}
}

func BenchmarkItoa(b *testing.B){
	num:=10
	b.ResetTimer()
	for i:=0;i<b.N;i++{
		strconv.Itoa(num)
	}
}
```

```
➜  go test -bench=. -benchmem -run=none
pkg: git.code.oa.com/simonhgao/testsrv
BenchmarkSprintf-12     13767098                78.1 ns/op            16 B/op          2 allocs/op
BenchmarkFormat-12      310182928                3.85 ns/op            0 B/op          0 allocs/op
BenchmarkItoa-12        284967086                4.15 ns/op            0 B/op          0 allocs/op
PASS
ok      github.com/simonhgao/testsrv       4.723s
```

`-benchmem`可以提供每次操作分配内存的次数，以及每次操作分配的字节数。从结果我们可以看到，性能高的两个函数，每次操作都是进行1次内存分配，而最慢的那个要分配2次；性能高的每次操作分配0字节内存，而慢的那个函数每次需要分配16字节的内存。从这个数据我们就知道它为什么这么慢了，内存分配都占用都太高。

在代码开发中，对于我们要求性能的地方，编写基准测试非常重要，这有助于我们开发出性能更好的代码。不过性能、可用性、复用性等也要有一个相对的取舍，不能为了追求性能而过度优化。

### 结合 pprof进行更形象化的分析

pprof 性能监控

```go
package bench
import "testing"
func Fib(n int) int {
    if n < 2 {
      return n
    }
    return Fib(n-1) + Fib(n-2)
}
func BenchmarkFib10(b *testing.B) {
    // run the Fib function b.N times
    for n := 0; n < b.N; n++ {
      Fib(10)
    }
}
```

可以同时看内存和CPU分析

```csharp
go test -bench=. -benchmem -memprofile memprofile.out -cpuprofile profile.out
```

然后就可以用输出的文件使用pprof(进入pprof环境)

```go
➜ go tool pprof profile.out
Type: cpu
Time: May 19, 2021 at 3:26pm (CST)
Duration: 1.56s, Total samples = 1.33s (85.34%)
Entering interactive mode (type "help" for commands, "o" for options)
(pprof) top
Showing nodes accounting for 1.33s, 100% of 1.33s total
Showing top 10 nodes out of 18
      flat  flat%   sum%        cum   cum%
     1.26s 94.74% 94.74%      1.27s 95.49%  github.com/simonhgao/testsrv.Fib
     0.05s  3.76% 98.50%      0.05s  3.76%  runtime.nanotime1
     0.01s  0.75% 99.25%      0.01s  0.75%  runtime.newstack
     0.01s  0.75%   100%      0.01s  0.75%  runtime.pthread_cond_signal
         0     0%   100%      1.27s 95.49%  github.com/simonhgao/testsrv.BenchmarkFib10
         0     0%   100%      0.01s  0.75%  runtime.findrunnable
         0     0%   100%      0.01s  0.75%  runtime.mcall
         0     0%   100%      0.05s  3.76%  runtime.mstart
         0     0%   100%      0.05s  3.76%  runtime.mstart1
         0     0%   100%      0.05s  3.76%  runtime.nanotime (inline)

```

然后你也可以用list命令检查函数需要的时间

```go
(pprof) list Fib
     1.26s      1.98s (flat, cum) 148.87% of Total
         .          .      1:package main
         .          .      2:
         .          .      3:import "testing"
         .          .      4:
     440ms      450ms      5:func Fib(n int) int {
     150ms      150ms      6:   if n < 2 {
     110ms      110ms      7:           return n
         .          .      8:   }
     560ms      1.27s      9:   return Fib(n-1) + Fib(n-2)
         .          .     10:}
         .          .     11:func BenchmarkFib10(b *testing.B) {
         .          .     12:   // run the Fib function b.N times
         .          .     13:   for n := 0; n < b.N; n++ {
         .          .     14:           Fib(10)
```

#### 图像分析

从 Go 1.11 开始, 火焰图等多种分析图被集成进入 Go 官方的 pprof 库.

```go
# This will listen on :8081 and open a browser.
# Change :8081 to a port of your choice.
$ go tool pprof -http=":8081" [binary] [profile]
```

我们可以通过上述的方法来快速的生成一个本地网址，然后查看这些分析图

比如：`go tool pprof -http=":8081" profile.out`

我们可以获得：

```go
➜  go tool pprof -http=":8081" profile.out                       
Serving web UI on http://localhost:8081
```

![在这里插入图片描述](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/393f1eaf0e074b1592199ff9cd92edf4~tplv-k3u1fbpfcp-zoom-in-crop-mark:3024:0:0:0.awebp)

如果遇到报错：Failed to execute dot. Is Graphviz installed? Error: exec: "dot": executable file not found in %PATH% （第一次一定会碰到）

是你电脑没有安装graphviz导致的： windows可以进入gvedit官网[下载地址](https://link.juejin.cn/?target=https%3A%2F%2Fwww.oschina.net%2Faction%2FGoToLink%3Furl%3Dhttps%3A%2F%2Fgraphviz.gitlab.io%2F_pages%2FDownload%2FDownload_windows.html) 下载稳定版

mac 安装比较简单， 执行下边的指令安装好后就可以使用web进行展现了

```
brew install graphviz
```

#### 火焰图：

火焰图（Flame Graph）是 Bredan Gregg 创建的一种性能分析图表，因为它的样子近似火焰而得名。

火焰图 svg 文件可以通过浏览器打开，它对于调用图的最优点是它是动态的：可以通过点击每个方块来 zoom in 分析它上面的内容。

火焰图的调用顺序从下到上，每个方块代表一个函数，它上面一层表示这个函数会调用哪些函数，方块的大小代表了占用 CPU 使用的长短。火焰图的配色并没有特殊的意义，默认的红、黄配色是为了更像火焰而已。

火焰图我们可以通过上边生成的网址[http://localhost:8081下拉菜单选择](https://link.juejin.cn/?target=http%3A%2F%2Flocalhost%3A8081%E4%B8%8B%E6%8B%89%E8%8F%9C%E5%8D%95%E9%80%89%E6%8B%A9) Flame Graph就可以了。

![在这里插入图片描述](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/183eef29b8ba4a2e99fa0d785f8c89f0~tplv-k3u1fbpfcp-zoom-in-crop-mark:3024:0:0:0.awebp) 当然pprof还有更多的使用方法，详细的可看：[tutorial](https://link.juejin.cn/?target=https%3A%2F%2Fblog.golang.org%2Fpprof)

### 逃逸分析

#### 堆分配还是栈

在比较古老的 C 语言中，内存分配是手动申请的，内存释放也需要手动完成。

- 手动控制有一个很大的**好处**就是你需要多少就申请多少，可以最大化地**利用内存**；
- 但是这种方式也有一个明显的**缺点**，就是如果忘记释放内存，就会导致**内存泄漏**。

所以，为了让程序员更好地专注于业务代码的实现，Go 语言增加了垃圾回收机制，自动地回收不再使用的内存。

Go 语言有两部分内存空间：**栈内存**和**堆内存**。

- **栈内存**由编译器自动分配和释放，开发者无法控制。栈内存一般存储函数中的局部变量、参数等，函数创建的时候，这些内存会被自动创建；函数返回的时候，这些内存会被自动释放。
- **堆内存**的生命周期比栈内存要长，如果函数返回的值还会在其他地方使用，那么这个值就会被编译器自动分配到堆上。堆内存相比栈内存来说，不能自动被编译器释放，只能通过垃圾回收器才能释放，所以栈内存效率会很高。

既然栈内存的效率更高，肯定是优先使用栈内存。那么 Go 语言是如何判断一个变量应该分配到堆上还是栈上的呢？这就需要**逃逸分析**了。下面我通过一个示例来讲解逃逸分析，代码如下：

*ch19/main.go*

```go
func newString() *string{

   s:=new(string)

   *s = "飞雪无情"

   return s

}
```

在这个示例中：

- 通过 new 函数申请了一块内存；
- 然后把它赋值给了指针变量 s；
- 最后通过 return 关键字返回。

> 小提示：以上 newString 函数是没有意义的，这里只是为了方便演示。

现在我通过逃逸分析来看下是否发生了逃逸，命令如下：

```go
➜ go build -gcflags="-m -l" ./ch19/main.go

# command-line-arguments

ch19/main.go:16:8: new(string) escapes to heap
```

在这一命令中，-m 表示打印出逃逸分析信息，-l 表示禁止内联，可以更好地观察逃逸。从以上输出结果可以看到，发生了逃逸，**也就是说指针作为函数返回值的时候**，**一定会发生逃逸**。

逃逸到堆内存的变量不能马上被回收，只能通过垃圾回收标记清除，增加了垃圾回收的压力，所以要尽可能地避免逃逸，让变量分配在栈内存上，这样函数返回时就可以回收资源，提升效率。

下面我对 newString 函数进行了避免逃逸的优化，优化后的函数代码如下：

*ch19/main.go*

```go
func newString() string{

   s:=new(string)

   *s = "飞雪无情"

   return *s

}
```

再次通过命令查看以上代码的逃逸分析，命令如下：

```go
➜ go build -gcflags="-m -l" ./ch19/main.go

# command-line-arguments

ch19/main.go:14:8: new(string) does not escape
```

通过分析结果可以看到，虽然还是声明了指针变量 s，但是函数返回的并不是指针，所以没有发生逃逸。

这就是关于指针作为函数返回逃逸的例子，那么是不是不使用指针就不会发生逃逸了呢？下面看个例子，代码如下：

```bash
fmt.Println("飞雪无情")
```

同样运行逃逸分析，你会看到如下结果：

```go
➜ go build -gcflags="-m -l" ./ch19/main.go

# command-line-arguments

ch19/main.go:13:13: ... argument does not escape

ch19/main.go:13:14: "飞雪无情" escapes to heap

ch19/main.go:17:8: new(string) does not escape
```

观察这一结果，你会发现「飞雪无情」这个字符串逃逸到了堆上，这是因为「飞雪无情」这个字符串被已经逃逸的指针变量引用，所以它也跟着逃逸了，引用代码如下：

```go
func (p *pp) printArg(arg interface{}, verb rune) {

   p.arg = arg

   //省略其他无关代码

}
```

所以**被已经逃逸的指针引用的变量也会发生逃逸**。

Go 语言中有 3 个比较特殊的类型，它们是 slice、map 和 chan，被这三种类型引用的指针也会发生逃逸，看个这样的例子：

*ch19/main.go*

```go
func main() {

   m:=map[int]*string{}

   s:="飞雪无情"

   m[0] = &s

}
```

同样运行逃逸分析，你看到的结果是：

```go
➜  gotour go build -gcflags="-m -l" ./ch19/main.go

# command-line-arguments

ch19/main.go:16:2: moved to heap: s

ch19/main.go:15:20: map[int]*string literal does not escape
```

从这一结果可以看到，变量 m 没有逃逸，反而被变量 m 引用的变量 s 逃逸到了堆上。**所以被map**、**slice 和 chan 这三种类型引用的指针一定会发生逃逸的**。

逃逸分析是判断变量是分配在堆上还是栈上的一种方法，在实际的项目中要尽可能避免逃逸，这样就不会被 GC 拖慢速度，从而提升效率。

> 小技巧：从逃逸分析来看，指针虽然可以减少内存的拷贝，但它同样会引起逃逸，所以要根据实际情况选择是否使用指针。

### 总结

1. 进行性能测试时，尽可能保持测试环境的稳定

2. 实现 benchmark 测试 • 位于 `_test.go` 文件中 • 函数名以 `Benchmark` 开头 • 参数为 `b *testing.B` • `b.ResetTimer()` 可重置定时器 • `b.StopTimer()` 暂停计时 • `b.StartTimer()` 开始计时

3. 执行 benchmark 测试 • `go test -bench .` 执行当前测试 • `-bench` 可传入正则，匹配用例 • `-cpu` 可改变 CPU 核数 • `-benchtime` 可指定执行时间或具体次数 • `-count` 可设置 benchmark 轮数 • `-benchmem` 可查看内存分配量和分配次数

4. pprof

   • `-memprofile -cpuprofile` 生成基准性能报告

   • `go tool pprof -http=":8081" [binary] [profile]` 生成本地图像分析

   使用pprof辅助优化我们的代码

   #### 优化技巧

   通过前面小节的介绍，相信你已经了解了栈内存和堆内存，以及变量什么时候会逃逸，那么在优化的时候思路就比较清晰了，因为都是基于以上原理进行的。下面我总结几个优化的小技巧：

   **第 1 个**需要介绍的技巧是**尽可能避免逃逸**，因为栈内存效率更高，还不用 GC。比如小对象的传参，array 要比 slice 效果好。

   如果避免不了逃逸，还是在堆上分配了内存，那么对于频繁的内存申请操作，我们要**学会重用内存，比如使用 sync.Pool**，这是**第 2 个**技巧。

   **第 3 个**技巧就是**选用合适的算法，达到高性能的目的**，比如空间换时间。

   > 小提示：性能优化的时候，要结合基准测试，来验证自己的优化是否有提升。

   以上是基于 GO 语言的内存管理机制总结出的 3 个方向的技巧，基于这 3 个大方向基本上可以优化出你想要的效果。除此之外，还有一些小技巧，比如要尽可能避免使用锁、并发加锁的范围要尽可能小、使用 StringBuilder 做 string 和 [ ] byte 之间的转换、defer 嵌套不要太多等等。

   最后推荐一个 Go 语言自带的性能剖析的工具 pprof，通过它你可以查看 CPU 分析、内存分析、阻塞分析、互斥锁分析，它的使用不是太复杂，你可以搜索下它的使用教程，这里就不展开介绍。

## 代码规范检查

在项目开发中，**保证代码质量和性能的手段不只有单元测试和基准测试**，**还有代码规范检查和性能优化**。

- **代码规范检查**是对单元测试的一种补充，它可以从非业务的层面检查你的代码是否还有优化的空间，比如变量是否被使用、是否是死代码等等。
- **性能优化**是通过基准测试来衡量的，这样我们才知道优化部分是否真的提升了程序的性能。

#### 什么是代码规范检查

代码规范检查，顾名思义，是从 Go 语言层面出发，依据 Go 语言的规范，对你写的代码进行的**静态扫描检查**，这种检查和你的业务无关。

比如你定义了个常量，从未使用过，虽然对代码运行并没有造成什么影响，但是这个常量是可以删除的，代码如下所示：

*ch19/main.go*

```csharp
const name = "飞雪无情"

func main() {

}
```

示例中的常量 name 其实并没有使用，所以为了节省内存你可以删除它，这种**未使用常量**的情况就可以通过代码规范检查检测出来。

再比如，你调用了一个函数，该函数返回了一个 error，但是你并没有对该 error 做判断，这种情况下，程序也可以正常编译运行。但是代码写得不严谨，因为返回的 error 被我们忽略了。代码如下所示：

*ch19/main.go*

```csharp
func main() {

   os.Mkdir("tmp",0666)

}
```

示例代码中，Mkdir 函数是有返回 error 的，但是你并没有对返回的 error 做判断，这种情况下，哪怕创建目录失败，你也不知道，因为错误被你忽略了。如果你使用代码规范检查，这类潜在的问题也会被检测出来。

以上两个例子可以帮你理解什么是代码规范检查、它有什么用。除了这两种情况，还有拼写问题、死代码、代码简化检测、命名中带下划线、冗余代码等，都可以使用代码规范检查检测出来。

#### golangci-lint

要想对代码进行检查，则需要对代码进行扫描，静态分析写的代码是否存在规范问题。

> 小提示：静态代码分析是不会运行代码的。

可用于 Go 语言代码分析的工具有很多，比如 golint、gofmt、misspell 等，如果一一引用配置，就会比较烦琐，所以通常我们不会单独地使用它们，而是使用 golangci-lint。

[golangci-lint](https://github.com/golangci/golangci-lint) 是一个**集成工具**，它集成了很多静态代码分析工具，便于我们使用。通过配置这一工具，我们可以很灵活地启用需要的代码规范检查。

如果要使用 golangci-lint，首先需要安装。因为 golangci-lint 本身就是 Go 语言编写的，所以我们可以从源代码安装它，打开终端，输入如下命令即可安装。

```kotlin
➜ go get github.com/golangci/golangci-lint/cmd/golangci-lint@v1.32.2
```

使用这一命令安装的是 v1.32.2 版本的 golangci-lint，安装完成后，在终端输入如下命令，检测是否安装成功。

```undefined
➜ golangci-lint version

golangci-lint has version v1.32.2
```

> 小提示：在 MacOS 下也可以使用 brew 来安装 golangci-lint。

好了，安装成功 golangci-lint 后，就可以使用它进行代码检查了，我以上面示例中的常量 name 和 Mkdir 函数为例，演示 golangci-lint 的使用。在终端输入如下命令回车：

```undefined
➜ golangci-lint run ch19/
```

这一示例表示要检测目录中 ch19 下的代码，运行后可以看到如下输出结果。

```go
ch19/main.go:5:7: `name` is unused (deadcode)

const name = "飞雪无情"

      ^

ch19/main.go:8:10: Error return value of `os.Mkdir` is not checked (errcheck)

        os.Mkdir("tmp",0666)
```

通过代码检测结果可以看到，我上一小节提到的两个代码规范问题都被检测出来了。检测出问题后，你就可以修复它们，让代码更加符合规范。

#### golangci-lint 配置

golangci-lint 的配置比较灵活，比如你可以自定义要启用哪些 linter。golangci-lint 默认启用的 linter，包括这些：

```undefined
deadcode - 死代码检查

errcheck - 返回错误是否使用检查

gosimple - 检查代码是否可以简化

govet - 代码可疑检查，比如格式化字符串和类型不一致

ineffassign - 检查是否有未使用的代码

staticcheck - 静态分析检查

structcheck - 查找未使用的结构体字段

typecheck - 类型检查

unused - 未使用代码检查

varcheck - 未使用的全局变量和常量检查
```

> 小提示：golangci-lint 支持的更多 linter，可以在终端中输入 golangci-lint linters 命令查看，并且可以看到每个 linter 的说明。

如果要修改默认启用的 linter，就需要对 golangci-lint 进行配置。即在项目根目录下新建一个名字为 .golangci.yml 的文件，这就是 golangci-lint 的配置文件。在运行代码规范检查的时候，golangci-lint 会自动使用它。假设我只启用 unused 检查，可以这样配置：

*.golangci.yml*

```yaml
linters:

  disable-all: true

  enable:

    - unused
```

在团队多人协作开发中，有一个固定的 golangci-lint 版本是非常重要的，这样大家就可以**基于同样的标准检查代码**。要配置 golangci-lint 使用的版本也比较简单，在配置文件中添加如下代码即可：

```yaml
service:

  golangci-lint-version: 1.32.2 # use the fixed version to not introduce new linters unexpectedly
```

此外，你还可以针对每个启用的 linter 进行配置，比如要设置拼写检测的语言为 US，可以使用如下代码设置：

```yaml
linters-settings:

  misspell:

    locale: US
```

golangci-lint 的配置比较多，你自己可以灵活配置。关于 golangci-lint 的更多配置可以参考[官方文档](https://golangci-lint.run/usage/configuration/)，这里我给出一个常用的配置，代码如下：

*.golangci.yml*

```yaml
linters-settings:

  golint:

    min-confidence: 0

  misspell:

    locale: US

linters:

  disable-all: true

  enable:

    - typecheck

    - goimports

    - misspell

    - govet

    - golint

    - ineffassign

    - gosimple

    - deadcode

    - structcheck

    - unused

    - errcheck

service:

  golangci-lint-version: 1.32.2 # use the fixed version to not introduce new linters unexpectedly
```

#### 集成 golangci-lint 到 CI

**代码检查一定要集成到 CI 流程中**，效果才会更好，这样开发者提交代码的时候，CI 就会自动检查代码，及时发现问题并进行修正。

不管你是使用 Jenkins，还是 Gitlab CI，或者 Github Action，都可以通过**Makefile**的方式运行 golangci-lint。现在我在项目根目录下创建一个 Makefile 文件，并添加如下代码：

*Makefile*

```bash
getdeps:

   @mkdir -p ${GOPATH}/bin

   @which golangci-lint 1>/dev/null || (echo "Installing golangci-lint" && go get github.com/golangci/golangci-lint/cmd/golangci-lint@v1.32.2)

lint:

   @echo "Running $@ check"

   @GO111MODULE=on ${GOPATH}/bin/golangci-lint cache clean

   @GO111MODULE=on ${GOPATH}/bin/golangci-lint run --timeout=5m --config ./.golangci.yml

verifiers: getdeps lint
```

> 小提示：关于 Makefile 的知识可以网上搜索学习一下，比较简单，这里不再进行讲述。

好了，现在你就可以把如下命令添加到你的 CI 中了，它可以帮你自动安装 golangci-lint，并检查你的代码。

```go
make verifiers
```

### 总结

这节课主要介绍了代码规范检查和性能优化两部分内容，其中代码规范检查是从工具使用的角度讲解，而性能优化可能涉及的点太多，所以是从原理的角度讲解，你明白了原理，就能更好地优化你的代码。

我认为是否进行性能优化取决于两点：**业务需求和自我驱动**。所以不要刻意地去做性能优化，尤其是不要提前做，先保证代码正确并上线，然后再根据业务需要，决定是否进行优化以及花多少时间优化。自我驱动其实是一种编码能力的体现，比如有经验的开发者在编码的时候，潜意识地就避免了逃逸，减少了内存拷贝，在高并发的场景中设计了低延迟的架构。



## 数据竞争（data race）

[参考](https://learnku.com/articles/45279)

定义：①多个线程对于同一个变量、②同时地、③进行读/写操作的现象并且④至少有一个线程进行写操作。（也就是说，如果所有线程都是只进行读操作，那么将不构成数据争用）

后果：如果发生了数据争用，读取该变量时得到的值将变得不可知，使得该多线程程序的运行结果将完全不可预测，可能直接崩溃。
如何防止：对于有可能被多个线程同时访问的变量使用排他访问控制，具体方法包括使用mutex（互斥量）和monitor（监视器），或者使用atomic变量。

### 数据竞争

要解释什么是数据竞争我们先来看一段程序：

```
package main

import "fmt"

func main() {
    fmt.Println(getNumber())
}

func getNumber() int {
    var i int
    go func() {
        i = 5
    }()

    return i

}
```

上面这段程序 `getNumber` 函数中开启了一个单独的 goroutine 设置变量 i 的值，同时在不知道开启的 goroutine 是否已经执行完成的情况下返回了 i。所以现在正在发生两个操作：

- 变量 i 的值正在被设置成 5。
- 函数 getNumber 返回了变量 i 的值。

现在，根据这两个操作中哪一个先完成，最后程序打印出来的值将是 0 或 5。

这就是为什么它被称为数据竞争：getNumber 返回的值根据操作 1 或操作 2 中的哪一个最先完成而不同。

下面的两张图描述了返回值的两种可能的情况对应的时间线：

![数据竞争--读操作先完成](https://cdn.learnku.com/uploads/images/202005/24/6964/WnGdF6UyOT.svg)

![数据竞争--写操作先完成](https://cdn.learnku.com/uploads/images/202005/24/6964/HRLPLcFDF7.svg)

你可以想象一下，每次调用代码时，代码表现出来的行为都不一样有多可怕。这就是为什么数据竞争会带来如此巨大的问题。

### 检测数据竞争

我们上面代码是一个高度简化的数据竞争示例。在较大的应用程序中，仅靠自己检查代码很难检测到数据竞争。幸运的是，Go(从 V1.1 开始) 有一个内置的数据竞争检测器，我们可以使用它来确定应用程序里潜在的数据竞争条件。

使用它非常简单，**只需在使用 Go 命令行工具时添加 -race 标志**。例如，让我们尝试使用 -race 标志来运行我们刚刚编写的程序：

```
go run -race main.go
```

执行后将输出：

```
0
==================
WARNING: DATA RACE
Write at 0x00c00001a0a8 by goroutine 6:
  main.getNumber.func1()
      /QSC/go/src/example.com/http_demo/utils/vlog/main.go:12 +0x38

Previous read at 0x00c00001a0a8 by main goroutine:
  main.getNumber()
      /QSC/go/src/example.com/http_demo/utils/vlog/main.go:15 +0x88
  main.main()
      /QSC/go/src/example.com/http_demo/utils/vlog/main.go:6 +0x33

Goroutine 6 (running) created at:
  main.getNumber()
      /QSC/go/src/example.com/http_demo/utils/vlog/main.go:11 +0x7a
  main.main()
      /QSC/go/src/example.com/http_demo/utils/vlog/main.go:6 +0x33
==================
Found 1 data race(s)
exit status 66
```

第一个 0 是打印结果 (因此我们现在知道是操作 2 首先完成)。接下来的几行给出了在代码中检测到的数据竞争的信息。我们可以看到关于数据竞争的信息分为三个部分：

第一部分告诉我们，在 getNumber 函数里创建的 goroutine 中尝试写入（这是我们将值 5 赋给 i 的位置）

下一部分告诉我们，在主 goroutine 里有一个在同时进行的读操作。

第三部分描述了导致数据竞争的 goroutine 是在哪里被创建的。

除了 go run 命令外，go build 和 go test 命令也支持使用 -race 标志。这个会使编译器创建的应用程序能够记录所有运行期间对共享变量访问，并且会记录下每一个读或者写共享变量的 goroutine 的身份信息。

竞争检查器会报告所有的已经发生的数据竞争。然而，它只能检测到运行时的竞争条件，并不能证明之后不会发生数据竞争。由于需要额外的记录，因此构建时加了竞争检测的程序跑起来会慢一些，且需要更大的内存，即使是这样，这些代价对于很多生产环境的工作来说还是可以接受的。对于一些偶发的竞争条件来说，使用附带竞争检查器的应用程序可以节省很多花在 Debug 上的时间。



### 解决数据竞争的方案

Go 提供了很多解决它的选择。所有这些解决方案的思路都是确保在我们写入变量时阻止对该变量的访问。一般常用的解决数据竞争的方案有：**使用 WaitGroup 锁**，**使用通道阻塞**以及**使用 Mutex 锁**，下面我们一个个来看他们的用法并比较一下这几种方案的不同点。

### 使用 WaitGroup

解决数据竞争的最直接方法是（如果需求允许的情况下）阻止读取访问，直到写入操作完成：

```
func getNumber() int {
    var i int
    // 初始化一个WaitGroup
    var wg sync.WaitGroup
    // Add(1) 通知程序有一个需要等待完成的任务
    wg.Add(1)
    go func() {
        i = 5
        // 调用wg.Done 表示正在等待的程序已经执行完成了
        wg.Done()
    }()
    // wg.Wait会阻塞当前程序直到等待的程序都执行完成为止
    wg.Wait()
    return i
}
```

下面是使用 `WaitGroup` 后程序执行的时间线：

![使用WaitGroup后程序执行的时间线](https://cdn.learnku.com/uploads/images/202005/24/6964/gG7r8X6MfU.svg)

### 使用通道阻塞

这个方法原则上与上一种方法类似，只是我们使用了通道而不是 `WaitGroup`：

```
func getNumber() int {
    var i int
  // 创建一个通道，在等待的任务完成时会向通道发送一个空结构体
    done := make(chan struct{})
    go func() {
        i = 5
        // 执行完成后向通道发送一个空结构体
        done <- struct{}{}
    }()
  // 从通道接收值将会阻塞程序，直到有值发送给done通道为止
    <-done
    return i
}
```

下图是使用通道阻塞解决数据竞争后程序的执行流程：

![使用通道解决数据竞争后程序的执行流程](https://cdn.learnku.com/uploads/images/202005/24/6964/gzabzbLvr5.svg)

### 使用 Mutex

到目前为止，使用的解决方案只有在确定写入操作完成后再读取 i 的值时才适用。现在让我们考虑一个更通常的情况，程序读取和写入的顺序并不是固定的，我们只要求它们不能同时发生就行。这种情况下我们应该考虑使用 Mutex 互斥锁。

```
// 首先，创建一个结构体包含我们想用互斥锁保护的值和一个mutex实例
type SafeNumber struct {
    val int
    m   sync.Mutex
}

func (i *SafeNumber) Get() int {、
    i.m.Lock()                       
    defer i.m.Unlock()                    
    return i.val
}

func (i *SafeNumber) Set(val int) {
    i.m.Lock()
    defer i.m.Unlock()
    i.val = val
}

func getNumber() int {
    // 创建一个sageNumber实例
    i := &SafeNumber{}
  // 使用Set和Get代替常规赋值和读取操作。
  // 我们现在可以确保只有在写入完成时才能读取，反之亦然
    go func() {
        i.Set(5)
    }()
    return i.Get()
}
```

下面两个图片对应于程序先获取到写锁和先获取到读锁两种可能的情况下程序的执行流程：

![先获取到写锁时程序的执行流程](https://cdn.learnku.com/uploads/images/202005/24/6964/Wah3tb2oIQ.svg)

![先获取读锁时程序的执行流程](https://cdn.learnku.com/uploads/images/202005/24/6964/c5dZ10xcq8.svg)

### Mutex vs Channel

上面我们使用互斥锁和通道两种方法解决了并发程序的数据竞争问题。那么我们该在什么情况下使用互斥锁，什么情况下又该使用通道呢？答案就在你试图解决的问题中。如果你试图解决的问题更适合互斥锁，那么就继续使用互斥锁。。如果问题似乎更适合渠道，则使用它。

大多数 Go 新手都试图使用通道来解决所有并发问题，因为这是 Go 语言的一个很酷的特性。这是不对的。语言为我们提供了使用 Mutex 或 Channel 的选项，选择两者都没有错。

通常，**当 goroutine 需要相互通信时使用通道，当确保同一时间只有一个 goroutine 能访问代码的关键部分时使用互斥锁**。在我们上面解决的问题中，我更倾向于使用互斥锁，因为这个问题不需要 goroutine 之间的任何通信。只需要确保同一时间只有一个 goroutine 拥有共享变量的使用权，互斥锁本来就是为解决这种问题而生的，所以使用互斥锁是更自然的一种选择。

### 一道用 Channel 解决的思考题

上面讲数据竞争问题举的例子里因为多个 goroutine 之间不需要通信，所以使用 Mutex 互斥锁的方案更合理些。那么针对使用 Channel 的并发编程场景我们就先留一道思考题给大家，题目如下：

假设有一个超长的切片，切片的元素类型为 int，切片中的元素为乱序排列。限时 5 秒，使用多个 goroutine 查找切片中是否存在给定值，在找到目标值或者超时后立刻结束所有 goroutine 的执行。

比如切片为：[23, 32, 78, 43, 76, 65, 345, 762, …… 915, 86]，查找的目标值为 345，如果切片中存在目标值程序输出:”Found it!” 并且立即取消仍在执行查找任务的 goroutine。如果在超时时间为找到目标值程序输出:”Timeout! Not Found”，同时立即取消仍在执行查找任务的 goroutine。

不用顾忌题目里切片的元素重不重复，也不需要对切片元素进行排序。解决这个问题肯定会用到 context、计时器、通道以及 select 语句（已经提示了很多啦：），相当于把最近关于并发编程文章里的知识串一遍。

