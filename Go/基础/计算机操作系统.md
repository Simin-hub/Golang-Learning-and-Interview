# 操作系统

# 概述

### **什么是操作系统？**

1. **操作系统（Operating System，简称 OS）是管理计算机硬件与软件资源的程序，是计算机的基石。**
2. **操作系统本质上是一个运行在计算机上的软件程序 ，用于管理计算机硬件和软件资源。** 举例：运行在你电脑上的所有应用程序都通过操作系统来调用系统内存以及磁盘等等硬件。
3. **操作系统存在屏蔽了硬件层的复杂性。** 操作系统就像是硬件使用的负责人， 统筹着各种相关事项。
4. **操作系统的内核（Kernel）是操作系统的核心部分，它负责系统的内存管理，硬件设备的管理，文件系统的管理以及应用程序的管理**。 内核是连接应用程序和硬件的桥梁，决定着系统的性能和稳定性。

![Kernel_Layout](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/Kernel_Layout.png)

### 基本特征

#### 1. 并发

并发是指宏观上**在一段时间内**能同时运行多个程序，而并行则指**同一时刻**能运行多个指令。

并行需要硬件支持，如多流水线、多核处理器或者分布式计算系统。

操作系统通过引入进程和线程，使得程序能够并发运行。

#### 2. 共享

共享是指系统中的资源可以被多**个并发进程**共同使用。

有两种共享方式：互斥共享和同时共享。

**互斥共享的资源称为临界资源**，例如打印机等，在同一时刻只允许一个进程访问，需要用同步机制来实现互斥访问。

#### 3. 虚拟

虚拟技术把一个物理实体转换为多个逻辑实体。

主要有两种虚拟技术：**时（时间）分复用技术和空（空间）分复用技术**。

多个进程能在同一个处理器上并发执行使用了时分复用技术，让每个进程轮流占用处理器，每次只执行一小个时间片并快速切换。

虚拟内存使用了空分复用技术，它将物理内存抽象为地址空间，每个进程都有各自的地址空间。地址空间的页被映射到物理内存，地址空间的页并不需要全部在物理内存中，当使用到一个没有

在物理内存的页时，执行页面置换算法，将该页置换到内存中。

#### 4. 异步

**异步指进程不是一次性执行完毕，而是走走停停**，以不可知的速度向前推进。

### 基本功能

#### 1. 进程管理

进程控制、进程同步、进程通信、死锁处理、处理机调度等。

#### 2. 内存管理

内存分配、地址映射、内存保护与共享、虚拟内存等。

#### 3. 文件管理

文件存储空间的管理、目录管理、文件读写管理和保护等。

#### 4. 设备管理

完成用户的 I/O 请求，方便用户使用各种设备，并提高设备的利用率。

主要包括缓冲管理、设备分配、设备处理、虛拟设备等。

### 系统调用

### **什么是系统调用呢？**

根据进程访问资源的特点，我们可以把进程在系统上的运行分为两个级别：

1. **用户态**(user mode) : 用户态运行的进程可以**直接读取用户程序的数据**。
2. **系统态**(kernel mode):可以简单的理解系统态运行的进程或程序几乎可以访问计算机的任何资源，不受限制。

说了用户态和系统态之后，那么什么是系统调用呢？

我们运行的程序基本都是运行在用户态，如果我们调用操作系统提供的系统态级别的子功能咋办呢？那就需要系统调用了！

也就是说在我们运行的用户程序中，**凡是与系统态级别的资源有关的操作（如文件管理、进程控制、内存管理等)**，都必须通过系统调用方式向操作系统提出服务请求，并由操作系统代为完成。

这些系统调用按功能大致可分为如下几类：

- **设备管理**。完成设备的请求或释放，以及设备启动等功能。
- **文件管理**。完成文件的读、写、创建及删除等功能。
- **进程控制**。完成进程的创建、撤销、阻塞及唤醒等功能。
- **进程通信**。完成进程之间的消息传递或信号传递等功能。
- **内存管理**。完成内存的分配、回收以及获取作业占用内存区大小及地址等功能。

如果一个进程在用户态需要使用内核态的功能，就进行系统调用从而陷入内核，由操作系统代为完成。

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f74475056302e706e67)



Linux 的系统调用主要有以下这些：

| Task     | Commands                    |
| -------- | --------------------------- |
| 进程控制 | fork(); exit(); wait();     |
| 进程通信 | pipe(); shmget(); mmap();   |
| 文件操作 | open(); read(); write();    |
| 设备操作 | ioctl(); read(); write();   |
| 信息维护 | getpid(); alarm(); sleep(); |
| 安全     | chmod(); umask(); chown();  |

### 宏内核和微内核

#### 1. 宏内核

宏内核是将操作系统功能作为一个紧密结合的整体放到内核。

由于各模块共享信息，因此有很高的性能。

#### 2. 微内核

由于操作系统不断复杂，因此将一部分操作系统功能移出内核，从而降低内核的复杂性。移出的部分根据分层的原则划分成若干服务，相互独立。

在微内核结构下，操作系统被划分成小的、定义良好的模块，只有微内核这一个模块运行在内核态，其余模块运行在用户态。

因为需要频繁地在用户态和核心态之间进行切换，所以会有一定的性能损失。

![img](https://camo.githubusercontent.com/e244b7965823da98c230d7b71038b8ee11dcb2e30b5e8fb1272dcd76008a889f/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f325f31345f6d6963726f6b65726e656c4172636869746563747572652e6a7067)



### 中断分类

#### 1. 外中断

**由 CPU 执行指令以外的事件引起**，如 I/O 完成中断，表示设备输入/输出处理已经完成，处理器能够发送下一个输入/输出请求。此外还有时钟中断、控制台中断等。

#### 2. 异常

**由 CPU 执行指令的内部事件引起**，如非法操作码、地址越界、算术溢出等。

#### 3. 陷入

在用户程序中使用系统调用。

# 进程管理

### 进程与线程

#### 1. 进程

**进程是资源分配的基本单位**。

**进程控制块 (Process Control Block, PCB) 描述进程的基本信息和运行状态**，所谓的创建进程和撤销进程，都是指对 PCB 的操作。

下图显示了 4 个程序创建了 4 个进程，这 4 个进程可以并发地执行。

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f61366163326230382d333836312d346538352d626161382d3338323238376266656539662e706e67)



#### 2. 线程

**线程是独立调度的基本单位**。

一个进程中可以有多个线程，它们共享进程资源。

QQ 和浏览器是两个进程，浏览器进程里面有很多线程，例如 HTTP 请求线程、事件响应线程、渲染线程等等，线程的并发执行使得在浏览器中点击一个新链接从而发起 HTTP 请求时，浏览器还可以响应用户的其它事件。

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f33636436333065612d303137632d343838642d616431642d3733326234656665646466352e706e67)



#### 3. 区别

Ⅰ 拥有资源

**进程是资源分配的基本单位，但是线程不拥有资源**，线程可以访问隶属进程的资源。

Ⅱ 调度

**线程是独立调度的基本单位，在同一进程中，线程的切换不会引起进程切换**，从一个进程中的线程切换到另一个进程中的线程时，会引起进程切换。

Ⅲ 系统开销

由于**创建或撤销进程时，系统都要为之分配或回收资源**，如内存空间、I/O 设备等，所付出的开销远大于创建或撤销线程时的开销。类似地，在进行进程切换时，涉及当前执行进程 CPU 环境的保存及新调度进程 CPU 环境的设置，而线程切换时只需保存和设置少量寄存器内容，开销很小。

Ⅳ 通信方面

**线程间可以通过直接读写同一进程中的数据进行通信**，但是进程通信需要借助 [IPC](https://zh.m.wikipedia.org/zh-hans/%E8%A1%8C%E7%A8%8B%E9%96%93%E9%80%9A%E8%A8%8A)（进程间通信，*Inter-Process Communication*）。

### 进程状态的切换

![img](https://camo.githubusercontent.com/0398c2bace5b1b0695f5a34f6cfedf6e358db565408abc83dd161de71d3bfec8/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f50726f6365737353746174652e706e67)

- 就绪状态（ready）：等待被调度
- 运行状态（running）
- 阻塞状态（waiting）：等待资源

应该注意以下内容：

- 只有**就绪态和运行态可以相互转换**，**其它的都是单向转换**。就绪状态的进程通过调度算法从而获得 CPU 时间，转为运行状态；而运行状态的进程，在分配给它的 CPU 时间片用完之后就会转为就绪状态，等待下一次调度。
- 阻塞状态是**缺少需要的资源从而由运行状态转换而来**，但是该资源不包括 CPU 时间，缺少 CPU 时间会从运行态转换为就绪态。

### 进程调度算法

不同环境的调度算法目标不同，因此需要针对不同环境来讨论调度算法。

#### 1. 批处理系统

批处理系统没有太多的用户操作，在该系统中，调度算法目标是保证吞吐量和周转时间（从提交到终止的时间）。

**1.1 先来先服务 first-come first-serverd（FCFS）**

非抢占式的调度算法，按照请求的顺序进行调度。

有利于长作业，但不利于短作业，因为短作业必须一直等待前面的长作业执行完毕才能执行，而长作业又需要执行很长时间，造成了短作业等待时间过长。

**1.2 短作业优先 shortest job first（SJF）**

非抢占式的调度算法，按估计运行时间最短的顺序进行调度。

长作业有可能会饿死，处于一直等待短作业执行完毕的状态。因为如果一直有短作业到来，那么长作业永远得不到调度。

**1.3 最短剩余时间优先 shortest remaining time next（SRTN）**

最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。 当一个新的作业到达时，其整个运行时间与当前进程的剩余时间作比较。如果新的进程需要的时间更少，则挂起当前进程，运行新的进程。否则新的进程等待。

#### 2. 交互式系统

交互式系统有大量的用户交互操作，在该系统中调度算法的目标是快速地进行响应。

**2.1 时间片轮转**

将所有就绪进程按 FCFS（先来先服务 ） 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。

时间片轮转算法的效率和时间片的大小有很大关系：

- 因为进程切换都要保存进程的信息并且载入新进程的信息，如果时间片太小，会导致进程切换得太频繁，在进程切换上就会花过多时间。
- 而如果时间片过长，那么实时性就不能得到保证。

![img](https://camo.githubusercontent.com/a87daa8201015ff54a213d9ea95c1e49e7eec447938c441dd0247e80b18eaa05/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f38633636323939392d633136632d343831632d396634302d3166646261356263393136372e706e67)



**2.2 优先级调度**

为每个进程分配一个优先级，按优先级进行调度。

为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。

**2.3 多级反馈队列**

一个进程需要执行 100 个时间片，如果采用时间片轮转调度算法，那么需要交换 100 次。

多级队列是为这种需要连续执行多个时间片的进程考虑，它设置了多个队列，每个队列时间片大小都不同，例如 1,2,4,8,..。进程在第一个队列没执行完，就会被移到下一个队列。这种方式下，之前的进程只需要交换 7 次。

每个队列优先权也不同，最上面的优先权最高。因此**只有上一个队列没有进程在排队，才能调度当前队列上的进程**。

可以将这种调度算法看成是时间片轮转调度算法和优先级调度算法的结合。

![img](https://camo.githubusercontent.com/c20fd7a3268ebc4ef0bce390344de2c5358392ecef2413d849c3095e21047980/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f30343263663932382d336338652d343831352d616539632d6632373830323032633638662e706e67)

#### 3. 实时系统

实时系统要求一个请求在一个确定时间内得到响应。

分为硬实时和软实时，前者必须满足绝对的截止时间，后者可以容忍一定的超时。

### 进程同步

#### 1. 临界区

对临界资源进行访问的那段代码称为临界区。

为了互斥访问临界资源，每个进程在进入临界区之前，需要先进行检查。

```
// entry section
// critical section;
// exit section
```

#### 2. 同步与互斥

- 同步：多个进程因为合作产生的直接制约关系，使得进程有一定的先后执行关系。
- 互斥：多个进程在同一时刻只有一个进程能进入临界区。

#### 3. 信号量

**信号量（Semaphore）是一个整型变量**，可以对其执行 down 和 up 操作，也就是常见的 P 和 V 操作。

- **down** : 如果信号量大于 0 ，执行 -1 操作；如果信号量等于 0，进程睡眠，等待信号量大于 0；
- **up** ：对信号量执行 +1 操作，唤醒睡眠的进程让其完成 down 操作。

down 和 up 操作需要被设计成原语，不可分割，通常的做法是在执行这些操作的时候屏蔽中断。

如果信号量的取值只能为 0 或者 1，那么就成为了 **互斥量（Mutex）** ，0 表示临界区已经加锁，1 表示临界区解锁。

```
typedef int semaphore;
semaphore mutex = 1;
void P1() {
    down(&mutex);
    // 临界区
    up(&mutex);
}

void P2() {
    down(&mutex);
    // 临界区
    up(&mutex);
}
```

<font size=3> **使用信号量实现生产者-消费者问题** </font> 

问题描述：使用一个缓冲区来保存物品，只有缓冲区没有满，生产者才可以放入物品；只有缓冲区不为空，消费者才可以拿走物品。

因为缓冲区属于临界资源，因此需要使用一个互斥量 mutex 来控制对缓冲区的互斥访问。

为了同步生产者和消费者的行为，需要记录缓冲区中物品的数量。数量可以使用信号量来进行统计，这里需要使用两个信号量：empty 记录空缓冲区的数量，full 记录满缓冲区的数量。其中，empty 信号量是在生产者进程中使用，当 empty 不为 0 时，生产者才可以放入物品；full 信号量是在消费者进程中使用，当 full 信号量不为 0 时，消费者才可以取走物品。

注意，不能先对缓冲区进行加锁，再测试信号量。也就是说，不能先执行 down(mutex) 再执行 down(empty)。如果这么做了，那么可能会出现这种情况：生产者对缓冲区加锁后，执行 down(empty) 操作，发现 empty = 0，此时生产者睡眠。消费者不能进入临界区，因为生产者对缓冲区加锁了，消费者就无法执行 up(empty) 操作，empty 永远都为 0，导致生产者永远等待下，不会释放锁，消费者因此也会永远等待下去。

#### 4. 管程

使用信号量机制实现的生产者消费者问题需要客户端代码做很多控制，而管程把控制的代码独立出来，不仅不容易出错，也使得客户端代码调用更容易。

管程有一个重要特性：在一个时刻只能有一个进程使用管程。进程在无法继续执行的时候不能一直占用管程，否则其它进程永远不能使用管程。

管程引入了 **条件变量** 以及相关的操作：**wait()** 和 **signal()** 来实现同步操作。对条件变量执行 wait() 操作会导致调用进程阻塞，把管程让出来给另一个进程持有。signal() 操作用于唤醒被阻塞的进程。

### 经典同步问题

生产者和消费者问题前面已经讨论过了。

#### 1. 哲学家进餐问题

[![img](https://camo.githubusercontent.com/7f8eb6362323b56a5dd8ec061d7ea0c5b0d07a842132598bbed860a8bb941317/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f61393037376630362d373538342d346632622d386332302d3361386534363932383832302e6a7067)](https://camo.githubusercontent.com/7f8eb6362323b56a5dd8ec061d7ea0c5b0d07a842132598bbed860a8bb941317/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f61393037376630362d373538342d346632622d386332302d3361386534363932383832302e6a7067)



五个哲学家围着一张圆桌，每个哲学家面前放着食物。哲学家的生活有两种交替活动：吃饭以及思考。当一个哲学家吃饭时，需要先拿起自己左右两边的两根筷子，并且一次只能拿起一根筷子。

下面是一种错误的解法，如果所有哲学家同时拿起左手边的筷子，那么所有哲学家都在等待其它哲学家吃完并释放自己手中的筷子，导致死锁。

```
#define N 5

void philosopher(int i) {
    while(TRUE) {
        think();
        take(i);       // 拿起左边的筷子
        take((i+1)%N); // 拿起右边的筷子
        eat();
        put(i);
        put((i+1)%N);
    }
}
```

为了防止死锁的发生，可以设置两个条件：

- **必须同时拿起左右两根筷子；**
- **只有在两个邻居都没有进餐的情况下才允许进餐。**

```
#define N 5
#define LEFT (i + N - 1) % N // 左邻居
#define RIGHT (i + 1) % N    // 右邻居
#define THINKING 0
#define HUNGRY   1
#define EATING   2
typedef int semaphore;
int state[N];                // 跟踪每个哲学家的状态
semaphore mutex = 1;         // 临界区的互斥，临界区是 state 数组，对其修改需要互斥
semaphore s[N];              // 每个哲学家一个信号量

void philosopher(int i) {
    while(TRUE) {
        think(i);
        take_two(i);
        eat(i);
        put_two(i);
    }
}

void take_two(int i) {
    down(&mutex);
    state[i] = HUNGRY;
    check(i);
    up(&mutex);
    down(&s[i]); // 只有收到通知之后才可以开始吃，否则会一直等下去
}

void put_two(i) {
    down(&mutex);
    state[i] = THINKING;
    check(LEFT); // 尝试通知左右邻居，自己吃完了，你们可以开始吃了
    check(RIGHT);
    up(&mutex);
}

void eat(int i) {
    down(&mutex);
    state[i] = EATING;
    up(&mutex);
}

// 检查两个邻居是否都没有用餐，如果是的话，就 up(&s[i])，使得 down(&s[i]) 能够得到通知并继续执行
void check(i) {         
    if(state[i] == HUNGRY && state[LEFT] != EATING && state[RIGHT] !=EATING) {
        state[i] = EATING;
        up(&s[i]);
    }
}
```

#### 2. 读者-写者问题

**允许多个进程同时对数据进行读操作，但是不允许读和写以及写和写操作同时发生。**

一个整型变量 count 记录在对数据进行读操作的进程数量，一个互斥量 count_mutex 用于对 count 加锁，一个互斥量 data_mutex 用于对读写的数据加锁。

```
typedef int semaphore;
semaphore count_mutex = 1;
semaphore data_mutex = 1;
int count = 0;

void reader() {
    while(TRUE) {
        down(&count_mutex);
        count++;
        if(count == 1) down(&data_mutex); // 第一个读者需要对数据进行加锁，防止写进程访问
        up(&count_mutex);
        read();
        down(&count_mutex);
        count--;
        if(count == 0) up(&data_mutex);
        up(&count_mutex);
    }
}

void writer() {
    while(TRUE) {
        down(&data_mutex);
        write();
        up(&data_mutex);
    }
}
```

以下内容由 [@Bandi Yugandhar](https://github.com/yugandharbandi) 提供。

The first case may result Writer to starve. This case favous Writers i.e no writer, once added to the queue, shall be kept waiting longer than absolutely necessary(only when there are readers that entered the queue before the writer).

```
int readcount, writecount;                   //(initial value = 0)
semaphore rmutex, wmutex, readLock, resource; //(initial value = 1)

//READER
void reader() {
<ENTRY Section>
 down(&readLock);                 //  reader is trying to enter
 down(&rmutex);                  //   lock to increase readcount
  readcount++;                 
  if (readcount == 1)          
   down(&resource);              //if you are the first reader then lock  the resource
 up(&rmutex);                  //release  for other readers
 up(&readLock);                 //Done with trying to access the resource

<CRITICAL Section>
//reading is performed

<EXIT Section>
 down(&rmutex);                  //reserve exit section - avoids race condition with readers
 readcount--;                       //indicate you're leaving
  if (readcount == 0)          //checks if you are last reader leaving
   up(&resource);              //if last, you must release the locked resource
 up(&rmutex);                  //release exit section for other readers
}

//WRITER
void writer() {
  <ENTRY Section>
  down(&wmutex);                  //reserve entry section for writers - avoids race conditions
  writecount++;                //report yourself as a writer entering
  if (writecount == 1)         //checks if you're first writer
   down(&readLock);               //if you're first, then you must lock the readers out. Prevent them from trying to enter CS
  up(&wmutex);                  //release entry section

<CRITICAL Section>
 down(&resource);                //reserve the resource for yourself - prevents other writers from simultaneously editing the shared resource
  //writing is performed
 up(&resource);                //release file

<EXIT Section>
  down(&wmutex);                  //reserve exit section
  writecount--;                //indicate you're leaving
  if (writecount == 0)         //checks if you're the last writer
   up(&readLock);               //if you're last writer, you must unlock the readers. Allows them to try enter CS for reading
  up(&wmutex);                  //release exit section
}
```

We can observe that every reader is forced to acquire ReadLock. On the otherhand, writers doesn’t need to lock individually. Once the first writer locks the ReadLock, it will be released only when there is no writer left in the queue.

From the both cases we observed that either reader or writer has to starve. Below solutionadds the constraint that no thread shall be allowed to starve; that is, the operation of obtaining a lock on the shared data will always terminate in a bounded amount of time.

```
int readCount;                  // init to 0; number of readers currently accessing resource

// all semaphores initialised to 1
Semaphore resourceAccess;       // controls access (read/write) to the resource
Semaphore readCountAccess;      // for syncing changes to shared variable readCount
Semaphore serviceQueue;         // FAIRNESS: preserves ordering of requests (signaling must be FIFO)

void writer()
{ 
    down(&serviceQueue);           // wait in line to be servicexs
    // <ENTER>
    down(&resourceAccess);         // request exclusive access to resource
    // </ENTER>
    up(&serviceQueue);           // let next in line be serviced

    // <WRITE>
    writeResource();            // writing is performed
    // </WRITE>

    // <EXIT>
    up(&resourceAccess);         // release resource access for next reader/writer
    // </EXIT>
}

void reader()
{ 
    down(&serviceQueue);           // wait in line to be serviced
    down(&readCountAccess);        // request exclusive access to readCount
    // <ENTER>
    if (readCount == 0)         // if there are no readers already reading:
        down(&resourceAccess);     // request resource access for readers (writers blocked)
    readCount++;                // update count of active readers
    // </ENTER>
    up(&serviceQueue);           // let next in line be serviced
    up(&readCountAccess);        // release access to readCount

    // <READ>
    readResource();             // reading is performed
    // </READ>

    down(&readCountAccess);        // request exclusive access to readCount
    // <EXIT>
    readCount--;                // update count of active readers
    if (readCount == 0)         // if there are no readers left:
        up(&resourceAccess);     // release resource access for all
    // </EXIT>
    up(&readCountAccess);        // release access to readCount
}
```

### 进程通信

进程同步与进程通信很容易混淆，它们的区别在于：

- 进程同步：控制多个进程按一定顺序执行；
- 进程通信：进程间传输信息。

**进程通信是一种手段，而进程同步是一种目的**。也可以说，为了能够达到进程同步的目的，需要让进程进行通信，传输一些进程同步所需要的信息。

#### 1. 管道

管道是通过调用 pipe 函数创建的，fd[0] 用于读，fd[1] 用于写。

```
#include <unistd.h>
int pipe(int fd[2]);
```

它具有以下限制：

- 只支持半双工通信（单向交替传输）；
- 只能在父子进程或者兄弟进程中使用。

[![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f35336364396164652d623061362d343339392d623464652d3766316662643036636466622e706e67)](https://camo.githubusercontent.com/af6ac5de61c835b0fe14c799c244632fa04239ef2ca9421eee543392353297c8/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f35336364396164652d623061362d343339392d623464652d3766316662643036636466622e706e67)



#### 2. FIFO

也称为命名管道，去除了管道只能在父子进程中使用的限制。

```
#include <sys/stat.h>
int mkfifo(const char *path, mode_t mode);
int mkfifoat(int fd, const char *path, mode_t mode);
```

FIFO 常用于客户-服务器应用程序中，FIFO 用作汇聚点，在客户进程和服务器进程之间传递数据。

[![img](https://camo.githubusercontent.com/8c4dd36cf4d1509b9c3ae0500085617fee811f7a83602a71e64769753b66b66b/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f32616335306238312d643932612d343430312d623965632d6632313133656363333037362e706e67)](https://camo.githubusercontent.com/8c4dd36cf4d1509b9c3ae0500085617fee811f7a83602a71e64769753b66b66b/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f32616335306238312d643932612d343430312d623965632d6632313133656363333037362e706e67)



#### 3. 消息队列

相比于 FIFO，消息队列具有以下优点：

- 消息队列可以独立于读写进程存在，从而避免了 FIFO 中同步管道的打开和关闭时可能产生的困难；
- 避免了 FIFO 的同步阻塞问题，不需要进程自己提供同步方法；
- 读进程可以根据消息类型有选择地接收消息，而不像 FIFO 那样只能默认地接收。

#### 4. 信号量

它是一个计数器，用于为多个进程提供对共享数据对象的访问。

#### 5. 共享存储

允许多个进程共享一个给定的存储区。因为数据不需要在进程之间复制，所以这是最快的一种 IPC。

需要使用信号量用来同步对共享存储的访问。

多个进程可以将同一个文件映射到它们的地址空间从而实现共享内存。另外 XSI 共享内存不是使用文件，而是使用内存的匿名段。

#### 6. 套接字

与其它通信机制不同的是，它可用于不同机器间的进程通信。

# 死锁

## 必要条件

[![img](https://camo.githubusercontent.com/8940a52ebe48a8a0162bd751bed592a6825f0a6ae9c52a369f511d4e29a4a4c2/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f63303337633930312d376561652d346533312d613165342d3964343133323965356333652e706e67)](https://camo.githubusercontent.com/8940a52ebe48a8a0162bd751bed592a6825f0a6ae9c52a369f511d4e29a4a4c2/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f63303337633930312d376561652d346533312d613165342d3964343133323965356333652e706e67)



- **互斥**：每个资源要么已经分配给了一个进程，要么就是可用的。
- **占有和等待**：已经得到了某个资源的进程可以再请求新的资源。
- **不可抢占：**已经分配给一个进程的资源**不能强制性地被抢占**，它只能被占有它的进程显式地释放。
- **环路等待**：有两个或者两个以上的进程组成一条环路，该环路中的每个进程都在等待下一个进程所占有的资源。

## 处理方法

主要有以下四种方法：

- 鸵鸟策略
- 死锁检测与死锁恢复
- 死锁预防
- 死锁避免

## 鸵鸟策略

**把头埋在沙子里，假装根本没发生问题。**

因为解决死锁问题的代价很高，因此鸵鸟策略这种不采取任务措施的方案会获得更高的性能。

当发生死锁时不会对用户造成多大影响，或发生死锁的概率很低，可以采用鸵鸟策略。

大多数操作系统，包括 Unix，Linux 和 Windows，处理死锁问题的办法仅仅是忽略它。

## 死锁检测与死锁恢复

不试图阻止死锁，而是当检测到死锁发生时，采取措施进行恢复。

### 1. 每种类型一个资源的死锁检测

[![img](https://camo.githubusercontent.com/5663be4d3b58da1b738412ca4854b61d255974230c1c88875f96511618a5bae0/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f62316661303435332d613462302d346561652d613335322d3438616363613866666637342e706e67)](https://camo.githubusercontent.com/5663be4d3b58da1b738412ca4854b61d255974230c1c88875f96511618a5bae0/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f62316661303435332d613462302d346561652d613335322d3438616363613866666637342e706e67)



上图为资源分配图，其中方框表示资源，圆圈表示进程。资源指向进程表示该资源已经分配给该进程，进程指向资源表示进程请求获取该资源。

图 a 可以抽取出环，如图 b，它满足了环路等待条件，因此会发生死锁。

每种类型一个资源的死锁检测算法是**通过检测有向图是否存在环来实现**，从一个节点出发进行深度优先搜索，对访问过的节点进行标记，如果访问了已经标记的节点，就表示有向图存在环，也就是检测到死锁的发生。

### 2. 每种类型多个资源的死锁检测

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f65316564613364352d356563382d343730382d386532352d3161303463356531316634382e706e67)



上图中，有三个进程四个资源，每个数据代表的含义如下：

- E 向量：资源总量
- A 向量：资源剩余量
- C 矩阵：每个进程所拥有的资源数量，每一行都代表一个进程拥有资源的数量
- R 矩阵：每个进程请求的资源数量

进程 P1 和 P2 所请求的资源都得不到满足，只有进程 P3 可以，让 P3 执行，之后释放 P3 拥有的资源，此时 A = (2 2 2 0)。P2 可以执行，执行后释放 P2 拥有的资源，A = (4 2 2 1) 。P1 也可以执行。所有进程都可以顺利执行，没有死锁。

算法总结如下：

每个进程最开始时都不被标记，执行过程有可能被标记。当算法结束时，任何没有被标记的进程都是死锁进程。

1. 寻找一个没有标记的进程 Pi，它所请求的资源小于等于 A。
2. 如果找到了这样一个进程，那么将 C 矩阵的第 i 行向量加到 A 中，标记该进程，并转回 1。
3. 如果没有这样一个进程，算法终止。

### 3. 死锁恢复

- 利用抢占恢复
- 利用回滚恢复
- 通过杀死进程恢复

## 死锁预防

在程序运行之前预防发生死锁。

### 1. 破坏互斥条件

例如假脱机打印机技术允许若干个进程同时输出，唯一真正请求物理打印机的进程是打印机守护进程。

### 2. 破坏占有和等待条件

一种实现方式是规定所有进程在开始执行前请求所需要的全部资源。

### 3. 破坏不可抢占条件

### 4. 破坏环路等待

给资源统一编号，进程只能按编号顺序来请求资源。

## 死锁避免

在程序运行时避免发生死锁。

### 1. 安全状态

[![img](https://camo.githubusercontent.com/09589c4bfe0e5514a44fc74cd63069f018b03246880e1f89b887313bbbdf2073/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f65643532333035312d363038662d346333662d623334332d3338336532643139343437302e706e67)](https://camo.githubusercontent.com/09589c4bfe0e5514a44fc74cd63069f018b03246880e1f89b887313bbbdf2073/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f65643532333035312d363038662d346333662d623334332d3338336532643139343437302e706e67)



图 a 的第二列 Has 表示已拥有的资源数，第三列 Max 表示总共需要的资源数，Free 表示还有可以使用的资源数。从图 a 开始出发，先让 B 拥有所需的所有资源（图 b），运行结束后释放 B，此时 Free 变为 5（图 c）；接着以同样的方式运行 C 和 A，使得所有进程都能成功运行，因此可以称图 a 所示的状态时安全的。

定义：如果没有死锁发生，并且即使所有进程突然请求对资源的最大需求，也仍然存在某种调度次序能够使得每一个进程运行完毕，则称该状态是安全的。

安全状态的检测与死锁的检测类似，因为安全状态必须要求不能发生死锁。下面的银行家算法与死锁检测算法非常类似，可以结合着做参考对比。

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/1358881-20191125164249992-1856910147.png)

 **注意：**

（1）系统在某一时刻的安全状态可能不唯一，但这不影响对系统安全性的判断。
（2）安全状态是非死锁状态，而不安全状态并不一定是死锁状态。即系统处于安全状态一定可以避免死锁，而系统处于不安全状态则仅仅可能进入死锁状态。

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/1358881-20191125164352815-1516999888.png)

### 2. 单个资源的银行家算法

一个小城镇的银行家，他向一群客户分别承诺了一定的贷款额度，算法要做的是**判断对请求的满足是否会进入不安全状态，如果是，就拒绝请求；否则予以分配**。

[![img](https://camo.githubusercontent.com/381663ffc7a4db80478e5f454a11400debf6c13628632e3396fdaa7a6e555716/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f64313630656332652d636665322d343634302d626461372d3632663533653538623863302e706e67)](https://camo.githubusercontent.com/381663ffc7a4db80478e5f454a11400debf6c13628632e3396fdaa7a6e555716/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f64313630656332652d636665322d343634302d626461372d3632663533653538623863302e706e67)



上图 c 为不安全状态，因此算法会拒绝之前的请求，从而避免进入图 c 中的状态。

### 3. 多个资源的银行家算法

[![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f36326530646434662d343463332d343365652d626236652d6665646239653036383531392e706e67)](https://camo.githubusercontent.com/5334ac030b7446b89615c4319275fe27330481ac6f1a9280fc682f6dffcf5241/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f36326530646434662d343463332d343365652d626236652d6665646239653036383531392e706e67)



上图中有五个进程，四个资源。**左边的图表示已经分配的资源，右边的图表示还需要分配的资源**。**最右边的 E、P 以及 A 分别表示：总资源、已分配资源以及可用资源**，注意这三个为向量，而不是具体数值，例如 A=(1020)，表示 4 个资源分别还剩下 1/0/2/0。

检查一个状态是否安全的算法如下：

- 查找右边的矩阵是否存在一行小于等于向量 A。如果不存在这样的行，那么系统将会发生死锁，状态是不安全的。
- 假若找到这样一行，将该进程标记为终止，并将其已分配资源加到 A 中。
- 重复以上两步，直到所有进程都标记为终止，则状态时安全的。

如果一个状态不是安全的，需要拒绝进入这个状态。

![img](https://img2018.cnblogs.com/i-beta/1358881/201911/1358881-20191125165114981-1954446360.png)

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/1358881-20191125171020518-1171969079.png)

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/1358881-20191125171200431-333419697.png)

总结：

安全状态：进程序列能够以某一种序列方式完成所有资源分配。

银行家算法：

1. 判断该时刻时候是安全状态
2. 判断否满足该进程申请的资源不大于所需资源，若不符合，进程错误
3. 判断否满足该进程申请的资源不大于可用资源，若不符合，进程阻塞
4. 若符合，试着分配资源给该进程，分配后是否是安全状态，若是安全状态则完成本次分配
5. 若处于不安全状态则进行回滚，撤销该进程的资源分配，该进程阻塞。

# 内存管理

## 虚拟内存

**虚拟内存的目的是为了让物理内存扩充成更大的逻辑内存**，从而让程序获得更多的可用内存。

为了更好的管理内存，操作系统将内存抽象成地址空间。**每个程序拥有自己的地址空间，这个地址空间被分割成多个块，每一块称为一页**。这些页被映射到物理内存，但不需要映射到连续的物理内存，也不需要所有页都必须在物理内存中。当程序引用到不在物理内存中的页时，**由硬件执行必要的映射**，将缺失的部分装入物理内存并重新执行失败的指令。

从上面的描述中可以看出，**虚拟内存允许程序不用将地址空间中的每一页都映射到物理内存**，也就是说一个程序不需要全部调入内存就可以运行，这使得有限的内存运行大程序成为可能。例如有一台计算机可以产生 16 位地址，那么一个程序的地址空间范围是 0~64K。该计算机只有 32KB 的物理内存，虚拟内存技术允许该计算机运行一个 64K 大小的程序。

[![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f37623238316231652d303539352d343032622d616533352d3863393130383463333363312e706e67)](https://camo.githubusercontent.com/01251b0ef66ccf744889c26424634aae680922be7d993522b4d831dca3c9511c/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f37623238316231652d303539352d343032622d616533352d3863393130383463333363312e706e67)



## 分页系统地址映射

[分段、分页、段页式](https://zhuanlan.zhihu.com/p/451405962)

内存管理单元（MMU）管理着地址空间和物理内存的转换，其中的页表（Page table）存储着页（程序地址空间）和页框（物理内存空间）的映射表。

一个虚拟地址分成两个部分，一部分存储页面号，一部分存储偏移量。

下图的页表存放着 16 个页，这 16 个页需要用 4 个比特位来进行索引定位。例如对于虚拟地址（0010 000000000100），前 4 位是存储页面号 2，读取表项内容为（110 1），**页表项最后一位表示是否存在于内存中，1 表示存在**。后 12 位存储偏移量。这个页对应的页框的地址为 （110 000000000100）。

[![img](https://camo.githubusercontent.com/1f3a60c6aaac33dd000b9d6a39069d3ddaf2bb04c22b8bcda782eca707eb64fe/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f63663433383661312d353863392d346563612d613137662d6531326231653937373065622e706e67)](https://camo.githubusercontent.com/1f3a60c6aaac33dd000b9d6a39069d3ddaf2bb04c22b8bcda782eca707eb64fe/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f63663433383661312d353863392d346563612d613137662d6531326231653937373065622e706e67)

### 分页是怎么解决分段的内存碎片、内存交换效率低的问题？

由于内存空间都是预先划分好的，也就不会像分段会产生间隙非常小的内存，这正是分段会产生内存碎片的原因。而**采用了分页，那么释放的内存都是以页为单位释放的，也就不会产生无法给进程使用的小内存。**

如果内存空间不够，操作系统会把其他正在运行的进程中的「最近没被使用」的内存页面给释放掉，也就是暂时写在硬盘上，称为**换出**（*Swap Out*）。一旦需要的时候，再加载进来，称为**换入**（*Swap In*）。所以，一次性写入磁盘的也只有少数的一个页或者几个页，不会花太多时间，**内存交换的效率就相对比较高。只有在程序运行中，需要用到对应虚拟内存页里面的指令和数据时，再加载到物理内存里面去。**

## 页面置换算法

在程序运行过程中，如果要访问的页面不在内存中，就发生缺页中断从而将该页调入内存中。此时如果内存已无空闲空间，系统必须从内存中调出一个页面到磁盘对换区中来腾出空间。

**页面置换算法和缓存淘汰策略类似**，可以将内存看成磁盘的缓存。在缓存系统中，缓存的大小有限，当有新的缓存到达时，需要淘汰一部分已经存在的缓存，这样才有空间存放新的缓存数据。

页面置换算法的主要目标是使页面置换频率最低（也可以说缺页率最低）。

### 1. 最佳

> OPT, Optimal replacement algorithm

所选择的被换出的页面将是最长时间内不再被访问，通常可以保证获得最低的缺页率。

是一种理论上的算法，因为无法知道一个页面多长时间不再被访问。

举例：一个系统为某进程分配了三个物理块，并有如下页面引用序列：

```
7，0，1，2，0，3，0，4，2，3，0，3，2，1，2，0，1，7，0，1
```

开始运行时，先将 7, 0, 1 三个页面装入内存。当进程要访问页面 2 时，产生缺页中断，会将页面 7 换出，因为页面 7 再次被访问的时间最长。

### 2. 最近最久未使用

> LRU, Least Recently Used

虽然无法知道将来要使用的页面情况，但是可以知道过去使用页面的情况。LRU 将最近最久未使用的页面换出。

为了实现 LRU，需要在内存中维护一个所有页面的链表。当一个页面被访问时，将这个页面移到链表表头。这样就能保证链表表尾的页面是最近最久未访问的。

因为每次访问都需要更新链表，因此这种方式实现的 LRU 代价很高。

```
4，7，0，7，1，0，1，2，1，2，6
```

[![img](https://camo.githubusercontent.com/c5cd2c10ae1c8526540a7af00c5390d1a953f147c4c147358953c9e929897cc3/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f65623835393232382d633066322d346263652d393130642d6439663736393239333532622e706e67)](https://camo.githubusercontent.com/c5cd2c10ae1c8526540a7af00c5390d1a953f147c4c147358953c9e929897cc3/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f65623835393232382d633066322d346263652d393130642d6439663736393239333532622e706e67)

### 3. 最近未使用

> NRU, Not Recently Used

每个页面都有两个状态位：R 与 M，当页面被访问时设置页面的 R=1，当页面被修改时设置 M=1。其中 R 位会定时被清零。可以将页面分成以下四类：

- R=0，M=0
- R=0，M=1
- R=1，M=0
- R=1，M=1

当发生缺页中断时，NRU 算法随机地从类编号最小的非空类中挑选一个页面将它换出。

NRU 优先换出已经被修改的脏页面（R=0，M=1），而不是被频繁使用的干净页面（R=1，M=0）。

### 4. 先进先出

> FIFO, First In First Out

选择换出的页面是最先进入的页面。

该算法会将那些经常被访问的页面换出，导致缺页率升高。

### 5. 第二次机会算法

FIFO 算法可能会把经常使用的页面置换出去，为了避免这一问题，对该算法做一个简单的修改：

当页面被访问 (读或写) 时设置该页面的 R 位为 1。需要替换的时候，检查最老页面的 R 位。如果 R 位是 0，那么这个页面既老又没有被使用，可以立刻置换掉；如果是 1，就将 R 位清 0，并把该页面放到链表的尾端，修改它的装入时间使它就像刚装入的一样，然后继续从链表的头部开始搜索。

[![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f65636638616435642d353430332d343862392d623665372d6632653230666665386663612e706e67)](https://camo.githubusercontent.com/579e409ef1551a1dc1c59487bc2fd54e93129ec97573721a3027376aa7f17595/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f65636638616435642d353430332d343862392d623665372d6632653230666665386663612e706e67)



### 6. 时钟

> Clock

第二次机会算法需要在链表中移动页面，降低了效率。时钟算法使用环形链表将页面连接起来，再使用一个指针指向最老的页面。

[![img](https://camo.githubusercontent.com/66bf1e33e909443e7fd77bf1d37c6144162b0545ac0aa6b078928e40a4d64878/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f35663565663062362d393865612d343937632d613030372d6636633535323838656162312e706e67)](https://camo.githubusercontent.com/66bf1e33e909443e7fd77bf1d37c6144162b0545ac0aa6b078928e40a4d64878/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f35663565663062362d393865612d343937632d613030372d6636633535323838656162312e706e67)



## 分段

**虚拟内存采用的是分页技术，也就是将地址空间划分成固定大小的页，每一页再与内存进行映射**。

下图为一个编译器在编译过程中建立的多个表，有 4 个表是动态增长的，如果使用分页系统的一维地址空间，动态增长的特点会导致覆盖问题的出现。

[![img](https://camo.githubusercontent.com/bc968c738c37aa7ad6d63d9b95a4803f11fe14aac87f571558024d19af30d399/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f32326465303533382d376336652d343336352d626433622d3863653363353930303231362e706e67)](https://camo.githubusercontent.com/bc968c738c37aa7ad6d63d9b95a4803f11fe14aac87f571558024d19af30d399/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f32326465303533382d376336652d343336352d626433622d3863653363353930303231362e706e67)



**分段的做法是把每个表分成段，一个段构成一个独立的地址空间。每个段的长度可以不同，并且可以动态增长。**

[![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f65303930306262322d323230612d343362372d396161392d3164356364353566663536652e706e67)](https://camo.githubusercontent.com/836f0a92a1f8ff0dee7112c8fc213daa419a42e82cd543d6fd87100fc2624bec/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f65303930306262322d323230612d343362372d396161392d3164356364353566663536652e706e67)



### 分段机制下，虚拟地址和物理地址是如何映射的？

分段机制下的虚拟地址由两部分组成，**段选择子**和**段内偏移量**。

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/v2-7c9dcf37f2467b69048a86c831e1ec72_r.jpg)

- **段选择子**就保存在段寄存器里面。段选择子里面最重要的是**段号**，用作段表的索引。**段表**里面保存的是这个**段的基地址、段的界限和特权等级**等。
- 虚拟地址中的**段内偏移量**应该位于 0 和段界限之间，如果段内偏移量是合法的，就将段基地址加上段内偏移量得到物理内存地址。

虚拟地址是通过**段表**与物理地址进行映射的，分段机制会把程序的虚拟地址分成 4 个段，每个段在段表中有一个项，在这一项找到段的基地址，再加上偏移量，于是就能找到物理内存中的地址，如下图：

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/v2-3901b3829782339de355bfb94ce60ed1_r.jpg)

如果要访问段 3 中偏移量 500 的虚拟地址，我们可以计算出物理地址为，段 3 基地址 7000 + 偏移量 500 = 7500。

分段的办法很好，解决了程序本身不需要关心具体的物理内存地址的问题，但它也有一些不足之处：

- 第一个就是**内存碎片**的问题。
- 第二个就是**内存交换的效率低**的问题。

**内存碎片的问题**

这里的内存碎片的问题共有两处地方：

- 外部内存碎片，也就是产生了多个不连续的小物理内存，导致新的程序无法被装载；
- 内部内存碎片，程序所有的内存都被装载到了物理内存，但是这个程序有部分的内存可能并不是很常使用，这也会导致内存的浪费；

解决外部内存碎片的问题就是**内存交换**。

可以把音乐程序占用的那 256MB 内存写到硬盘上，然后再从硬盘上读回来到内存里。不过再读回的时候，我们不能装载回原来的位置，而是紧紧跟着那已经被占用了的 512MB 内存后面。这样就能空缺出连续的 256MB 空间，于是新的 200MB 程序就可以装载进来。

这个内存交换空间，**在 Linux 系统里，也就是我们常看到的 Swap 空间**，这块空间是从硬盘划分出来的，用于内存与硬盘的空间交换

### 分段为什么会导致内存交换效率低？

对于多进程的系统来说，用分段的方式，内存碎片是很容易产生的，产生了内存碎片，那不得不重新 `Swap` 内存区域，这个过程会产生性能瓶颈。

因为硬盘的访问速度要比内存慢太多了，每一次内存交换，我们都需要把一大段连续的内存数据写到硬盘上。

所以，**如果内存交换的时候，交换的是一个占内存空间很大的程序，这样整个机器都会显得卡顿。**

## 段页式

程序的地址空间划**分成多个拥有独立地址空间的段，每个段上的地址空间划分成大小相同的页**。这样既拥有分段系统的共享和保护，又拥有分页系统的虚拟内存功能。

段页式内存管理实现的方式：

- 先将程序划分为多个有逻辑意义的段，也就是前面提到的分段机制；
- 接着再把每个段划分为多个页，也就是对分段划分出来的连续空间，再划分固定大小的页；

这样，地址结构就由**段号、段内页号和页内位移**三部分组成。

用于段页式地址变换的数据结构是每一个程序一张段表，每个段又建立一张页表，段表中的地址是页表的起始地址，而页表中的地址则为某页的物理页号，如图所示：

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/v2-bc9415b2bb7e540e001033c03c3fbc30_r.jpg)

**段页式管理中的段表、页表与内存的关系**

段页式地址变换中要得到物理地址须经过三次内存访问：

- 第一次访问段表，得到页表起始地址；
- 第二次访问页表，得到物理页号；
- 第三次将物理页号与页内位移组合，得到物理地址。

可用软、硬件相结合的方法实现段页式地址变换，这样虽然增加了硬件成本和系统开销，但提高了内存的利用率。

## 分页与分段的比较

- 对程序员的透明性：分页透明，但是**分段需要程序员显式划分每个段**。
- 地址空间的维度：分页是一维地址空间，分段是二维的。
- 大小是否可以改变：页的大小不可变，段的大小可以动态改变。
- 出现的原因：分页主要用于实现虚拟内存，从而获得更大的地址空间；**分段主要是为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护**。

# 设备管理

## 磁盘结构

- 盘面（Platter）：一个磁盘有多个盘面；
- 磁道（Track）：盘面上的圆形带状区域，一个盘面可以有多个磁道；
- 扇区（Track Sector）：磁道上的一个弧段，一个磁道可以有多个扇区，它是最小的物理储存单位，目前主要有 512 bytes 与 4 K 两种大小；
- 磁头（Head）：与盘面非常接近，能够将盘面上的磁场转换为电信号（读），或者将电信号转换为盘面的磁场（写）；
- 制动手臂（Actuator arm）：用于在磁道之间移动磁头；
- 主轴（Spindle）：使整个盘面转动。

[![img](https://camo.githubusercontent.com/062b5e89146b6df61a790e3585635f2d8892ab9f8f6181da26aa58a9cbd55922/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f30313466626334642d643837332d346131322d623136302d3836376464616564393830372e6a7067)](https://camo.githubusercontent.com/062b5e89146b6df61a790e3585635f2d8892ab9f8f6181da26aa58a9cbd55922/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f30313466626334642d643837332d346131322d623136302d3836376464616564393830372e6a7067)



## 磁盘调度算法

读写一个磁盘块的时间的影响因素有：

- 旋转时间（主轴转动盘面，使得磁头移动到适当的扇区上）
- 寻道时间（制动手臂移动，使得磁头移动到适当的磁道上）
- 实际的数据传输时间

其中，寻道时间最长，因此磁盘调度的主要目标是使磁盘的平均寻道时间最短。

### 1. 先来先服务

> FCFS, First Come First Served

按照磁盘请求的顺序进行调度。

优点是公平和简单。缺点也很明显，因为未对寻道做任何优化，使平均寻道时间可能较长。

### 2. 最短寻道时间优先

> SSTF, Shortest Seek Time First

**优先调度与当前磁头所在磁道距离最近的磁道。**

虽然平均寻道时间比较低，但是不够公平。如果新到达的磁道请求总是比一个在等待的磁道请求近，那么在等待的磁道请求会一直等待下去，也就是出现饥饿现象。具体来说，两端的磁道请求更容易出现饥饿现象。

[![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f34653234383565342d333462642d343936372d396630322d3063303933623739376161612e706e67)](https://camo.githubusercontent.com/4aaee136900eb1ece1352fa6ca5b92f37e59801a6fcd0a2345afa73ca44fd5b0/68747470733a2f2f63732d6e6f7465732d313235363130393739362e636f732e61702d6775616e677a686f752e6d7971636c6f75642e636f6d2f34653234383565342d333462642d343936372d396630322d3063303933623739376161612e706e67)



### 3. 电梯算法

> SCAN

电梯总是保持一个方向运行，直到该方向没有请求为止，然后改变运行方向。

电梯算法（扫描算法）和电梯的运行过程类似，**总是按一个方向来进行磁盘调度，直到该方向上没有未完成的磁盘请求，然后改变方向。**

因为考虑了移动方向，因此所有的磁盘请求都会被满足，解决了 SSTF 的饥饿问题。

# 面试题

[这 50 道操作系统面试题，真牛批！](https://cloud.tencent.com/developer/article/1815965)

### ![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/e3ae7a6c28.png)**解释一下什么是操作系统**

**操作系统是管理硬件和软件的一种应用程序**。操作系统是运行在计算机上最重要的一种`软件`，它管理计算机的资源和进程以及所有的硬件和软件。它为计算机硬件和软件提供了一种中间层，使应用软件和硬件进行分离，让我们无需关注硬件的实现，把关注点更多放在软件应用上。

![img](https://ask.qcloudimg.com/http-save/yehe-5359587/h6sz87bsou.png?imageView2/2/w/1620)

通常情况下，计算机上会运行着许多应用程序，它们都需要对内存和 CPU 进行交互，操作系统的目的就是为了保证这些访问和交互能够准确无误的进行。

### **操作系统的主要功能**

一般来说，现代操作系统主要提供下面几种功能

- `进程管理`: **进程管理的主要作用就是任务调度**，在单核处理器下，操作系统会为每个进程分配一个任务，进程管理的工作十分简单；而在多核处理器下，操作系统除了要为进程分配任务外，还要解决处理器的调度、分配和回收等问题
- `内存管理`：**内存管理主要是操作系统负责管理内存的分配、回收**，在进程需要时分配内存以及在进程完成时回收内存，协调内存资源，通过合理的页面置换算法进行页面的换入换出
- `设备管理`：**根据确定的设备分配原则对设备进行分配**，使设备与主机能够并行工作，为用户提供良好的设备使用界面。
- `文件管理`：**有效地管理文件的存储空间**，合理地组织和管理文件系统，为文件访问和文件保护提供更有效的方法及手段。
- `提供用户接口`：**操作系统提供了访问应用程序和硬件的接口**，使用户能够通过应用程序发起系统调用从而操纵硬件，实现想要的功能。

### **软件访问硬件的几种方式**

软件访问硬件其实就是一种 IO 操作，软件访问硬件的方式，也就是 I/O 操作的方式有哪些。

硬件在 I/O 上大致分为**并行和串行**，同时也对应串行接口和并行接口。

随着计算机技术的发展，I/O 控制方式也在不断发展。选择和衡量 I/O 控制方式有如下三条原则

> （1） 数据传送速度足够快，能满足用户的需求但又不丢失数据； （2） 系统开销小，所需的处理控制程序少； （3） 能充分发挥硬件资源的能力，使 I/O 设备尽可能忙，而 CPU 等待时间尽可能少。

根据以上控制原则，I/O 操作可以分为四类

- `直接访问`：直接访问由用户进程**直接控制主存或 CPU 和外围设备之间的信息传送**。直接程序控制方式又称为忙/等待方式。
- `中断驱动`：为了减少程序直接控制方式下 CPU 的等待时间以及提高系统的并行程度，系统**引入了中断机制**。中断机制引入后，**外围设备仅当操作正常结束或异常结束时才向 CPU 发出中断请求**。在 I/O 设备输入每个数据的过程中，由于无需 CPU 的干预，一定程度上实现了 CPU 与 I/O 设备的并行工作。

上述两种方法的特点都是以 `CPU` 为中心，数据传送通过一段程序来实现，软件的传送手段限制了数据传送的速度。接下来介绍的这两种 I/O 控制方式采用硬件的方法来显示 I/O 的控制

- `DMA 直接内存访问`：为了进一步减少 CPU 对 I/O 操作的干预，防止因并行操作设备过多使 CPU 来不及处理或因速度不匹配而造成的数据丢失现象，引入了 DMA 控制方式。
- `通道控制方式`：通道，独立于 CPU 的专门负责输入输出控制的处理机，它控制设备与内存直接进行数据交换。有自己的通道指令，这些指令由 CPU 启动，并在操作结束时向 CPU 发出中断信号。

### **解释一下操作系统的主要目的是什么**

操作系统是一种软件，它的主要目的有三种

- 管理计算机资源，这些资源包括 CPU、内存、磁盘驱动器、打印机等。
- 提供一种图形界面，就像我们前面描述的那样，它提供了用户和计算机之间的桥梁。
- 为其他软件提供服务，操作系统与软件进行交互，以便为其分配运行所需的任何必要资源。

### **操作系统的种类有哪些**

操作系统通常预装在你购买计算机之前。大部分用户都会使用默认的操作系统，但是你也可以升级甚至更改操作系统。但是一般常见的操作系统只有三种：**Windows、macOS 和 Linux**。

### **为什么 Linux 系统下的应用程序不能直接在 Windows 下运行**

这是一个老生常谈的问题了，在这里给出具体的回答。

其中一点是因为 Linux 系统和 Windows 系统的格式不同，**格式就是协议**，就是在固定位置有意义的数据。**Linux 下的可执行程序文件格式是 `elf`**，可以使用 `readelf` 命令查看 elf 文件头。

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/vhj0rkmcem.png)

而 **Windows 下的可执行程序是 `PE` 格式**，它是一种可移植的可执行文件。

还有一点是因为 Linux 系统和 Windows 系统的 `API` 不同，这个 API 指的就是操作系统的 API，Linux 中的 API 被称为`系统调用`，是通过 `int 0x80` 这个软中断实现的。而 Windows 中的 API 是放在动态链接库文件中的，也就是 Windows 开发人员所说的 `DLL` ，这是一个库，里面包含代码和数据。Linux 中的可执行程序获得系统资源的方法和 Windows 不一样，所以显然是不能在 Windows 中运行的。

### **操作系统结构**

#### **单体系统**

在大多数系统中，整个系统在内核态以单一程序的方式运行。整个操作系统是以程序集合来编写的，链接在一块形成一个大的二进制可执行程序，这种系统称为单体系统。

在单体系统中构造实际目标程序时，会首先编译所有单个过程（或包含这些过程的文件），然后使用系统链接器将它们全部绑定到一个可执行文件中

在单体系统中，对于每个系统调用都会有一个服务程序来保障和运行。需要一组实用程序来弥补服务程序需要的功能，例如从用户程序中获取数据。可将各种过程划分为一个三层模型

![img](https://ask.qcloudimg.com/http-save/yehe-5359587/9xsicvk8ft.png)

除了在计算机初启动时所装载的核心操作系统外，许多操作系统还支持额外的扩展。比如 I/O 设备驱动和文件系统。这些部件可以按需装载。在 UNIX 中把它们叫做 `共享库(shared library)`，在 Windows 中则被称为 `动态链接库(Dynamic Link Library,DLL)`。他们的扩展名为 `.dll`，在 `C:\Windows\system32` 目录下存在 1000 多个 DLL 文件，所以不要轻易删除 C 盘文件，否则可能就炸了哦。

#### **分层系统**

分层系统使用层来分隔不同的功能单元。每一层只与该层的上层和下层通信。每一层都使用下面的层来执行其功能。层之间的通信通过预定义的固定接口通信。

![img](https://ask.qcloudimg.com/http-save/yehe-5359587/uwomvbvomg.png)

#### **微内核**

为了实现高可靠性，**将操作系统划分成小的、层级之间能够更好定义的模块**是很有必要的，**只有一个模块 --- 微内核 --- 运行在内核态**，其余模块可以作为普通用户进程运行。由于把每个设备驱动和文件系统分别作为普通用户进程，这些模块中的错误虽然会使这些模块崩溃，但是不会使整个系统死机。

`MINIX 3` 是微内核的代表作，它的具体结构如下

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/jiggkmutnu.png)

在内核的外部，系统的构造有三层，它们都在用户态下运行，最底层是设备驱动器。由于它们都在用户态下运行，所以不能物理的访问 I/O 端口空间，也不能直接发出 I/O 命令。相反，为了能够对 I/O 设备编程，驱动器构建一个结构，指明哪个参数值写到哪个 I/O 端口，并声称一个内核调用，这样就完成了一次调用过程。

#### **客户-**[**服务器**](https://cloud.tencent.com/product/cvm?from=10680)**模式**

微内核思想的策略是把进程划分为两类：`服务器`，每个服务器用来提供服务；`客户端`，使用这些服务。这个模式就是所谓的 `客户-服务器`模式。

客户-服务器模式会有两种载体，一种情况是一台计算机既是客户又是服务器，在这种方式下，操作系统会有某种优化；但是普遍情况下是客户端和服务器在不同的机器上，它们通过局域网或广域网连接。

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/78b8hz43zm.png)

客户通过发送消息与服务器通信，客户端并不需要知道这些消息是在本地机器上处理，还是通过网络被送到远程机器上处理。对于客户端而言，这两种情形是一样的：都是发送请求并得到回应。

### **为什么称为陷入内核**

如果把软件结构进行分层说明的话，应该是这个样子的，最外层是应用程序，里面是操作系统内核。

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/ye4pmvwojz.png)

应用程序处于特权级 3，操作系统内核处于特权级 0 。如果用户程序想要访问操作系统资源时，会发起系统调用，陷入内核，这样 CPU 就进入了内核态，执行内核代码。至于为什么是陷入，我们看图，内核是一个凹陷的构造，有陷下去的感觉，所以称为陷入。

### **什么是用户态和内核态**

用户态和内核态是操作系统的两种运行状态。

- `内核态`：**处于内核态的 CPU 可以访问任意的数据**，包括外围设备，比如网卡、硬盘等，处于内核态的 CPU 可以从一个程序切换到另外一个程序，并且占用 CPU 不会发生抢占情况，一般处于特权级 0 的状态我们称之为内核态。
- `用户态`：处于用户态的 CPU 只能受限的访问内存，并且不允许访问外围设备，用户态下的 CPU 不允许独占，也就是说 CPU 能够被其他程序获取。

> 那么为什么要有用户态和内核态呢？

这个主要是访问能力的限制的考量，计算机中有一些比较危险的操作，比如设置时钟、内存清理，这些都需要在内核态下完成，如果随意进行这些操作，那你的系统得崩溃多少次。

### **用户态和内核态是如何切换的？**

所有的用户进程都是运行在用户态的，但是我们上面也说了，用户程序的访问能力有限，一些比较重要的比如从硬盘读取数据，从键盘获取数据的操作则是内核态才能做的事情，而这些数据却又对用户程序来说非常重要。所以就涉及到两种模式下的转换，即**用户态 -> 内核态 -> 用户态**，而唯一能够做这些操作的只有 `系统调用`，而**能够执行系统调用的就只有 `操作系统`。**

一般用户态 -> 内核态的转换我们都称之为 trap 进内核，也被称之为 `陷阱指令(trap instruction)`。

他们的工作流程如下：

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/brotz73h4a.png)

- 首先用户程序会调用 `glibc` 库，glibc 是一个标准库，同时也是一套核心库，库中定义了很多关键 API。
- glibc 库知道针对不同体系结构调用`系统调用`的正确方法，它会根据体系结构应用程序的二进制接口设置用户进程传递的参数，来准备系统调用。
- 然后，glibc 库调用`软件中断指令(SWI)` ，这个指令通过更新 `CPSR` 寄存器将模式改为超级用户模式，然后跳转到地址 `0x08` 处。
- 到目前为止，整个过程仍处于用户态下，在执行 SWI 指令后，允许进程执行内核代码，MMU 现在允许内核虚拟内存访问
- 从地址 0x08 开始，进程执行加载并跳转到中断处理程序，这个程序就是 ARM 中的 `vector_swi()`。
- 在 vector_swi() 处，从 SWI 指令中提取系统调用号 SCNO，然后使用 SCNO 作为系统调用表 `sys_call_table` 的索引，调转到系统调用函数。
- 执行系统调用完成后，将还原用户模式寄存器，然后再以用户模式执行。

### **什么是内核**

**在计算机中，内核是一个计算机程序，它是操作系统的核心，可以控制操作系统中所有的内容**。内核通常是在 boot loader 装载程序之前加载的第一个程序。

这里还需要了解一下什么是 `boot loader`。

> boot loader 又被称为引导加载程序，能够将计算机的操作系统放入内存中。在电源通电或者计算机重启时，BIOS 会执行一些初始测试，然后将控制权转移到引导加载程序所在的`主引导记录(MBR)` 。

### **什么是实时系统**

实时操作系统对时间做出了严格的要求，实时操作系统分为两种：**硬实时和软实时**

`硬实时操作系统`规定某个动作必须在规定的时刻内完成或发生，比如汽车生产车间，焊接机器必须在某一时刻内完成焊接，焊接的太早或者太晚都会对汽车造成永久性伤害。

`软实时操作系统`虽然不希望偶尔违反最终的时限要求，但是仍然可以接受。并且不会引起任何永久性伤害。比如数字音频、多媒体、手机都是属于软实时操作系统。

你可以简单理解硬实时和软实时的两个指标：**是否在时刻内必须完成以及是否造成严重损害**。

### 操作系统的启动过程

#### Linux

1. BIOS 开机自检，对硬件进行检测和初始化
2. 将磁盘中的第一个分区（MBR 主引导记录，Master Boot Record）读取到一个固定的内存区域并执行
3. 程序从磁盘中调入 boot 独立程序，boot 程序将自身复制到高位地址的内存从而为操作系统释放低位地址的内存
4. boot 程序读取启动设备的根目录

当计算机电源通电后，`BIOS`会进行`开机自检(Power-On-Self-Test, POST)`，**对硬件进行检测和初始化**。因为操作系统的启动会使用到磁盘、屏幕、键盘、鼠标等设备。下一步，磁盘中的第一个分区，也被称为 `MBR(Master Boot Record)` 主引导记录，被读入到一个固定的内存区域并执行。这个分区中有一个非常小的，只有 512 字节的程序。程序从磁盘中调入 boot 独立程序，boot 程序将自身复制到高位地址的内存从而为操作系统释放低位地址的内存。

复制完成后，boot 程序读取启动设备的根目录。boot 程序要理解文件系统和目录格式。**然后 boot 程序被调入内核，把控制权移交给内核**。直到这里，boot 完成了它的工作。系统内核开始运行。

内核启动代码是使用`汇编语言`完成的，主要包括创建内核堆栈、识别 CPU 类型、计算内存、禁用中断、启动内存管理单元等，然后调用 C 语言的 main 函数执行操作系统部分。

这部分也会做很多事情，首先会分配一个消息缓冲区来存放调试出现的问题，调试信息会写入缓冲区。如果调试出现错误，这些信息可以通过诊断程序调出来。

然后操作系统会进行自动配置，检测设备，加载配置文件，被检测设备如果做出响应，就会被添加到已链接的设备表中，如果没有相应，就归为未连接直接忽略。

配置完所有硬件后，接下来要做的就是仔细手工处理进程0，设置其堆栈，然后运行它，执行初始化、配置时钟、挂载文件系统。创建 `init 进程(进程 1 )` 和 `守护进程(进程 2)`。

init 进程会检测它的标志以确定它是否为单用户还是多用户服务。在前一种情况中，它会调用 fork 函数创建一个 shell 进程，并且等待这个进程结束。后一种情况调用 fork 函数创建一个运行系统初始化的 shell 脚本（即 /etc/rc）的进程，这个进程可以进行文件系统一致性检测、挂载文件系统、开启守护进程等。

然后 /etc/rc 这个进程会从 /etc/ttys 中读取数据，/etc/ttys 列出了所有的终端和属性。对于每一个启用的终端，这个进程调用 fork 函数创建一个自身的副本，进行内部处理并运行一个名为 `getty` 的程序。

getty 程序会在终端上输入

```javascript
login:
```

等待用户输入用户名，在输入用户名后，getty 程序结束，登陆程序 `/bin/login` 开始运行。login 程序需要输入密码，并与保存在 `/etc/passwd` 中的密码进行对比，如果输入正确，login 程序以用户 shell 程序替换自身，等待第一个命令。如果不正确，login 程序要求输入另一个用户名。

整个系统启动过程如下

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/5qe2ayh8gk.png)

#### windows

Windows 的启动过程大致可分为5个步骤:预启动,启动,装载内核,初始化内核以及用户登录。下面分别展开介绍：

##### 一.预启动

**首先计算机通电进行自检,并由BIOS(即基本输入输出系统)完成基本硬件配置,然后读取硬盘的MBR(主引导记录)检查硬盘分区表以确定引导分区,并将引导分区上的操作系统引导扇区调入内存中执行,此处即执行NTLDR(操作系统加载器)文件**。

Windows 支持多重启动。它在安装时会首先将已存在的其它操作系统引导扇区保存为BOOTSECT.DOS文件(位于活动分区根目录下),并修改系统引导扇区,以便系统启动时加载NTLDR文件,从而达到多重启动的目的。而Windows 则不具备这个功能，因此如果先装好Windows 后再装Windows 会破坏掉Windows 的引导记录，导致2000/XP不能启动。

##### 二.启动

1.首先进行初始化,NTLDR会把处理器从实模式转换为32位保护模式。

2.读取BOOT.INI文件。该文件位于活动分区根目录下,它的作用是**使系统在启动过程中出现选择菜单,由用户选择希望启动的操作系统**。如果选择启动Windows ,NTLDR会继续引导进行以下过程;如果选择为非Windows 系统,NTLDR则会读取系统引导扇区副本BOTSECT.DOS转入启动相应系统。

其中[BOOT LOADER]即操作系统加载器,指定系统选择菜单默认等待时间和默认引导的操作系统。可手工修改或在控制面板中修改，为了保险起见，建议在控制面板中修改。依次选择控制面板-〉系统-〉高级->启动和故障恢复，即可更改相关设置。(在WindowsXP中还有另一种方法，即运行msconfig（系统配置实用程序）。

[OPERATING SYSTEMS]段指定操作系统列表,由双引号括起来的部分就是列表所显示的内容,可任意修改,使其更加个性化。

形如MULTI(0)DISK(0)RDISK(0)PARTITION(1)格式的语句被称为ARC路径,它的格式为:MULTI()--指定磁盘控制器(若为SCSI控制器,则此处应替换为SCSI())；DISK()--指定SCSI设备编号(对于MULTI该处值始终为0)；RDISK()--指定IDE设备编号(对于SCSI,此处被忽略)；PARTITION()--指定分区编号。除分区编号由1开始外,其余编号均从0开始。

参数/FASTDETECT表示禁用串行鼠标检测,是系统默认值。还有几个常见参数:MAXMEM--指定Windows 可用内存容量;BASEVIDEO--使用标准VGA显示驱动程序;NOGUIBOOT--启动过程中不显示图形屏幕;SOS--加载设备驱动程序时显示其名称。

在操作系统选择菜单中的中文字体由位于活动分区根目录下的BOOTFONT.BIN文件提供。

3.系统加载NTDETECT.COM文件。由它来检测机器硬件,如并行端口,显示适配器等等,并将收集到的硬件列表返回NTLDR用于以后在注册表中注册保存。

4.如果Windows 有多个硬件配置文件,此时会出现选择菜单,等待用户确定要使用的硬件配置文件,否则直接跳过此步,启用默认配置。

 硬件配置文件是指保存计算机特定硬件配置的系统文件。可以创建多个不同的硬件配置文件以满足计算机在不同场合的应用。可以依次选择控制面板-〉系统->硬件-〉硬件配置文件作出修改。

##### 三.装载内核

引导过程开始装载Windows 内核NTOSKRNL.EXE。这个文件位于Windows 安装文件夹下的SYSTEM32文件夹中。随后,硬件抽象层(HAL)被引导进程加载,完成本步骤。

硬件抽象层(HAL):隐藏特定平台的硬件接口细节,为操作系统提供虚拟硬件平台,使其具有硬件无关性,可在多种平台上进行移植。

##### 四.初始化内核

内核完成初始化,NTLDR将控制权转交Windows 内核,后者开始装载并初始化设备驱动程序,以及启动WIN32子系统和Windows 服务。

##### 五.用户登录

开始登录进程。由WIN32子系统启动WINLOGON.EXE,并由它启动LOCAL SECURITY AUTHORITY(LSASS.EXE)显示登录对话框。用户登录后,Windows 会继续配置网络设备和用户环境。最后,伴随着微软之声和我们熟悉的个性化桌面,Windows 漫长的启动过程终于完成。呵，是不是睡着了，醒醒吧，系统启动成功，您现在该干嘛就干嘛！

### 多处理系统的优势

随着处理器的不断增加，我们的计算机系统由单机系统变为了多处理系统，多处理系统的吞吐量比较高，多处理系统拥有多个并行的处理器，这些处理器共享时钟、内存、总线、外围设备等。

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/mjyghoqi6g.png)

多处理系统由于可以共享资源，因此可以开源节流，省钱。整个系统的可靠性也随之提高。

### **什么是进程和进程表**

`进程`就是正在执行程序的实例，比如说 Web 程序就是一个进程，shell 也是一个进程，文章编辑器 typora 也是一个进程。

操作系统负责管理所有正在运行的进程，操作系统会为每个进程分配特定的时间来占用 CPU，操作系统还会为每个进程分配特定的资源。

**操作系统为了跟踪每个进程的活动状态，维护了一个`进程表`**。在进程表的内部，列出了每个进程的状态以及每个进程使用的资源等。

### **什么是线程，线程和进程的区别**

这又是一道老生常谈的问题了，从操作系统的角度来回答一下吧。

我们上面说到进程是正在运行的程序的实例，而线程其实就是进程中的单条流向，因为线程具有进程中的某些属性，所以线程又被称为轻量级的进程。浏览器如果是一个进程的话，那么浏览器下面的每个 tab 页可以看作是一个个的线程。

下面是线程和进程持有资源的区别

![img](https://ask.qcloudimg.com/http-save/yehe-5359587/nlhdwur6gi.png)

线程不像进程那样具有很强的独立性，线程之间会共享数据

创建线程的开销要比进程小很多，因为创建线程仅仅需要`堆栈指针`和`程序计数器`就可以了，而创建进程需要操作系统分配新的地址空间，数据资源等，这个开销比较大。

### **什么是上下文切换**

对于单核单线程 CPU 而言，在某一时刻只能执行一条 CPU 指令。上下文切换 (Context Switch) 是一种 **将 CPU 资源从一个进程分配给另一个进程的机制**。从用户角度看，计算机能够并行运行多个进程，这恰恰是操作系统通过快速上下文切换造成的结果。在切换的过程中，操作系统需要先存储当前进程的状态 (包括内存空间的指针，当前执行完的指令等等)，再读入下一个进程的状态，然后执行此进程。

### **使用多线程的好处是什么**

多线程是程序员不得不知的基本素养之一，所以，下面我们给出一些多线程编程的好处

- 能够提高对用户的响应顺序
- 在流程中的资源共享
- 比较经济适用
- 能够对多线程架构有深入的理解

### **进程终止的方式**

#### **进程的终止**

进程在创建之后，它就开始运行并做完成任务。然而，没有什么事儿是永不停歇的，包括进程也一样。进程早晚会发生终止，但是通常是由于以下情况触发的

- `正常退出(自愿的)`
- `错误退出(自愿的)`
- `严重错误(非自愿的)`
- `被其他进程杀死(非自愿的)`

#### **正常退出**

多数进程是由于完成了工作而终止。当编译器完成了所给定程序的编译之后，**编译器会执行一个系统调用告诉操作系统它完成了工作**。这个调用在 UNIX 中是 `exit` ，在 Windows 中是 `ExitProcess`。面向屏幕中的软件也支持自愿终止操作。字处理软件、Internet 浏览器和类似的程序中总有一个供用户点击的图标或菜单项，用来通知进程删除它所打开的任何临时文件，然后终止。

#### **错误退出**

**进程发生终止的第二个原因是发现严重错误**，例如，如果用户执行如下命令

```javascript
cc foo.c    
```

为了能够编译 foo.c 但是该文件不存在，于是编译器就会发出声明并退出。在给出了错误参数时，面向屏幕的交互式进程通常并不会直接退出，因为这从用户的角度来说并不合理，用户需要知道发生了什么并想要进行重试，所以这时候应用程序通常会弹出一个对话框告知用户发生了系统错误，是需要重试还是退出。

#### **严重错误**

进程终止的第三个原因是**由进程引起的错误，通常是由于程序中的错误所导致的**。例如，执行了一条非法指令，引用不存在的内存，或者除数是 0 等。在有些系统比如 UNIX 中，进程可以通知操作系统，它希望自行处理某种类型的错误，在这类错误中，进程会收到信号（中断），而不是在这类错误出现时直接终止进程。

#### **被其他进程杀死**

第四个终止进程的原因是，某个进程执行系统调用告诉操作系统杀死某个进程。在 UNIX 中，这个系统调用是 kill。在 Win32 中对应的函数是 `TerminateProcess`（注意不是系统调用）。

### **进程间的通信方式**

进程间的通信方式比较多，首先你需要理解下面这几个概念

- 竞态条件：即两个或多个线程同时对一共享数据进行修改，从而影响程序运行的正确性时，这种就被称为`竞态条件(race condition)`。
- 临界区：不仅`共享资源`会造成竞态条件，事实上共享文件、共享内存也会造成竞态条件、那么该如何避免呢？或许一句话可以概括说明：**禁止一个或多个进程在同一时刻对共享资源（包括共享内存、共享文件等）进行读写**。换句话说，我们需要一种 `互斥(mutual exclusion)` 条件，这也就是说，如果一个进程在某种方式下使用共享变量和文件的话，除该进程之外的其他进程就禁止做这种事（访问统一资源）。 一个好的解决方案，应该包含下面四种条件

1. 任何时候两个进程不能同时处于临界区
2. 不应对 CPU 的速度和数量做任何假设
3. 位于临界区外的进程不得阻塞其他进程
4. 不能使任何进程无限等待进入临界区

![img](https://ask.qcloudimg.com/http-save/yehe-5359587/f2wwugaprz.png)

- 忙等互斥：当一个进程在对资源进行修改时，其他进程必须进行等待，进程之间要具有互斥性，我们讨论的解决方案其实都是基于忙等互斥提出的。

进程间的通信用专业一点的术语来表示就是 `Inter Process Communication，IPC`，它主要有下面 7。种通信方式

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/0lkiglz8d0.png)

- `消息传递`：**消息传递是进程间实现通信和同步等待的机制，使用消息传递，进程间的交流不需要共享变量**，直接就可以进行通信；消息传递分为发送方和接收方
- `先进先出队列`：先进先出队列指的是两个不相关联进程间的通信，两个进程之间可以彼此相互进程通信，这是一种**全双工通信方式**
- `管道`：管道用于两个相关进程之间的通信，这是一种**半双工的通信方式**，如果需要全双工，需要另外一个管道。
- `直接通信`：在这种进程通信的方式中，进程与进程之间只存在一条链接，进程间要明确通信双方的命名。
- `间接通信`：**间接通信是通信双方不会直接建立连接，而是找到一个中介者**，这个中介者可能是个对象等等，进程可以在其中放置消息，并且可以从中删除消息，以此达到进程间通信的目的。
- `消息队列`：[消息队列](https://cloud.tencent.com/product/cmq?from=10680)是内核中存储消息的链表，它由消息队列标识符进行标识，这种方式能够在不同的进程之间提供全双工的通信连接。
- `共享内存`：共享内存是使用所有进程之间的内存来建立连接，这种类型需要同步进程访问来相互保护。

### **进程间状态模型**

#### **进程的三态模型**

当一个进程开始运行时，它可能会经历下面这几种状态

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/x0nt940j82.png)

图中会涉及三种状态

1. `运行态`：运行态指的就是进程实际占用 CPU 时间片运行时
2. `就绪态`：就绪态指的是可运行，但因为其他进程正在运行而处于就绪状态
3. `阻塞态`：阻塞态又被称为睡眠态，它指的是进程不具备运行条件，正在等待被 CPU 调度。

逻辑上来说，运行态和就绪态是很相似的。这两种情况下都表示进程`可运行`，但是第二种情况没有获得 CPU 时间分片。第三种状态与前两种状态不同的原因是这个进程不能运行，CPU 空闲时也不能运行。

三种状态会涉及四种状态间的切换，在操作系统发现进程不能继续执行时会发生`状态1`的轮转，在某些系统中进程执行系统调用，例如 `pause`，来获取一个阻塞的状态。在其他系统中包括 UNIX，当进程从管道或特殊文件（例如终端）中读取没有可用的输入时，该进程会被自动终止。

转换 2 和转换 3 都是由进程调度程序（操作系统的一部分）引起的，进程本身不知道调度程序的存在。转换 2 的出现说明进程调度器认定当前进程已经运行了足够长的时间，是时候让其他进程运行 CPU 时间片了。当所有其他进程都运行过后，这时候该是让第一个进程重新获得 CPU 时间片的时候了，就会发生转换。

> **程序调度指的是，决定哪个进程优先被运行和运行多久，这是很重要的一点**。已经设计出许多算法来尝试平衡系统整体效率与各个流程之间的竞争需求。

当进程等待的一个外部事件发生时（如从外部输入一些数据后），则发生转换 4。如果此时没有其他进程在运行，则立刻触发转换 3，该进程便开始运行，否则该进程会处于就绪阶段，等待 CPU 空闲后再轮到它运行。

#### **进程的五态模型**

在三态模型的基础上，增加了两个状态，即 `新建` 和 `终止` 状态。

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/gnuec6z6yo.png)

- 新建态：进程的新建态就是进程刚创建出来的时候

> 创建进程需要两个步骤：即为新进程分配所需要的资源和空间，设置进程为就绪态，并等待调度执行。

- 终止态：进程的终止态就是指进程执行完毕，到达结束点，或者因为错误而不得不中止进程。

> 终止一个进程需要两个步骤：

1. 先等待操作系统或相关的进程进行善后处理。
2. 然后回收占用的资源并被系统删除。

### **调度算法都有哪些**

调度算法分为三大类：批处理中的调度、交互系统中的调度、实时系统中的调度

#### **批处理中的调度**

#### **先来先服务**

很像是先到先得。。。可能最简单的非抢占式调度算法的设计就是 `先来先服务(first-come,first-serverd)`。使用此算法，将按照请求顺序为进程分配 CPU。最基本的，会有一个就绪进程的等待队列。当第一个任务从外部进入系统时，将会立即启动并允许运行任意长的时间。它不会因为运行时间太长而中断。当其他作业进入时，它们排到就绪队列尾部。当正在运行的进程阻塞，处于等待队列的第一个进程就开始运行。当一个阻塞的进程重新处于就绪态时，它会像一个新到达的任务，会排在队列的末尾，即排在所有进程最后。

![img](https://ask.qcloudimg.com/http-save/yehe-5359587/ftjug5v1dr.png)

这个算法的强大之处在于易于理解和编程，在这个算法中，一个单链表记录了所有就绪进程。要选取一个进程运行，只要从该队列的头部移走一个进程即可；要添加一个新的作业或者阻塞一个进程，只要把这个作业或进程附加在队列的末尾即可。这是很简单的一种实现。

不过，先来先服务也是有缺点的，那就是没有优先级的关系，试想一下，如果有 100 个 I/O 进程正在排队，第 101 个是一个 CPU 密集型进程，那岂不是需要等 100 个 I/O 进程运行完毕才会等到一个 CPU 密集型进程运行，这在实际情况下根本不可能，所以需要优先级或者抢占式进程的出现来优先选择重要的进程运行。

#### **最短作业优先**

批处理中，第二种调度算法是 `最短作业优先(Shortest Job First)`，我们假设运行时间已知。例如，一家保险公司，因为每天要做类似的工作，所以人们可以相当精确地预测处理 1000 个索赔的一批作业需要多长时间。当输入队列中有若干个同等重要的作业被启动时，调度程序应使用最短优先作业算法

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/law8saslcm.png)

如上图 a 所示，这里有 4 个作业 A、B、C、D ，运行时间分别为 8、4、4、4 分钟。若按图中的次序运行，则 A 的周转时间为 8 分钟，B 为 12 分钟，C 为 16 分钟，D 为 20 分钟，平均时间内为 14 分钟。

现在考虑使用最短作业优先算法运行 4 个作业，如上图 b 所示，目前的周转时间分别为 4、8、12、20，平均为 11 分钟，可以证明最短作业优先是最优的。考虑有 4 个作业的情况，其运行时间分别为 a、b、c、d。第一个作业在时间 a 结束，第二个在时间 a + b 结束，以此类推。平均周转时间为 (4a + 3b + 2c + d) / 4 。显然 a 对平均值的影响最大，所以 a 应该是最短优先作业，其次是 b，然后是 c ，最后是 d 它就只能影响自己的周转时间了。

> 需要注意的是，在所有的进程都可以运行的情况下，最短作业优先的算法才是最优的。

#### **最短剩余时间优先**

最短作业优先的抢占式版本被称作为 `最短剩余时间优先(Shortest Remaining Time Next)` 算法。使用这个算法，调度程序总是选择剩余运行时间最短的那个进程运行。当一个新作业到达时，其整个时间同当前进程的剩余时间做比较。如果新的进程比当前运行进程需要更少的时间，当前进程就被挂起，而运行新的进程。这种方式能够使短期作业获得良好的服务。

### **交互式系统中的调度**

交互式系统中在个人计算机、服务器和其他系统中都是很常用的，所以有必要来探讨一下交互式调度

#### **轮询调度**

一种最古老、最简单、最公平并且最广泛使用的算法就是 `轮询算法(round-robin)`。每个进程都会被分配一个时间段，称为`时间片(quantum)`，在这个时间片内允许进程运行。如果时间片结束时进程还在运行的话，则抢占一个 CPU 并将其分配给另一个进程。如果进程在时间片结束前阻塞或结束，则 CPU 立即进行切换。轮询算法比较容易实现。调度程序所做的就是维护一个可运行进程的列表，就像下图中的 a，当一个进程用完时间片后就被移到队列的末尾，就像下图的 b。

![img](https://ask.qcloudimg.com/http-save/yehe-5359587/yj3xq7lgzz.png)

#### **优先级调度**

事实情况是不是所有的进程都是优先级相等的。例如，在一所大学中的等级制度，首先是院长，然后是教授、秘书、后勤人员，最后是学生。这种将外部情况考虑在内就实现了`优先级调度(priority scheduling)`

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/0oliyl0j7t.png)

它的基本思想很明确，每个进程都被赋予一个优先级，优先级高的进程优先运行。

但是也不意味着高优先级的进程能够永远一直运行下去，调度程序会在每个时钟中断期间降低当前运行进程的优先级。如果此操作导致其优先级降低到下一个最高进程的优先级以下，则会发生进程切换。或者，可以为每个进程分配允许运行的最大时间间隔。当时间间隔用完后，下一个高优先级的进程会得到运行的机会。

#### **最短进程优先**

对于批处理系统而言，由于最短作业优先常常伴随着最短响应时间，一种方式是根据进程过去的行为进行推测，并执行估计运行时间最短的那一个。假设每个终端上每条命令的预估运行时间为 `T0`，现在假设测量到其下一次运行时间为 `T1`，可以用两个值的加权来改进估计时间，即`aT0+ (1- 1)T1`。通过选择 a 的值，可以决定是尽快忘掉老的运行时间，还是在一段长时间内始终记住它们。当 a = 1/2 时，可以得到下面这个序列

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/b9kzd7y1eu.png)

可以看到，在三轮过后，T0 在新的估计值中所占比重下降至 1/8。

有时把这种通过当前测量值和先前估计值进行加权平均从而得到下一个估计值的技术称作 `老化(aging)`。这种方法会使用很多预测值基于当前值的情况。

#### **彩票调度**

有一种既可以给出预测结果而又有一种比较简单的实现方式的算法，就是 `彩票调度(lottery scheduling)`算法。他的基本思想为进程提供各种系统资源的`彩票`。当做出一个调度决策的时候，就随机抽出一张彩票，拥有彩票的进程将获得资源。比如在 CPU 进行调度时，系统可以每秒持有 50 次抽奖，每个中奖进程会获得额外运行时间的奖励。

> 可以把彩票理解为 buff，这个 buff 有 15% 的几率能让你产生 `速度之靴` 的效果。

#### **公平分享调度**

如果用户 1 启动了 9 个进程，而用户 2 启动了一个进程，使用轮转或相同优先级调度算法，那么用户 1 将得到 90 % 的 CPU 时间，而用户 2 将之得到 10 % 的 CPU 时间。

为了阻止这种情况的出现，一些系统在调度前会把进程的拥有者考虑在内。在这种模型下，每个用户都会分配一些CPU 时间，而调度程序会选择进程并强制执行。因此如果两个用户每个都会有 50% 的 CPU 时间片保证，那么无论一个用户有多少个进程，都将获得相同的 CPU 份额。

### **影响调度程序的指标是什么**

会有下面几个因素决定调度程序的好坏

- CPU 使用率：

CPU 正在执行任务（即不处于空闲状态）的时间百分比。

- 等待时间

这是进程轮流执行的时间，也就是进程切换的时间

- 吞吐量

单位时间内完成进程的数量

- 响应时间

这是从提交流程到获得有用输出所经过的时间。

- 周转时间

从提交流程到完成流程所经过的时间。

### **什么是 RR 调度算法**

轮询算法，`RR(round-robin)` 调度算法主要针对分时系统，RR 的调度算法会把时间片以相同的部分并循环的分配给每个进程，RR 调度算法没有优先级的概念。这种算法的实现比较简单，而且每个线程都会占有时间片，并不存在线程饥饿的问题。



### **什么是按需分页**

在操作系统中，**进程是以页为单位加载到内存中的**，按需分页是一种`虚拟内存`的管理方式。在使用请求分页的系统中，只有在尝试访问页面所在的磁盘并且该页面尚未在内存中时，也就发生了`缺页异常`，操作系统才会将磁盘页面复制到内存中。

### **什么是虚拟内存**

`虚拟内存`是一种内存分配方案，是一项可以用来辅助内存分配的机制。我们知道，应用程序是按页装载进内存中的。但并不是所有的页都会装载到内存中，计算机中的硬件和软件会将数据从 RAM 临时传输到磁盘中来弥补内存的不足。如果没有虚拟内存的话，一旦你将计算机内存填满后，计算机会对你说

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/kqvt5e0ie1.png)

呃，不，**对不起，您无法再加载任何应用程序，请关闭另一个应用程序以加载新的应用程序**。对于虚拟内存，计算机可以执行操作是查看内存中最近未使用过的区域，然后将其复制到硬盘上。虚拟内存通过复制技术实现了 **妹子，你快来看哥哥能装这么多程序** 的资本。复制是自动进行的，你无法感知到它的存在。

### **虚拟内存的实现方式**

虚拟内存中，允许将一个作业分多次调入内存。釆用连续分配方式时，会使相当一部分内存空间都处于暂时或`永久`的空闲状态，造成内存资源的严重浪费，而且也无法从逻辑上扩大内存容量。因此，虚拟内存的实需要建立在离散分配的内存管理方式的基础上。虚拟内存的实现有以下三种方式：

- 请求分页存储管理。
- 请求分段存储管理。
- 请求段页式存储管理。

不管哪种方式，都需要有一定的硬件支持。一般需要的支持有以下几个方面：

- 一定容量的内存和外存。
- 页表机制（或段表机制），作为主要的数据结构。
- 中断机构，当用户程序要访问的部分尚未调入内存，则产生中断。
- 地址变换机构，逻辑地址到物理地址的变换。

### **内存为什么要分段**

内存是随机访问设备，对于内存来说，不需要从头开始查找，只需要直接给出地址即可。内存的分段是从 `8086 CPU` 开始的，8086 的 CPU 还是 16 位的寄存器宽，16 位的寄存器可以存储的数字范围是 2 的 16 次方，即 64 KB，8086 的 CPU 还没有 `虚拟地址`，只有物理地址，也就是说，**如果两个相同的程序编译出来的地址相同，那么这两个程序是无法同时运行的**。为了解决这个问题，操作系统设计人员提出了让 CPU 使用 `段基址 + 段内偏移` 的方式来访问任意内存。这样的好处是让程序可以 `重定位`，**这也是内存为什么要分段的第一个原因**。

> 那么什么是重定位呢？

简单来说就是将程序中的指令地址改为另一个地址，地址处存储的内容还是原来的。

CPU 采用段基址 + 段内偏移地址的形式访问内存，就需要提供专门的寄存器，这些专门的寄存器就是 **CS、DS、ES 等**，如果你对寄存器不熟悉，可以看我的这一篇文章。

[爱了爱了，这篇寄存器讲的有点意思](https://mp.weixin.qq.com/s?__biz=MzI0ODk2NDIyMQ==&mid=2247486191&idx=1&sn=ae26d8c42dc4317659232345e576ebaa&chksm=e999fffddeee76eb05ba3bcda5e6fd9c6c170a77cab414ae23e7879d7c3e18104e006a2af4e2&token=620789124&lang=zh_CN&scene=21#wechat_redirect)

也就是说，程序中需要用到哪块内存，就需要先加载合适的段到段基址寄存器中，再给出相对于该段基址的段偏移地址即可。CPU 中的地址加法器会将这两个地址进行合并，从地址总线送入内存。

8086 的 CPU 有 20 根地址总线，最大的寻址能力是 1MB，而段基址所在的寄存器宽度只有 16 位，最大为你 64 KB 的寻址能力，64 KB 显然不能满足 1MB 的最大寻址范围，所以就要把内存分段，每个段的最大寻址能力是 64KB，但是仍旧不能达到最大 1 MB 的寻址能力，所以这时候就需要 `偏移地址`的辅助，偏移地址也存入寄存器，同样为 64 KB 的寻址能力，这么一看还是不能满足 1MB 的寻址，所以 CPU 的设计者对地址单元动了手脚，将段基址左移 4 位，然后再和 16 位的段内偏移地址相加，就达到了 1MB 的寻址能力。**所以内存分段的第二个目的就是能够访问到所有内存**。

### **物理地址、逻辑地址、有效地址、线性地址、虚拟地址的区别**

**物理地址就是内存中真正的地址**，它就相当于是你家的门牌号，你家就肯定有这个门牌号，具有唯一性。**不管哪种地址，最终都会映射为物理地址**。

在`实模式`下，段基址 + 段内偏移经过地址加法器的处理，经过地址总线传输，最终也会转换为`物理地址`。

但是在`保护模式`下，**段基址 + 段内偏移被称为`线性地址`**，不过此时的段基址不能称为真正的地址，而是会被称作为一个`选择子`的东西，选择子就是个索引，相当于数组的下标，通过这个索引能够在 GDT 中找到相应的段描述符，段描述符记录了**段的起始、段的大小**等信息，这样便得到了基地址。如果此时没有开启内存分页功能，那么这个线性地址可以直接当做物理地址来使用，直接访问内存。**如果开启了分页功能，那么这个线性地址又多了一个名字，这个名字就是`虚拟地址`**。

不论在实模式还是保护模式下，**段内偏移地址都叫做`有效地址`。有效抵制也是逻辑地址**。

线性地址可以看作是`虚拟地址`，虚拟地址不是真正的物理地址，但是虚拟地址会最终被映射为物理地址。下面是虚拟地址 -> 物理地址的映射。

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/kozire9g0f.png)

### **空闲内存管理的方式**

操作系统在动态分配内存时（malloc，new），需要对空间内存进行管理。一般采用了两种方式：位图和空闲链表。

#### **使用位图进行管理**

使用位图方法时，内存可能被划分为小到几个字或大到几千字节的分配单元。每个分配单元对应于位图中的一位，0 表示空闲， 1 表示占用（或者相反）。一块内存区域和其对应的位图如下

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/5bhcgoauj7.png)

> 图 a 表示一段有 5 个进程和 3 个空闲区的内存，刻度为内存分配单元，阴影区表示空闲（在位图中用 0 表示）；图 b 表示对应的位图；图 c 表示用链表表示同样的信息

分配单元的大小是一个重要的设计因素，分配单位越小，位图越大。然而，即使只有 4 字节的分配单元，32 位的内存也仅仅只需要位图中的 1 位。`32n` 位的内存需要 n 位的位图，所以**1 个位图只占用了 1/32 的内存**。如果选择更大的内存单元，位图应该要更小。如果进程的大小不是分配单元的整数倍，那么在最后一个分配单元中会有大量的内存被浪费。

`位图`提供了一种简单的方法在固定大小的内存中跟踪内存的使用情况，因为**位图的大小取决于内存和分配单元的大小**。这种方法有一个问题，当决定为把具有 k 个分配单元的进程放入内存时，`内容管理器(memory manager)` 必须搜索位图，在位图中找出能够运行 k 个连续 0 位的串。在位图中找出制定长度的连续 0 串是一个很耗时的操作，这是位图的缺点。（可以简单理解为在杂乱无章的数组中，找出具有一大长串空闲的数组单元）

#### **使用空闲链表**

另一种记录内存使用情况的方法是，维护一个记录已分配内存段和空闲内存段的链表，段会包含进程或者是两个进程的空闲区域。可用上面的图 c **来表示内存的使用情况**。链表中的每一项都可以代表一个 `空闲区(H)` 或者是`进程(P)`的起始标志，长度和下一个链表项的位置。

在这个例子中，`段链表(segment list)`是按照地址排序的。这种方式的优点是，当进程终止或被交换时，更新列表很简单。一个终止进程通常有两个邻居（除了内存的顶部和底部外）。相邻的可能是进程也可能是空闲区，它们有四种组合方式。

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/bedpgjmmgr.png)

当按照地址顺序在链表中存放进程和空闲区时，有几种算法可以为创建的进程（或者从磁盘中换入的进程）分配内存。

- 首次适配算法：在链表中进行搜索，直到找到最初的一个足够大的空闲区，将其分配。除非进程大小和空间区大小恰好相同，否则会将空闲区分为两部分，一部分为进程使用，一部分成为新的空闲区。该方法是速度很快的算法，因为索引链表结点的个数较少。
- 下次适配算法：工作方式与首次适配算法相同，但每次找到新的空闲区位置后都记录当前位置，下次寻找空闲区从上次结束的地方开始搜索，而不是与首次适配一样从头开始；
- 最佳适配算法：搜索整个链表，找出能够容纳进程分配的最小的空闲区。这样存在的问题是，尽管可以保证为进程找到一个最为合适的空闲区进行分配，但大多数情况下，这样的空闲区被分为两部分，一部分用于进程分配，一部分会生成很小的空闲区，而这样的空闲区很难再被进行利用。
- 最差适配算法：与最佳适配算法相反，每次分配搜索最大的空闲区进行分配，从而可以使得空闲区拆分得到的新的空闲区可以更好的被进行利用。

### **页面置换算法都有哪些**

在地址映射过程中，如果在页面中发现所要访问的页面不在内存中，那么就会产生一条缺页中断。当发生缺页中断时，如果操作系统内存中没有空闲页面，那么操作系统必须在内存选择一个页面将其移出内存，以便为即将调入的页面让出空间。而用来选择淘汰哪一页的规则叫做页面置换算法。

下面我汇总的这些页面置换算法比较齐全，只给出简单介绍，算法具体的实现和原理读者可以自行了解。

![img](https://ask.qcloudimg.com/http-save/yehe-5359587/b4j05hgag9.png)

- `最优算法`在当前页面中置换最后要访问的页面。不幸的是，没有办法来判定哪个页面是最后一个要访问的，`因此实际上该算法不能使用`。然而，它可以作为衡量其他算法的标准。
- `NRU` 算法根据 R 位和 M 位的状态将页面分为四类。从编号最小的类别中随机选择一个页面。NRU 算法易于实现，但是性能不是很好。存在更好的算法。
- `FIFO` 会跟踪页面加载进入内存中的顺序，并把页面放入一个链表中。有可能删除存在时间最长但是还在使用的页面，因此这个算法也不是一个很好的选择。
- `第二次机会`算法是对 FIFO 的一个修改，它会在删除页面之前检查这个页面是否仍在使用。如果页面正在使用，就会进行保留。这个改进大大提高了性能。
- `时钟` 算法是第二次机会算法的另外一种实现形式，时钟算法和第二次算法的性能差不多，但是会花费更少的时间来执行算法。
- `LRU` 算法是一个非常优秀的算法，但是没有`特殊的硬件(TLB)`很难实现。如果没有硬件，就不能使用 LRU 算法。
- `NFU` 算法是一种近似于 LRU 的算法，它的性能不是非常好。
- `老化` 算法是一种更接近 LRU 算法的实现，并且可以更好的实现，因此是一个很好的选择
- 最后两种算法都使用了工作集算法。工作集算法提供了合理的性能开销，但是它的实现比较复杂。`WSClock` 是另外一种变体，它不仅能够提供良好的性能，而且可以高效地实现。

**最好的算法是老化算法和WSClock算法**。他们分别是基于 LRU 和工作集算法。他们都具有良好的性能并且能够被有效的实现。还存在其他一些好的算法，但实际上这两个可能是最重要的。



### **提高文件系统性能的方式**

访问磁盘的效率要比内存慢很多，是时候又祭出这张图了

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/dv6lp5lnkh.png)

所以磁盘优化是很有必要的，下面我们会讨论几种优化方式

#### **高速缓存**

最常用的减少磁盘访问次数的技术是使用 `块高速缓存(block cache)` 或者 `缓冲区高速缓存(buffer cache)`。高速缓存指的是一系列的块，它们在逻辑上属于磁盘，但实际上基于性能的考虑被保存在内存中。

管理高速缓存有不同的算法，**常用的算法是：检查全部的读请求，查看在高速缓存中是否有所需要的块**。如果存在，可执行读操作而无须访问磁盘。如果检查块不再高速缓存中，那么首先把它读入高速缓存，再复制到所需的地方。之后，对同一个块的请求都通过`高速缓存`来完成。

高速缓存的操作如下图所示

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/2r1tbox8ru.png)

由于在高速缓存中有许多块，所以需要某种方法快速确定所需的块是否存在。常用方法是**将设备和磁盘地址进行散列操作**。然后在散列表中查找结果。具有相同散列值的块在一个链表中连接在一起（这个数据结构是不是很像 HashMap?），这样就可以沿着冲突链查找其他块。

如果高速缓存`已满`，此时需要调入新的块，则要把原来的某一块调出高速缓存，如果要调出的块在上次调入后已经被修改过，则需要把它写回磁盘。这种情况与分页非常相似。

#### **块提前读**

第二个明显提高文件系统的性能是**在需要用到块之前试图提前将其写入高速缓存从而提高命中率**。许多文件都是`顺序读取`。如果请求文件系统在某个文件中生成块 k，文件系统执行相关操作并且在完成之后，会检查高速缓存，以便确定块 k + 1 是否已经在高速缓存。如果不在，文件系统会为 k + 1 安排一个预读取，因为文件希望在用到该块的时候能够直接从高速缓存中读取。

当然，块提前读取策略只适用于实际顺序读取的文件。对随机访问的文件，提前读丝毫不起作用。甚至还会造成阻碍。

#### **减少磁盘臂运动**

高速缓存和块提前读并不是提高文件系统性能的唯一方法。另一种重要的技术是**把有可能顺序访问的块放在一起，当然最好是在同一个柱面上，从而减少磁盘臂的移动次数**。当写一个输出文件时，文件系统就必须按照要求一次一次地分配磁盘块。如果用位图来记录空闲块，并且整个位图在内存中，那么选择与前一块最近的空闲块是很容易的。如果用空闲表，并且链表的一部分存在磁盘上，要分配紧邻的空闲块就会困难很多。

不过，即使采用空闲表，也可以使用 `块簇` 技术。即不用块而用连续块簇来跟踪磁盘存储区。如果一个扇区有 512 个字节，有可能系统采用 1 KB 的块（2 个扇区），但却按每 2 块（4 个扇区）一个单位来分配磁盘存储区。这和 2 KB 的磁盘块并不相同，因为在高速缓存中它仍然使用 1 KB 的块，磁盘与内存数据之间传送也是以 1 KB 进行，但在一个空闲的系统上顺序读取这些文件，寻道的次数可以减少一半，从而使文件系统的性能大大改善。若考虑旋转定位则可以得到这类方法的变体。在分配块时，系统尽量把一个文件中的连续块存放在同一个柱面上。

在使用 inode 或任何类似 inode 的系统中，另一个性能瓶颈是，读取一个很短的文件也需要两次磁盘访问：**一次是访问 inode，一次是访问块**。通常情况下，inode 的放置如下图所示

![img](https://ask.qcloudimg.com/http-save/yehe-5359587/lmiral4s87.png)

其中，全部 inode 放在靠近磁盘开始位置，所以 inode 和它所指向的块之间的平均距离是柱面组的一半，这将会需要较长时间的寻道时间。

一个简单的改进方法是，在磁盘中部而不是开始处存放 inode ，此时，在 inode 和第一个块之间的寻道时间减为原来的一半。另一种做法是：将磁盘分成多个柱面组，每个柱面组有自己的 inode，数据块和空闲表，如上图 b 所示。

当然，只有在磁盘中装有磁盘臂的情况下，讨论寻道时间和旋转时间才是有意义的。现在越来越多的电脑使用 `固态硬盘(SSD)`，对于这些硬盘，由于采用了和闪存同样的制造技术，使得随机访问和顺序访问在传输速度上已经较为相近，传统硬盘的许多问题就消失了。但是也引发了新的问题。

#### **磁盘碎片整理**

在初始安装操作系统后，文件就会被不断的创建和清除，于是磁盘会产生很多的碎片，在创建一个文件时，它使用的块会散布在整个磁盘上，降低性能。删除文件后，回收磁盘块，可能会造成空穴。

磁盘性能可以通过如下方式恢复：移动文件使它们相互挨着，并把所有的至少是大部分的空闲空间放在一个或多个大的连续区域内。Windows 有一个程序 `defrag` 就是做这个事儿的。Windows 用户会经常使用它，SSD 除外。

磁盘碎片整理程序会在让文件系统上很好地运行。Linux 文件系统（特别是 ext2 和 ext3）由于其选择磁盘块的方式，在磁盘碎片整理上一般不会像 Windows 一样困难，因此很少需要手动的磁盘碎片整理。而且，固态硬盘并不受磁盘碎片的影响，事实上，在固态硬盘上做磁盘碎片整理反倒是多此一举，不仅没有提高性能，反而磨损了固态硬盘。所以碎片整理只会缩短固态硬盘的寿命。

### **磁盘臂调度算法**

一般情况下，影响磁盘快读写的时间由下面几个因素决定

- 寻道时间 - 寻道时间指的就是将磁盘臂移动到需要读取磁盘块上的时间
- 旋转延迟 - 等待合适的扇区旋转到磁头下所需的时间
- 实际数据的读取或者写入时间

这三种时间参数也是磁盘寻道的过程。一般情况下，寻道时间对总时间的影响最大，所以，有效的降低寻道时间能够提高磁盘的读取速度。

如果磁盘驱动程序每次接收一个请求并按照接收顺序完成请求，这种处理方式也就是 `先来先服务(First-Come, First-served, FCFS)` ，这种方式很难优化寻道时间。因为每次都会按照顺序处理，不管顺序如何，有可能这次读完后需要等待一个磁盘旋转一周才能继续读取，而其他柱面能够马上进行读取，这种情况下每次请求也会排队。

通常情况下，磁盘在进行寻道时，其他进程会产生其他的磁盘请求。磁盘驱动程序会维护一张表，表中会记录着柱面号当作索引，每个柱面未完成的请求会形成链表，链表头存放在表的相应表项中。

一种对先来先服务的算法改良的方案是使用 `最短路径优先(SSF)` 算法，下面描述了这个算法。

假如我们在对磁道 6 号进行寻址时，同时发生了对 11 , 2 , 4, 14, 8, 15, 3 的请求，如果采用先来先服务的原则，如下图所示

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/79yeo57mjj.png)

我们可以计算一下磁盘臂所跨越的磁盘数量为 5 + 9 + 2 + 10 + 6 + 7 + 12 = 51，相当于是跨越了 51 次盘面，如果使用最短路径优先，我们来计算一下跨越的盘面

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/up4o3532go.png)

跨越的磁盘数量为 4 + 1 + 1 + 4 + 3 + 3 + 1 = 17 ，相比 51 足足省了两倍的时间。

但是，最短路径优先的算法也不是完美无缺的，这种算法照样存在问题，那就是`优先级` 问题，

这里有一个原型可以参考就是我们日常生活中的电梯，电梯使用一种`电梯算法(elevator algorithm)` 来进行调度，从而满足协调效率和公平性这两个相互冲突的目标。电梯一般会保持向一个方向移动，直到在那个方向上没有请求为止，然后改变方向。

电梯算法需要维护一个`二进制位`，也就是当前的方向位：`UP(向上)`或者是 `DOWN(向下)`。当一个请求处理完成后，磁盘或电梯的驱动程序会检查该位，如果此位是 UP 位，磁盘臂或者电梯仓移到下一个更高跌未完成的请求。如果高位没有未完成的请求，则取相反方向。当方向位是 `DOWN`时，同时存在一个低位的请求，磁盘臂会转向该点。如果不存在的话，那么它只是停止并等待。

我们举个例子来描述一下电梯算法，比如各个柱面得到服务的顺序是 4，7，10，14，9，6，3，1 ，那么它的流程图如下

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/atu3v10lud.png)

所以电梯算法需要跨越的盘面数量是 3 + 3 + 4 + 5 + 3 + 3 + 1 = 22

电梯算法通常情况下不如 SSF 算法。

一些磁盘控制器为软件提供了一种检查磁头下方当前扇区号的方法，使用这样的控制器，能够进行另一种优化。如果对一个相同的柱面有两个或者多个请求正等待处理，驱动程序可以发出请求读写下一次要通过磁头的扇区。

> 这里需要注意一点，当一个柱面有多条磁道时，相继的请求可能针对不同的磁道，这种选择没有代价，因为选择磁头不需要移动磁盘臂也没有旋转延迟。

对于磁盘来说，最影响性能的就是寻道时间和旋转延迟，所以一次只读取一个或两个扇区的效率是非常低的。出于这个原因，许多磁盘控制器总是读出多个扇区并进行高速缓存，即使只请求一个扇区时也是这样。一般情况下读取一个扇区的同时会读取该扇区所在的磁道或者是所有剩余的扇区被读出，读出扇区的数量取决于控制器的高速缓存中有多少可用的空间。

磁盘控制器的高速缓存和操作系统的高速缓存有一些不同，磁盘控制器的高速缓存用于缓存没有实际被请求的块，而操作系统维护的高速缓存由显示地读出的块组成，并且操作系统会认为这些块在近期仍然会频繁使用。

当同一个控制器上有多个驱动器时，操作系统应该为每个驱动器都单独的维护一个未完成的请求表。一旦有某个驱动器闲置时，就应该发出一个寻道请求来将磁盘臂移到下一个被请求的柱面。如果下一个寻道请求到来时恰好没有磁盘臂处于正确的位置，那么驱动程序会在刚刚完成传输的驱动器上发出一个新的寻道命令并等待，等待下一次中断到来时检查哪个驱动器处于闲置状态。

### **RAID 的不同级别**

RAID 称为 `磁盘冗余阵列`，简称 `磁盘阵列`。利用虚拟化技术把多个硬盘结合在一起，成为一个或多个磁盘阵列组，目的是提升性能或数据冗余。

RAID 有不同的级别

- RAID 0 - 无容错的条带化磁盘阵列
- RAID 1 - 镜像和双工
- RAID 2 - 内存式纠错码
- RAID 3 - 比特交错奇偶校验
- RAID 4 - 块交错奇偶校验
- RAID 5 - 块交错分布式奇偶校验
- RAID 6 - P + Q冗余



### **操作系统中的时钟是什么**

`时钟(Clocks)` 也被称为`定时器(timers)`，时钟/定时器对任何程序系统来说都是必不可少的。时钟负责维护时间、防止一个进程长期占用 CPU 时间等其他功能。`时钟软件(clock software)` 也是一种设备驱动的方式。下面我们就来对时钟进行介绍，一般都是先讨论硬件再介绍软件，采用由下到上的方式，也是告诉你，底层是最重要的。

#### **时钟硬件**

在计算机中有两种类型的时钟，这些时钟与现实生活中使用的时钟完全不一样。

- 比较简单的一种时钟被连接到 110 V 或 220 V 的电源线上，这样每个`电压周期`会产生一个中断，大概是 50 - 60 HZ。这些时钟过去一直占据支配地位。
- 另外的一种时钟由晶体振荡器、计数器和寄存器组成，示意图如下所示

![img](https://ask.qcloudimg.com/http-save/yehe-5359587/zlvaglegor.png)

这种时钟称为`可编程时钟` ，可编程时钟有两种模式，一种是 `一键式(one-shot mode)`，当时钟启动时，会把存储器中的值复制到计数器中，然后，每次晶体的振荡器的脉冲都会使计数器 -1。当计数器变为 0 时，会产生一个中断，并停止工作，直到软件再一次显示启动。还有一种模式是 `方波(square-wave mode)` 模式，在这种模式下，当计数器变为 0 并产生中断后，存储寄存器的值会自动复制到计数器中，这种周期性的中断称为一个时钟周期。

### **设备控制器的主要功能**

设备控制器是一个`可编址`的设备，当它仅控制一个设备时，它只有一个唯一的设备地址；如果设备控制器控制多个可连接设备时，则应含有多个设备地址，并使每一个设备地址对应一个设备。

设备控制器主要分为两种：字符设备和块设备

设备控制器的主要功能有下面这些

- 接收和识别命令：设备控制器可以接受来自 CPU 的指令，并进行识别。设备控制器内部也会有寄存器，用来存放指令和参数
- 进行数据交换：CPU、控制器和设备之间会进行数据的交换，CPU 通过总线把指令发送给控制器，或从控制器中并行地读出数据；控制器将数据写入指定设备。
- 地址识别：每个硬件设备都有自己的地址，设备控制器能够识别这些不同的地址，来达到控制硬件的目的，此外，为使 CPU 能向寄存器中写入或者读取数据，这些寄存器都应具有唯一的地址。
- 差错检测：设备控制器还具有对设备传递过来的数据进行检测的功能。

### **中断处理过程**

中断处理方案有很多种，下面是 《**ARM System Developer’s Guide**

**Designing and Optimizing System Software**》列出来的一些方案

- `非嵌套`的中断处理程序按照顺序处理各个中断，非嵌套的中断处理程序也是最简单的中断处理
- `嵌套`的中断处理程序会处理多个中断而无需分配优先级
- `可重入`的中断处理程序可使用优先级处理多个中断
- `简单优先级`中断处理程序可处理简单的中断
- `标准优先级`中断处理程序比低优先级的中断处理程序在更短的时间能够处理优先级更高的中断
- `高优先级` 中断处理程序在短时间能够处理优先级更高的任务，并直接进入特定的服务例程。
- `优先级分组`中断处理程序能够处理不同优先级的中断任务

下面是一些通用的中断处理程序的步骤，不同的操作系统实现细节不一样

- 保存所有没有被中断硬件保存的寄存器
- 为中断服务程序设置上下文环境，可能包括设置 `TLB`、`MMU` 和页表，如果不太了解这三个概念，请参考另外一篇文章
- 为中断服务程序设置栈
- 对中断控制器作出响应，如果不存在集中的中断控制器，则继续响应中断
- 把寄存器从保存它的地方拷贝到进程表中
- 运行中断服务程序，它会从发出中断的设备控制器的寄存器中提取信息
- 操作系统会选择一个合适的进程来运行。如果中断造成了一些优先级更高的进程变为就绪态，则选择运行这些优先级高的进程
- 为进程设置 MMU 上下文，可能也会需要 TLB，根据实际情况决定
- 加载进程的寄存器，包括 PSW 寄存器
- 开始运行新的进程

上面我们罗列了一些大致的中断步骤，不同性质的操作系统和中断处理程序能够处理的中断步骤和细节也不尽相同，下面是一个嵌套中断的具体运行步骤

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/90cfwv7pnh.png)

### **什么是设备驱动程序**

在计算机中，设备驱动程序是一种计算机程序，它能够控制或者操作连接到计算机的特定设备。驱动程序提供了与硬件进行交互的软件接口，使操作系统和其他计算机程序能够访问特定设备，不用需要了解其硬件的具体构造。

### **什么是 DMA**

DMA 的中文名称是`直接内存访问`，它意味着 CPU 授予 I/O 模块权限在不涉及 CPU 的情况下读取或写入内存。也就是 DMA 可以不需要 CPU 的参与。这个过程由称为 DMA 控制器（DMAC）的芯片管理。由于 DMA 设备可以直接在内存之间传输数据，而不是使用 CPU 作为中介，因此可以缓解总线上的拥塞。DMA 通过允许 CPU 执行任务，同时 DMA 系统通过系统和内存总线传输数据来提高系统并发性。

### **直接内存访问的特点**

DMA 方式有如下特点：

- 数据传送以数据块为基本单位
- 所传送的数据从设备直接送入主存，或者从主存直接输出到设备上
- 仅在传送一个或多个数据块的开始和结束时才需 CPU 的干预，而整块数据的传送则是在控制器的控制下完成。

DMA 方式和中断驱动控制方式相比，减少了 CPU 对 I/O 操作的干预，进一步提高了 CPU 与 I/O 设备的并行操作程度。

DMA 方式的线路简单、价格低廉，适合高速设备与主存之间的成批数据传送，小型、微型机中的快速设备均采用这种方式，但其功能较差，不能满足复杂的 I/O 要求。



### **什么是僵尸进程**

僵尸进程是已完成且处于终止状态，但在进程表中却仍然存在的进程。僵尸进程通常发生在父子关系的进程中，由于父进程仍需要读取其子进程的退出状态所造成的。

### **死锁产生的原因**

死锁产生的原因大致有两个：资源竞争和程序执行顺序不当

### **死锁产生的必要条件**

资源死锁可能出现的情况主要有

- **互斥条件**：每个资源都被分配给了一个进程或者资源是可用的
- **保持和等待条件**：已经获取资源的进程被认为能够获取新的资源
- **不可抢占条件**：分配给一个进程的资源不能强制的从其他进程抢占资源，它只能由占有它的进程显示释放
- **循环等待**：死锁发生时，系统中一定有两个或者两个以上的进程组成一个循环，循环中的每个进程都在等待下一个进程释放的资源。

### **死锁的恢复方式**

所以针对检测出来的死锁，我们要对其进行恢复，下面我们会探讨几种死锁的恢复方式

#### **通过抢占进行恢复**

在某些情况下，可能会临时将某个资源从它的持有者转移到另一个进程。比如在不通知原进程的情况下，将某个资源从进程中强制取走给其他进程使用，使用完后又送回。这种恢复方式一般比较困难而且有些简单粗暴，并不可取。

#### **通过回滚进行恢复**

如果系统设计者和机器操作员知道有可能发生死锁，那么就可以定期检查流程。进程的检测点意味着进程的状态可以被写入到文件以便后面进行恢复。检测点不仅包含`存储映像(memory image)`，还包含`资源状态(resource state)`。一种更有效的解决方式是不要覆盖原有的检测点，而是每出现一个检测点都要把它写入到文件中，这样当进程执行时，就会有一系列的检查点文件被累积起来。

为了进行恢复，要从上一个较早的检查点上开始，这样所需要资源的进程会回滚到上一个时间点，在这个时间点上，死锁进程还没有获取所需要的资源，可以在此时对其进行资源分配。

#### **杀死进程恢复**

最简单有效的解决方案是直接杀死一个死锁进程。但是杀死一个进程可能照样行不通，这时候就需要杀死别的资源进行恢复。

另外一种方式是选择一个环外的进程作为牺牲品来释放进程资源。

### **如何破坏死锁**

和死锁产生的必要条件一样，如果要破坏死锁，也是从下面四种方式进行破坏。

#### **破坏互斥条件**

我们首先考虑的就是**破坏互斥使用条件**。如果资源不被一个进程独占，那么死锁肯定不会产生。如果两个打印机同时使用一个资源会造成混乱，打印机的解决方式是使用 `假脱机打印机(spooling printer)` ，这项技术可以允许多个进程同时产生输出，在这种模型中，实际请求打印机的唯一进程是打印机守护进程，也称为后台进程。后台进程不会请求其他资源。我们可以消除打印机的死锁。

后台进程通常被编写为能够输出完整的文件后才能打印，假如两个进程都占用了假脱机空间的一半，而这两个进程都没有完成全部的输出，就会导致死锁。

因此，尽量做到尽可能少的进程可以请求资源。

#### **破坏保持等待的条件**

第二种方式是如果我们能阻止持有资源的进程请求其他资源，我们就能够消除死锁。一种实现方式是让所有的进程开始执行前请求全部的资源。如果所需的资源可用，进程会完成资源的分配并运行到结束。如果有任何一个资源处于频繁分配的情况，那么没有分配到资源的进程就会等待。

很多进程**无法在执行完成前就知道到底需要多少资源**，如果知道的话，就可以使用银行家算法；还有一个问题是这样**无法合理有效利用资源**。

还有一种方式是进程在请求其他资源时，先释放所占用的资源，然后再尝试一次获取全部的资源。

#### **破坏不可抢占条件**

破坏不可抢占条件也是可以的。可以通过`虚拟化`的方式来避免这种情况。

#### **破坏循环等待条件**

现在就剩最后一个条件了，循环等待条件可以通过多种方法来破坏。一种方式是制定一个标准，一个进程在任何时候只能使用一种资源。如果需要另外一种资源，必须释放当前资源。

另一种方式是将所有的资源统一编号，如下图所示

![img](https://ask.qcloudimg.com/http-save/yehe-5359587/2ms5e2wycc.png)

进程可以在任何时间提出请求，但是所有的请求都必须按照资源的顺序提出。如果按照此分配规则的话，那么资源分配之间不会出现环。

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/re7x4jmspv.png)

### **死锁类型**

#### **两阶段加锁**

虽然很多情况下死锁的避免和预防都能处理，但是效果并不好。随着时间的推移，提出了很多优秀的算法用来处理死锁。例如在[数据库](https://cloud.tencent.com/solution/database?from=10680)系统中，一个经常发生的操作是请求锁住一些记录，然后更新所有锁定的记录。当同时有多个进程运行时，就会有死锁的风险。

一种解决方式是使用 `两阶段提交(two-phase locking)`。顾名思义分为两个阶段，一阶段是进程尝试一次锁定它需要的所有记录。如果成功后，才会开始第二阶段，第二阶段是执行更新并释放锁。第一阶段并不做真正有意义的工作。

如果在第一阶段某个进程所需要的记录已经被加锁，那么该进程会释放所有锁定的记录并重新开始第一阶段。从某种意义上来说，这种方法类似于预先请求所有必需的资源或者是在进行一些不可逆的操作之前请求所有的资源。

不过在一般的应用场景中，两阶段加锁的策略并不通用。如果一个进程缺少资源就会半途中断并重新开始的方式是不可接受的。

#### **通信死锁**

我们上面一直讨论的是资源死锁，资源死锁是一种死锁类型，但并不是唯一类型，还有通信死锁，也就是两个或多个进程在发送消息时出现的死锁。进程 A 给进程 B 发了一条消息，然后进程 A 阻塞直到进程 B 返回响应。假设请求消息丢失了，那么进程 A 在一直等着回复，进程 B 也会阻塞等待请求消息到来，这时候就产生`死锁`。

尽管会产生死锁，但是这并不是一个资源死锁，因为 A 并没有占据 B 的资源。事实上，通信死锁并没有完全可见的资源。根据死锁的定义来说：每个进程因为等待其他进程引起的事件而产生阻塞，这就是一种死锁。相较于最常见的通信死锁，我们把上面这种情况称为`通信死锁(communication deadlock)`。

通信死锁不能通过调度的方式来避免，但是可以使用通信中一个非常重要的概念来避免：`超时(timeout)`。在通信过程中，只要一个信息被发出后，发送者就会启动一个定时器，定时器会记录消息的超时时间，如果超时时间到了但是消息还没有返回，就会认为消息已经丢失并重新发送，通过这种方式，可以避免通信死锁。

但是并非所有网络通信发生的死锁都是通信死锁，也存在资源死锁，下面就是一个典型的资源死锁。

当一个数据包从主机进入路由器时，会被放入一个缓冲区，然后再传输到另外一个路由器，再到另一个，以此类推直到目的地。缓冲区都是资源并且数量有限。如下图所示，每个路由器都有 10 个缓冲区（实际上有很多）。

![img](https://ask.qcloudimg.com/http-save/yehe-5359587/rnggpk3xku.png)

假如路由器 A 的所有数据需要发送到 B ，B 的所有数据包需要发送到 D，然后 D 的所有数据包需要发送到 A 。没有数据包可以移动，因为在另一端没有缓冲区可用，这就是一个典型的资源死锁。

#### **活锁**

某些情况下，当进程意识到它不能获取所需要的下一个锁时，就会尝试礼貌的释放已经获得的锁，然后等待非常短的时间再次尝试获取。可以想像一下这个场景：当两个人在狭路相逢的时候，都想给对方让路，相同的步调会导致双方都无法前进。

现在假想有一对并行的进程用到了两个资源。它们分别尝试获取另一个锁失败后，两个进程都会释放自己持有的锁，再次进行尝试，这个过程会一直进行重复。很明显，这个过程中没有进程阻塞，但是进程仍然不会向下执行，这种状况我们称之为 `活锁(livelock)`。

#### **饥饿**

与死锁和活锁的一个非常相似的问题是 `饥饿(starvvation)`。想象一下你什么时候会饿？一段时间不吃东西是不是会饿？对于进程来讲，最重要的就是资源，如果一段时间没有获得资源，那么进程会产生饥饿，这些进程会永远得不到服务。

我们假设打印机的分配方案是每次都会分配给最小文件的进程，那么要打印大文件的进程会永远得不到服务，导致进程饥饿，进程会无限制的推后，虽然它没有阻塞。

### 线上服务器CPU占用率高如何排查定位问题？

[参考](https://blog.51cto.com/u_14490033/3133424)

#### **1、定位进程**

登录服务器，执行top命令，查看CPU占用情况：



```
$top
PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
1893 admin     20   0 7127m 2.6g  38m S 181.7 32.6  10:20.26 java
```

**top命令是Linux下常用的性能分析工具，能够实时显示系统中各个进程的资源占用状况，类似于Windows的任务管理器**。

通过以上命令，我们可以看到，进程ID为1893的Java进程的CPU占用率达到了181%，基本可以定位到是我们的Java应用导致整个服务器的CPU占用率飙升。

#### 2、定位线程

我们知道，Java是单进程多线程的，那么，我们接下来看看PID=1893的这个Java进程中的各个线程的CPU使用情况，**同样是用top命令**：

```
$top -Hp 1893
   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
  4519 admin     20   0 7127m 2.6g  38m R 18.6 32.6   0:40.11 java
```

通过top -Hp 1893命令，我们可以发现，当前1893这个进程中，ID为4519的线程占用CPU最高。

#### 3、定位代码

通过top命令，我们目前已经定位到导致CPU使用率较高的具体线程， 那么我么接下来就定位下到底是哪一行代码存在问题。

首先，我们需要**把4519这个线程转成16进制**：

```
$printf %x 4519
11a7
```

接下来，通过jstack命令，查看栈信息：

```
$sudo -u admin  jstack 1893 |grep -A 200 11a7
"HSFBizProcessor-DEFAULT-8-thread-5" #500 daemon prio=10 os_prio=0 tid=0x00007f632314a800 nid=0x11a2 runnable [0x000000005442a000]
   java.lang.Thread.State: RUNNABLE
  at sun.misc.URLClassPath$Loader.findResource(URLClassPath.java:684)
  at sun.misc.URLClassPath.findResource(URLClassPath.java:188)
  at java.net.URLClassLoader$2.run(URLClassLoader.java:569)
  at java.net.URLClassLoader$2.run(URLClassLoader.java:567)
  at java.security.AccessController.doPrivileged(Native Method)
  at java.net.URLClassLoader.findResource(URLClassLoader.java:566)
  at java.lang.ClassLoader.getResource(ClassLoader.java:1093)
  at java.net.URLClassLoader.getResourceAsStream(URLClassLoader.java:232)
  at org.hibernate.validator.internal.xml.ValidationXmlParser.getInputStreamForPath(ValidationXmlParser.java:248)
  at org.hibernate.validator.internal.xml.ValidationXmlParser.getValidationConfig(ValidationXmlParser.java:191)
  at org.hibernate.validator.internal.xml.ValidationXmlParser.parseValidationXml(ValidationXmlParser.java:65)
  at org.hibernate.validator.internal.engine.ConfigurationImpl.parseValidationXml(ConfigurationImpl.java:287)
  at org.hibernate.validator.internal.engine.ConfigurationImpl.buildValidatorFactory(ConfigurationImpl.java:174)
  at javax.validation.Validation.buildDefaultValidatorFactory(Validation.java:111)
  at com.test.common.util.BeanValidator.validate(BeanValidator.java:30)
```

通过以上代码，我们可以清楚的看到，BeanValidator.java的第30行是有可能存在问题的。

问题解决

接下来就是通过查看代码来解决问题了，我们发现，我们自定义了一个BeanValidator，封装了Hibernate的Validator，然后在validate方法中，通过Validation.buildDefaultValidatorFactory().getValidator()初始化一个Validator实例，通过分析发现这个实例化的过程比较耗时。

我们重构了一下代码，把Validator实例的初始化提到方法外，在类初始化的时候创建一次就解决了问题。

#### 总结

以上，展示了一次比较完成的线上问题定位过程。**主要用到的命令有:top 、printf 和 jstack**

另外，线上问题排查还可以使用Alibaba开源的工具Arthas进行排查，以上问题，可以使用一下命令定位：

**thread -n 3 //查看cpu占比前三的线程**

### 请简述操作系统分页式内存管理机制，并介绍下进程fork时对内存的copy on write实现原理。

[参考](https://www.nowcoder.com/questionTerminal/56f6e3d6a4d94361993eba1d2f4664c8)

1、逻辑地址和物理地址分离的内存分配管理方案，程序的逻辑地址划分为固定大小的页，物理地址划分为同样大小的帧，通过页表对应逻辑地址和物理地址 

  2、**内核fork()时并不复制整个进程地址空间**，而是让父子进程共享一个地址空间---》只有在需要写入时，数据才会被复制，从而使各个进程拥有各自的拷贝数据。也就是说，**只有在需要写入的时候才复制资源**，在此之前，以只读方式共享

### 简述操作系统中 malloc 的实现原理

[参考](https://www.nowcoder.com/questionTerminal/5aae63b290c542f0ab0582d293e6c791)

malloc可以分别由伙伴系统或基于链表的实现； 

  1、它有一个将可用的内存块连接为一个长长的列表的所谓空闲链表；

  2、  调用malloc函数时，它**沿连接表寻找一个大到足以满足用户请求所需要的内存块**。然后，将该内存块一分为二（一块的大小与用户请求的大小相等，另一块的大小就是剩下的字节）。接下来，将分配给用户的那块内存传给用户，并将剩下的那块（如果有的话）返回到连接表上。

  3、  **调用free函数时，它将用户释放的内存块连接到空闲链上**。到最后，空闲链会被切成很多的小内存片段，如果这时用户申请一个大的内存片段，那么空闲链上可能没有可以满足用户要求的片段了。于是，malloc函数请求延时，并开始**在空闲链上翻箱倒柜地检查各内存片段，对它们进行整理，将相邻的小空闲块合并成较大的内存块**。 

### 简述僵尸进程和孤儿进程及其危害和处理

[参考](https://blog.csdn.net/a745233700/article/details/120715371)

#### 1、什么是僵尸进程和孤儿进程：

​    在 Unix/Linux 系统中，正常情况下，**子进程是通过父进程创建的，且两者的运行是相互独立的，父进程永远无法预测子进程到底什么时候结束**。当一个进程**调用 exit 命令结束自己的生命**时，其实它并**没有真正的被销毁**，**内核只是释放了该进程的所有资源**，包括打开的文件、占用的内存等，但是留下一个称为僵尸进程的数据结构，这个结构保留了一定的信息（包括进程号 the process ID，退出状态，运行时间），这些信息直到父进程通过 wait()/waitpid() 来取时才释放。这样**设计的目的主要是保证只要父进程想知道子进程结束时的状态信息**，就可以得到

- 僵尸进程：一个进程使用 fork 创建子进程，如果子进程退出，而**父进程并没有调用 wait 或 waitpid 获取子进程的状态信息**，那么子进程的进程描述符仍然保存在系统中，这种进程称之为僵死进程。
- 孤儿进程：**一个父进程退出，而它的一个或多个子进程还在运行**，那么这些子进程将成为孤儿进程。孤儿进程将被 init 进程(进程号为1)所收养，并由 init 进程对它们完成状态收集工作。

#### 2、僵尸进程与孤儿进程的问题危害：

​    僵尸进程虽然不占有任何内存空间，但如果父进程不调用 wait() / waitpid() 的话，那么保留的信息就不会释放，**其进程号就会一直被占用**，而系统所能使用的进程号是有限的，如果大量的产生僵死进程，将因为没有可用的进程号而导致系统不能产生新的进程，此即为僵尸进程的危害。

​    孤儿进程是没有父进程的进程，孤儿进程这个重任就落到了 init 进程身上，**init 进程**就好像是一个民政局，专门负责处理孤儿进程的善后工作。每当出现一个孤儿进程的时候，内核就把孤儿进程的父进程设置为 init，而 init 进程会循环地 wait() 它的已经退出的子进程。这样，当一个孤儿进程凄凉地结束了其生命周期的时候，init 进程就会出面处理它的一切善后工作。因此**孤儿进程并不会有什么危害**。

> 如果子进程在 exit() 之后，父进程没有来得及处理，这时用 ps 命令就能看到子进程的状态是“Z”。如果父进程能及时处理，可能用 ps 命令就来不及看到子进程的僵尸状态，但这并不等于子进程不经过僵尸状态。 如果父进程在子进程结束之前退出，则子进程将由 init 接管。**init 将会以父进程的身份对僵尸状态的子进程进行处理**。

#### 3、如果解决僵尸进程造成的问题：

（1）方案一：父进程通过 wait 和 waitpid 等函数等待子进程结束，但这会导致父进程挂起，所以这并不是一个好办法，父进程如果不能和子进程并发执行的话，那我们创建子进程的意义就没有。同时一个 wait 只能解决一个子进程，如果有多个子进程就要用到多个 wait

（2）方案二：通过信号机制：

​    子进程退出时，**向父进程发送 SIGCHILD 信号，父进程处理 SIGCHILD 信号**，在信号处理函数中调用 wait 进行处理僵尸进程。

（3）方案三：**fork两次**：

​    原理是将进程成为孤儿进程，从而其的父进程变为 init 进程，通过 init 进程处理僵尸进程。具体操作为：父进程一次 fork() 后产生一个子进程随后立即执行 wait(NULL) 来等待子进程结束，然后子进程 fork() 后产生孙子进程随后立即exit(0)。这样子进程顺利终止（父进程仅仅给子进程收尸，并不需要子进程的返回值），然后父进程继续执行。这时的孙子进程由于失去了它的父进程（即是父进程的子进程），将被转交给Init进程托管。于是父进程与孙子进程无继承关系了，它们的父进程均为Init，Init进程在其子进程结束时会自动收尸，这样也就不会产生僵死进程了

（4）方案四：kill 父进程：

​    严格地来说，僵死进程并不是问题的根源，**罪魁祸首是产生出大量僵死进程的那个父进程**。因此，当我们寻求如何消灭系统中大量的僵死进程时，答案就是把产生大量僵死进程的那个元凶枪毙掉（也就是通过 kill 发送 SIGTERM 或者 SIGKILL 信号啦）。枪毙了元凶进程之后，它产生的僵死进程就变成了孤儿进 程，这些孤儿进程会被 init 进程接管，init 进程会 wait() 这些孤儿进程，释放它们占用的系统进程表中的资源，这样，这些已经僵死的孤儿进程就能瞑目而去了。

### [管道pipe的实现原理](https://segmentfault.com/a/1190000009528245)

#### 管道

管道是进程间通信的主要手段之一。**一个管道实际上就是个只存在于内存中的文件**，对这个文件的操作要通过两个已经打开文件进行，它们分别代表管道的两端。**管道是一种特殊的文件，它不属于某一种文件系统，而是一种独立的文件系统**，有其自己的数据结构。

根据管道的适用范围将其分为：无名管道和命名管道。

##### 无名管道

主要用于父进程与子进程之间，或者两个兄弟进程之间。在linux系统中可以通过**系统调用建立起一个单向的通信管道**，且这种关系**只能由父进程来建立**。

##### 命名管道

**命名管道是建立在实际的磁盘介质或文件系统（而不是只存在于内存中）上有自己名字的文件**，任何进程可以在任何时间通过文件名或路径名与该文件建立联系。为了实现命名管道，引入了一种新的文件类型——**FIFO文件（遵循先进先出的原则）**。实现一个命名管道实际上就是实现一个FIFO文件。命名管道一旦建立，之后它的读、写以及关闭操作都与普通管道完全相同。虽然FIFO文件的inode节点在磁盘上，但是仅是一个节点而已，文件的数据还是存在于内存缓冲页面中，和普通管道相同。

#### 管道实现机制

管道是由内核管理的一个缓冲区，相当于我们放入内存中的一个纸条。

管道的一端连接一个进程的输出。这个进程会向管道中放入信息。

管道的另一端连接一个进程的输入，这个进程取出被放入管道的信息。

一个缓冲区不需要很大一般为4K大小，它被设计成为环形的数据结构，以便管道可以被循环利用。

当管道中没有信息的话，从管道中读取的进程会等待，直到另一端的进程放入信息。

当管道被放满信息的时候，尝试放入信息的进程会等待，直到另一端的进程取出信息。

当两个进程都终结的时候，管道也自动消失。

#### 创建过程

![clipboard.png](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/bVN8RW)

#### 细节

在Linux中，管道的实现并没有使用专门的数据结构，而是借助了文件系统的file结构和VFS的索引节点inode。

通过将两个file结构指向同一个临时的 VFS 索引节点，而这个 VFS 索引节点又指向一个物理页面而实现的。

如下图有两个 file 数据结构，但它们定义文件操作例程地址是不同的，其中一个是向管道中写入数据的例程地址，而另一个是从管道中读出数据的例程地址。

这样，用户程序的系统调用仍然是通常的文件操作，而内核却利用这种抽象机制实现了管道这一特殊操作。
![clipboard.png](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/bVN8SZ)

#### 读写操作

管道实现的源代码在fs/pipe.c中，在pipe.c中有很多函数，其中有两个函数比较重要，即管道读函数pipe_read()和管道写函数pipe_wrtie()。

管道写函数通过将字节复制到 VFS 索引节点指向的物理内存而写入数据，而管道读函数则通过复制物理内存中的字节而读出数据。

当然，内核必须利用一定的机制同步对管道的访问，为此，内核使用了锁、等待队列和信号。

当写进程向管道中写入时，它利用标准的库函数write()，系统根据库函数传递的文件描述符，可找到该文件的 file 结构。

file 结构中指定了用来进行写操作的函数（即写入函数）地址，于是，内核调用该函数完成写操作。
写

入函数在向内存中写入数据之前，必须首先检查 VFS 索引节点中的信息，同时满足如下条件时，才能进行实际的内存复制工作：

```undefined
内存中有足够的空间可容纳所有要写入的数据；

内存没有被读程序锁定。
```

如果同时满足上述条件，写入函数首先锁定内存，然后从写进程的地址空间中复制数据到内存。否则，写入进程就休眠在 VFS 索引节点的等待队列中，接下来，内核将调用调度程序，而调度程序会选择其他进程运行。

写入进程实际处于可中断的等待状态，当内存中有足够的空间可以容纳写入数据，或内存被解锁时，读取进程会唤醒写入进程，这时，写入进程将接收到信号。

当数据写入内存之后，内存被解锁，而所有休眠在索引节点的读取进程会被唤醒。

管道的读取过程和写入过程类似。但是，进程可以在没有数据或内存被锁定时立即返回错误信息，而不是阻塞该进程，这依赖于文件或管道的打开模式。反之，进程可以休眠在索引节点的等待队列中等待写入进程写入数据。

当所有的进程完成了管道操作之后，管道的索引节点被丢弃，而共享数据页也被释放

### 同步异步、阻塞非阻塞

[参考](career.huawei.com/reccampportal/portal5/campus-recruitment.html)

#### 同步（Sync）和异步（Async）

**同步：**

所谓同步，就是发出一个功能调用时，在没有得到结果之前，该调用就不返回或继续执行后续操作。

简单来说，同步就是必须一件一件事做，等前一件做完了才能做下一件事。

例如：B/S模式中的表单提交，具体过程是：客户端提交请求->等待[服务器](https://cloud.tencent.com/product/cvm?from=10680)处理->处理完毕返回，在这个过程中客户端（浏览器）不能做其他事。

**异步：**

异步与同步相对，当一个异步过程调用发出后，调用者在没有得到结果之前，就可以继续执行后续操作。当这个调用完成后，一般**通过状态、通知和回调来通知调用者**。对于异步调用，调用的返回并不受调用者控制。

对于通知调用者的三种方式，具体如下：

- 状态：即监听被调用者的状态（轮询），调用者需要每隔一定时间检查一次，效率会很低。
- 通知：当被调用者执行完成后，发出通知告知调用者，无需消耗太多性能。
- 回调：与通知类似，当被调用者执行完成后，会调用调用者提供的回调函数。

例如：B/S模式中的ajax请求，具体过程是：客户端发出ajax请求->服务端处理->处理完毕执行客户端回调，在客户端（浏览器）发出请求后，仍然可以做其他的事。

**同步和异步的区别：**

总结来说，同步和异步的区别：请求发出后，是否需要等待结果，才能继续执行其他操作。

#### 阻塞和非阻塞

阻塞和非阻塞这两个概念与程序（线程）等待消息通知(无所谓同步或者异步)时的状态有关。也就是说**阻塞与非阻塞主要是程序（线程）等待消息通知时的状态角度**来说的。

阻塞和非阻塞关注的是程序在等待调用结果（消息，返回值）时的状态。

阻塞调用是指调用结果返回之前，当前线程会被挂起。调用线程只有在得到结果之后才会返回。

非阻塞调用指在不能立刻得到结果之前，该调用不会阻塞当前线程。

#### 异步和多线程区别？（原理篇）

##### **1 异步和多线程有什么区别？**

其实，**异步是目的**，而**多线程是实现这个目的的方法**。异步是说，A发起一个操作后（一般都是比较耗时的操作，如果不耗时的操作就没有必要异步了），可以继续自顾自的处理它自己的事儿，不用干等着这个耗时操作返回。

##### **2 多线程和异步操作的异同**

多线程和异步操作两者都可以达到避免调用线程阻塞的目的，从而提高软件的可响应性。甚至有些时候我们就认为多线程和异步操作是等同的概念。但是，多线程和异步操作还是有一些区别的。而这些区别造成了使用多线程和异步操作的时机的区别。

##### **3 异步操作的本质**

所有的程序最终都会由计算机硬件来执行，所以为了更好的理解异步操作的本质，我们有必要了解一下它的硬件基础。熟悉电脑硬件的朋友肯定对DMA这个词不陌生，硬盘、光驱的技术规格中都有明确DMA的模式指标，其实网卡、声卡、显卡也是有DMA功能的。

**DMA就是直接内存访问的意思**，也就是说，拥有DMA功能的硬件在和内存进行数据交换的时候可以不消耗CPU资源。只要CPU在发起数据传输时发送一个指令，硬件就开 始自己和内存交换数据，在传输完成之后硬件会触发一个中断来通知操作完成。**这些无须消耗CPU时间的I/O操作正是异步操作的硬件基础**。所以即使在DOS 这样的单进程（而且无线程概念）系统中也同样可以发起异步的DMA操作。

##### **4 线程的本质**

**线程不是一个计算机硬件的功能，而是操作系统提供的一种逻辑功能**，线程本质上是进程中一段并发运行的代码，所以线程需要操作系统投入CPU资源来运行和调度。

##### **5 异步操作的优缺点**

因为异步操作无须额外的线程负担，并且使用回调的方式进行处理，在设计良好的情况下，处理函数可以不必使用共享变量（即使无法完全不用，最起码可以减少 共享变量的数量），减少了死锁的可能。当然异步操作也并非完美无暇。编写异步操作的复杂程度较高，程序主要使用回调方式进行处理，与普通人的思维方式有些 出入，而且难以调试。

##### **6 多线程的优缺点**

多线程的优点很明显，线程中的处理程序依然是顺序执行，符合普通人的思维习惯，所以编程简单。但是多线程的缺点也同样明显，线程的使用（滥用）会给系统带来上下文切换的额外负担。并且线程间的共享变量可能造成死锁的出现。

异步与多线程，从辩证关系上来看，异步和多线程并不是一个同等关系，异步是目的，多线程只是我们实现异步的一个手段。什么是异步：异步是当一个调用请求发送给被调用者，而调用者不用等待其结果的返回。实现异步可以采用多线程技术或则交给另外的进程来处理。扩展：[多线程基础体系知识清单](http://mp.weixin.qq.com/s?__biz=MzI4Njc5NjM1NQ==&mid=2247489977&idx=1&sn=1b62e91b7f898435dce81eee46f6621d&chksm=ebd62695dca1af839ca0da7015707db7a83e10b38b6787c2b012e4d20ecf7ea80499976424d2&scene=21#wechat_redirect)

#### 异步，多线程和并行的区别？（故事篇）

非专业人员，就用非专业的语言解释下吧，比喻不够贴切，但大概是那么个意思，

先听我讲一个故事：

> 那还是10年前，还没有12306的年代，大家买票只能去火车站买。因为大家都要过年回家，都还不想等，火车站只有一个，窗口只有那么多，头疼啊。更头疼的是，排到窗口的那个人，各种挑剔，不要贵的，不要晚上的，不要站票……跟售票员各种墨迹，后面的人更加着急，一个个义愤填膺，骂爹骂娘。

现在假设整个城市就只有1个火车，1个售票员，每个乘客咨询售票员后需要思考1分钟再决定买哪趟车的票。

**1。异步：**在买票的人咨询后，需要思考1分钟，马上靠边站，但不用重新排队，什么时候想清楚可以立马去跟售票员去买票。在该人站在旁边思考的时候，后面的人赶紧上去接着买。这时候队伍是很快的挪动的，没有阻塞，售票员的最大化的效率。

**2。多线程：**火车站开n个窗口（但还是只有一个人售票），外面同时排n个队，售票员回答咨询者问题后，立马马上去下个窗口，然后继续轮换到下个窗口…..哪个窗口的人决定好了，售票员立马过去买给他。这个时候乘客比较简单，但万一那个队伍有人思考半天纠结，后面的人就悲剧了。

**3。并行：**复制n个火车站，同时卖票，买票能力大大增强。大家也可以哪个火车站人少，就去那个买票。

**可见：**在只有一个火车站，且只有一个售票员的情况下，卖完一个再卖一个就会导致资源浪费，效率低下，队伍卡死，很难往前挪动。1，2优化的办法都解决了队伍不动，售票率低下的问题。但增加火车站，增加窗口，增加售票员才是好办法。扩展：[多线程基础体系知识清单](http://mp.weixin.qq.com/s?__biz=MzI4Njc5NjM1NQ==&mid=2247489977&idx=1&sn=1b62e91b7f898435dce81eee46f6621d&chksm=ebd62695dca1af839ca0da7015707db7a83e10b38b6787c2b012e4d20ecf7ea80499976424d2&scene=21#wechat_redirect)

#### **结论：**

1。异步和多线程其实效率差不多，但是开的窗口不多例如3个，同时有很多人都是去花5分钟，而不是1分钟去纠结的时候，多线程效率实际是低于异步的，因为售票员还是常遇到3个队伍同时卡在那纠结不能买票的时候。

2。这2个概念拿来对比也有点不合适，因为他们不是一个概念，多线程的目的还是为了实现异步，多线程应该是一种实现异步的手段。异步应该去跟同步比较才对。

3。多线程比较简单，但需要增设窗口，增加成本，且售票员比较累这类似apache下php，和node。js下[javascript](https://cloud.tencent.com/product/sms?from=10680)的关系，一个是多线程，但是是阻塞的，另外一个是单线程异步非阻塞的。php的方案比较符合常规思维，但比较费内存，node。js非阻塞，用较少的资源就能完成同样的任务，但编程比较费神。

4。并行，类似同时利用多核cpu的各个核去计算。并发可分为伪并发、真并发。前者例如单核处理器的并发，后者发是指多核处理器的并发。

5。终极办法是[并行计算](https://cloud.tencent.com/product/gpu?from=10680)，并且每个cpu下进行异步计算，这样你的每个核都充分利用。只不过对编程要求太高了太高了，如果不是密集型计算，例如大型有限元计算（多采用并发），或者服务器同时处理上千的访问（多采用异步或者多线程），还是老老实实的用传统的办法吧，毕竟常规程序的计算量对现在的硬件来说，问题都不大。扩展：[多线程基础体系知识清单](http://mp.weixin.qq.com/s?__biz=MzI4Njc5NjM1NQ==&mid=2247489977&idx=1&sn=1b62e91b7f898435dce81eee46f6621d&chksm=ebd62695dca1af839ca0da7015707db7a83e10b38b6787c2b012e4d20ecf7ea80499976424d2&scene=21#wechat_redirect)

#### 阻塞非阻塞与同步异步的区别？（故事篇）

理解同步阻塞、同步非阻塞、异步阻塞、异步阻塞、异步非阻塞

**同步/异步关注的是消息通知的机制，而阻塞/非阻塞关注的是程序（线程）等待消息通知时的状态。**

以小明下载文件打个比方，从这两个关注点来再次说明这两组概念，希望能够更好的促进大家的理解。

**同步阻塞：小明一直盯着下载进度条，到 100% 的时候就完成。**

- 同步体现在：等待下载完成通知；
- 阻塞体现在：等待下载完成通知过程中，不能做其他任务处理；

**同步非阻塞：小明提交下载任务后就去干别的，每过一段时间就去瞄一眼进度条，看到 100% 就完成。**

- 同步体现在：等待下载完成通知，但是要在；
- 非阻塞体现在：等待下载完成通知过程中，去干别的任务了，只是时不时会瞄一眼进度条；【小明必须要在两个任务间切换，关注下载进度】

**异步阻塞：小明换了个有下载完成通知功能的软件，下载完成就“叮”一声。不过小明仍然一直等待“叮”的声音（看起来很傻，不是吗）。**

- 异步体现在：下载完成“叮”一声通知；
- 阻塞体现在：等待下载完成“叮”一声通知过程中，不能做其他任务处理；

**异步非阻塞：仍然是那个会“叮”一声的下载软件，小明提交下载任务后就去干别的，听到“叮”的一声就知道完成了。**

- 异步体现在：下载完成“叮”一声通知；
- 非阻塞体现在：等待下载完成“叮”一声通知过程中，去干别的任务了，只需要接收“叮”声通知即可；【软件处理下载任务，小明处理其他任务，不需关注进度，只需接收软件“叮”声通知，即可】

也就是说，同步/异步是“下载完成消息”通知的方式（机制），而阻塞/非阻塞则是在等待“下载完成消息”通知过程中的状态（能不能干其他任务），在不同的场景下，同步/异步、阻塞/非阻塞的四种组合都有应用。

所以，综上所述，**同步和异步仅仅是关注的消息如何通知的机制，而阻塞与非阻塞关注的是等待消息通知时的状态**。也就是说，同步的情况下，是由处理消息者自己去等待消息是否被触发，而异步的情况下是由触发机制来通知处理消息者，所以在异步机制中，处理消息者和触发机制之间就需要一个连接的桥梁：

在小明的例子中，这个桥梁就是软件“叮”的声音。

#### **同步/异步与阻塞/非阻塞**

##### **1 同步阻塞形式**

**效率是最低的，**

拿上面的例子来说，就是你专心等待下载完成，什么别的事都不做。

实际程序中：就是未对fd 设置O_NONBLOCK标志位的read/write 操作；

##### **2 异步阻塞形式**

异步操作是可以被阻塞住的，只不过它不是在处理消息时阻塞，而是在等待消息通知时被阻塞。

比如select 函数，假如传入的最后一个timeout参数为NULL，那么如果所关注的事件没有一个被触发，程序就会一直阻塞在这个select 调用处。

##### **3 同步非阻塞形式**

**实际上是效率低下的，**

想象一下你一边干别的事情一边还需要抬头看下载完成没有，如果把干别的事情和观察下载完成情况的位置看成是程序的两个操作的话，这个程序需要在这两种不同的行为之间来回的切换，效率可想而知是低下的。

很多人会写阻塞的read/write 操作，但是别忘了可以对fd设置O_NONBLOCK 标志位，这样就可以将同步操作变成非阻塞的了。

##### **4 异步非阻塞形式**

**效率更高，**

因为等待下载完成是你(等待者)的事情，而通知你则是电脑(消息触发机制)的事情，程序没有在两种不同的操作中来回切换。

### malloc分配内存到哪里？

[堆和栈，malloc分配的空间是堆，局部变量都在栈中](https://www.cnblogs.com/will-boot/p/3302936.html)

### [进程的三状态模型、五状态模型、七状态模型](https://hsuloong.github.io/operating-system/process-state-model.html)

进程状态模型通常如下三种：

- 三状态模型：包含**运行态、就绪态、阻塞态**三种基本状态模型
- 五状态模型：除三状态模型中的三种基本状态外，由于进程需要经过创建过程并且最终结束运行，因此添加**创建态、终止态**
- 七状态模型：除五状态模型五种状态外，在引入挂起概念后，多出了**就绪挂起、阻塞挂起**两种状态

![进程七状态转换模型](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/process-seven-status.png)

### [什么情况下，进程会进行切换？](https://blog.csdn.net/Mind_programmonkey/article/details/116722482)

进程切换一定发生在中断/异常/系统调用处理过程中，常见的有以下情况：

- 时间片**中断**、IO**中断**后 更改优先级进程；（导致被中断进程进入**就绪态**，即运行态-》就绪态）；
- 阻塞式**系统调用**、**虚拟地址异常**；（导致被中断进程进入**等待态**， 即运行态-》阻塞态）
- 终止用**系统调用**、**不能继续执行的异常**；（导致被中断进程进入**终止态**， 即运行态-》终止态）

### Linux 系统态与用户态，什么时候会进入系统态？

[参考](https://blog.csdn.net/Shangxingya/article/details/113664779)

中断可以使CPU从用户态切换为核心态，使操作系统获得计算机的控制权。有了中断，才能实现多道程序并发执行。

“用户态→核心态”是通过中断实现的。**并且中断是唯一途径。**

“核心态→用户态”的切换是通过**执行一个特权指令，将程序状态字(PSW)的标志位设置为“用户态”**

#### 中断的分类

- **中断分为内中断和外中断,** 核心区别就是这个中断信号的来源, **内中断是本CPU运行这段代码段锁发出的**, **外中断是其他CPU执行代码段发来的**, 也就是与当前CPU执行的指令无关.
  ![在这里插入图片描述](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/20210204212628785.png)

#### 中断的处理过程

- Step 1:执行完每个指令之后，CPU都要检查当前是否有外部中断信号
- Step 2:如果检测到外部中断信号，则需要保护被中断进程的CPU环境（如程序状态字PSw、程序计数器PC、各种通用寄存器)
- Step 3:根据中断信号类型转入相应的中断处理程序(进入内核态)
- Step 4:恢复原进程的CPU环境并退出中断，返回原进程继续往下执行
  ![在这里插入图片描述](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/20210204212920770.png)

#### 总结

![在这里插入图片描述](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/20210204213033833.png)

### 系统调用

#### 什么是系统调用

- 操作系统作为用户和计算机硬件之间的接口，需要向上提供一些简单易用的服务。
- 主要包括命令接口和程序接口。其中，程序接口由一组系统调用组成。

![在这里插入图片描述](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/20210204213221305.png)

**“系统调用”是操作系统提供给应用程序（程序员/编程人员)使用的接口**，可以理解为一种可供应用程序调用的特殊函数，应用程序可以发出系统调用请求来获得操作系统的服务。

#### 功能分类

- 应用程序通过系统调用请求操作系统的服务。
- 系统中的各种共享资源都由操作系统统一掌管，因此在用户程序中，凡是与资源有关的操作（如存储分配、I/O操作、文件管理等），都必须通过系统调用的方式向操作系统提出服务请求，由操作系统代为完成。
- **而每一个系统调用背后的功能都涉及到对应的资源管理和进程控制, 这些指令都是一些特权指令, 所以需要进行用户态到内核态的改变**
- **这样可以保证系统的稳定性和安全性，防止用户进行非法操作。**
- 如果按功能分配分为如下几种
  ![在这里插入图片描述](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/20210204213530368.png)

#### 如何实现系统调用

- 我们使用的高级语言对大多数的系统调用进行了封装变成库函数, 所以当我们在执行高级语言的时候都需要进行操作系统的编译成为汇编语言指令.
- 汇编语言就是一条条指令, 一开始执行的时候还是在用户态下, 但是一旦涉及到系统调用的接口, 就会发生上下文切换进入内核态执行系统调用相关的代码
  ![在这里插入图片描述](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/20210204214129485.png)
  传递系统调用参数→执行陷入指令(用户态）→执行系统调用相应服务程序（核心态)→返回用户程序

注意:

1. 陷入指令是在用户态执行的，执行陷入指令之后立即引发一个内中断，从而CPU进入核心态
2. 发出系统调用请求是在用户态，而对系统调用的相应处理在核心态下进行
3. 陷入指令是唯一 一个只能在用户态执行，而不可在核心态执行的指令

#### [系统调用的过程是怎样的？](https://blog.csdn.net/wangquan1992/article/details/108496821)

![介绍Linux下的系统调用过程介绍Linux下的系统调用过程](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/aad9f3f7f0288710bae356c170c5d9e7.png)

首先，应用程序能直接调用的是系统提供的API，这个在用户态（Ring3）下就可做到。

然后相应的API就会将相应的系统调用号保存到eax寄存器中（这一步通过内联汇编实现），之后就是使用int 0x80触发中断（内联汇编），进入到中断处理函数中（该函数是完全由汇编代码编写），这个时候就进入到了内核态（Ring0）了。

在中断处理函数中就会调用与系统调用号相对应的那个系统调用。在这个函数中，**会把ds（数据段寄存器）、es（额外寄存器）这两个寄存器设置为指向内核空间**。这样一来，我们无法把数据从用户态中传到内核态啊（如open(const char * filename, int flag, ...)中，filename指针指向的字符串的地址是在用户空间中的，在内核空间相应的地方取的话根本没有该字符串），这该怎么办呢？中断处理函数中的**fs寄存器被设置为指向了用户空间**，所以问题得以解决。

在系统调用中就是进行相应的操作了，如打开文件、写文件等。

处理完后，将会返回到中断处理函数，返回值保存在eax寄存器中。

从中断处理函数中返回到API，依旧是把返回值保存到eax寄存器中。这个时候就从内核态恢复成用户态。

在API中从eax中取出值，做相应的判断返回不同的值，用以表示操作完成情况。

#### 系统调用三种方法

下面介绍Linux 下三种发生系统调用的方法。

##### 通过 glibc 提供的库函数

glibc 是 Linux 下使用的开源的标准 C 库，它是 GNU 发布的 libc 库，即运行时库。glibc 为程序员提供丰富的 API（Application Programming Interface），除了例如字符串处理、数学运算等用户态服务之外，最重要的是封装了操作系统提供的系统服务，即系统调用的封装。那么glibc提供的系统调用API与内核特定的系统调用之间的关系是什么呢？

- 通常情况，每个特定的系统调用对应了至少一个 glibc 封装的库函数，如系统提供的打开文件系统调用 `sys_open` 对应的是 glibc 中的 `open` 函数；
- 其次，glibc 一个单独的 API 可能调用多个系统调用，如 glibc 提供的 `printf` 函数就会调用如 `sys_open`、`sys_mmap`、`sys_write`、`sys_close` 等等系统调用；
- 另外，多个 API 也可能只对应同一个系统调用，如glibc 下实现的 `malloc`、`calloc`、`free` 等函数用来分配和释放内存，都利用了内核的 `sys_brk` 的系统调用。

##### 使用 syscall 直接调用

使用上面的方法有很多好处，首先你无须知道更多的细节，如 chmod 系统调用号，你只需了解 glibc 提供的 API 的原型；其次，该方法具有更好的移植性，你可以很轻松将该程序移植到其他平台，或者将 glibc 库换成其它库，程序只需做少量改动。
**但有点不足是，如果 glibc 没有封装某个内核提供的系统调用时，我就没办法通过上面的方法来调用该系统调用**。如我自己通过编译内核增加了一个系统调用，这时 glibc 不可能有你新增系统调用的封装 API，此时我们可以利用 glibc 提供的`syscall` 函数直接调用。该函数定义在 `unistd.h` 头文件中，函数原型如下：

```cpp
long int syscall (long int sysno, ...)
```

- **sysno** 是系统调用号，每个系统调用都有唯一的系统调用号来标识。在 `sys/syscall.h` 中有所有可能的系统调用号的宏定义。
- **...** 为剩余可变长的参数，为系统调用所带的参数，根据系统调用的不同，可带0~5个不等的参数，如果超过特定系统调用能带的参数，多余的参数被忽略。
- **返回值** 该函数返回值为特定系统调用的返回值，在系统调用成功之后你可以将该返回值转化为特定的类型，如果系统调用失败则返回 -1，错误代码存放在 `errno` 中。

#### 通过 int 指令陷入

如果我们知道系统调用的整个过程的话，应该就能知道**用户态程序通过软中断指令`int 0x80` 来陷入内核态**（在Intel Pentium II 又引入了`sysenter`指令），参数的传递是通过寄存器，**eax 传递的是系统调用号**，ebx、ecx、edx、esi和edi 来依次传递最多五个参数，当系统调用返回时，**返回值存放在 eax 中**。

#### 总结

![在这里插入图片描述](https://img-blog.csdnimg.cn/20210204214345523.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NoYW5neGluZ3lh,size_16,color_FFFFFF,t_70)

### [共享内存是如何实现的？](https://cloud.tencent.com/developer/article/1878790)

#### 共享内存使用

##### 1. 获取共享内存

要使用共享内存，首先需要使用 `shmget()` 函数获取共享内存，`shmget()` 函数的原型如下：

```javascript
int shmget(key_t key, size_t size, int shmflg);
```

- 参数 `key` 一般由 `ftok()` 函数生成，用于标识系统的唯一IPC资源。
- 参数 `size` 指定创建的共享内存大小。
- 参数 `shmflg` 指定 `shmget()` 函数的动作，比如传入 `IPC_CREAT` 表示要创建新的共享内存。

函数调用成功时返回一个新建或已经存在的的共享内存标识符，取决于shmflg的参数。失败返回-1，并设置错误码。

##### **2. **关联共享内存

`shmget()` 函数返回的是一个标识符，而不是可用的内存地址，所以还需要调用 `shmat()` 函数把共享内存关联到某个虚拟内存地址上。`shmat()` 函数的原型如下：

```javascript
void *shmat(int shmid, const void *shmaddr, int shmflg);
```

- 参数 `shmid` 是 `shmget()` 函数返回的标识符。
- 参数 `shmaddr` 是要关联的虚拟内存地址，如果传入0，表示由系统自动选择合适的虚拟内存地址。
- 参数 `shmflg` 若指定了 `SHM_RDONLY` 位，则以只读方式连接此段，否则以读写方式连接此段。

函数调用成功返回一个可用的指针（虚拟内存地址），出错返回-1。

##### 3. 取消关联共享内存

当一个进程不需要共享内存的时候，就需要取消共享内存与虚拟内存地址的关联。取消关联共享内存通过 `shmdt()` 函数实现，原型如下：

```javascript
int shmdt(const void *shmaddr);
```

- 参数 `shmaddr` 是要取消关联的虚拟内存地址，也就是 `shmat()` 函数返回的值。

函数调用成功返回0，出错返回-1。

#### 共享内存实现原理

我们先通过一幅图来了解一下共享内存的大概原理，如下图：

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/63ab13e03a885b9922b60303f02f4fd3.png)

通过上图可知，共享内存是通过将不同进程的虚拟内存地址映射到相同的物理内存地址来实现的，下面将会介绍Linux的实现方式。

在Linux内核中，每个共享内存都由一个名为 `struct shmid_kernel` 的结构体来管理，而且Linux限制了系统最大能创建的共享内存为128个。通过类型为 `struct shmid_kernel` 结构的数组来管理，如下：

```javascript
struct shmid_ds {
 struct ipc_perm  shm_perm; /* operation perms */
 int   shm_segsz; /* size of segment (bytes) */
 __kernel_time_t  shm_atime; /* last attach time */
 __kernel_time_t  shm_dtime; /* last detach time */
 __kernel_time_t  shm_ctime; /* last change time */
 __kernel_ipc_pid_t shm_cpid; /* pid of creator */
 __kernel_ipc_pid_t shm_lpid; /* pid of last operator */
 unsigned short  shm_nattch; /* no. of current attaches */
 unsigned short   shm_unused; /* compatibility */
 void    *shm_unused2; /* ditto - used by DIPC */
 void   *shm_unused3; /* unused */
};

struct shmid_kernel
{ 
 struct shmid_ds  u;
 /* the following are private */
 unsigned long  shm_npages; /* size of segment (pages) */
 pte_t   *shm_pages; /* array of ptrs to frames -> SHMMAX */ 
 struct vm_area_struct *attaches; /* descriptors for attaches */
};

static struct shmid_kernel *shm_segs[SHMMNI]; // SHMMNI等于128
```

从注释可以知道 `struct shmid_kernel` 结构体各个字段的作用，比如 `shm_npages` 字段表示共享内存使用了多少个内存页。而 `shm_pages` 字段指向了共享内存映射的虚拟内存页表项数组等。

另外 `struct shmid_ds` 结构体用于管理共享内存的信息，而 `shm_segs数组` 用于管理系统中所有的共享内存。

##### shmget() 函数实现

通过前面的例子可知，要使用共享内存，首先需要调用 `shmget()` 函数来创建或者获取一块共享内存。`shmget()` 函数的实现如下：

```javascript
asmlinkage long sys_shmget (key_t key, int size, int shmflg)
{
 struct shmid_kernel *shp;
 int err, id = 0;

 down(&current->mm->mmap_sem);
 spin_lock(&shm_lock);
 if (size < 0 || size > shmmax) {
  err = -EINVAL;
 } else if (key == IPC_PRIVATE) {
  err = newseg(key, shmflg, size);
 } else if ((id = findkey (key)) == -1) {
  if (!(shmflg & IPC_CREAT))
   err = -ENOENT;
  else
   err = newseg(key, shmflg, size);
 } else if ((shmflg & IPC_CREAT) && (shmflg & IPC_EXCL)) {
  err = -EEXIST;
 } else {
  shp = shm_segs[id];
  if (shp->u.shm_perm.mode & SHM_DEST)
   err = -EIDRM;
  else if (size > shp->u.shm_segsz)
   err = -EINVAL;
  else if (ipcperms (&shp->u.shm_perm, shmflg))
   err = -EACCES;
  else
   err = (int) shp->u.shm_perm.seq * SHMMNI + id;
 }
 spin_unlock(&shm_lock);
 up(&current->mm->mmap_sem);
 return err;
}
```

`shmget()` 函数的实现比较简单，首先调用 `findkey()` 函数查找值为key的共享内存是否已经被创建，`findkey()` 函数返回共享内存在 `shm_segs数组` 的索引。如果找到，那么直接返回共享内存的标识符即可。否则就调用 `newseg()` 函数创建新的共享内存。`newseg()` 函数的实现也比较简单，就是创建一个新的 `struct shmid_kernel` 结构体，然后设置其各个字段的值，并且保存到 `shm_segs数组` 中。

##### shmat() 函数实现

`shmat()` 函数用于将共享内存映射到本地虚拟内存地址，由于 `shmat()` 函数的实现比较复杂，所以我们分段来分析这个函数：

```javascript
asmlinkage long sys_shmat (int shmid, char *shmaddr, int shmflg, ulong *raddr)
{
 struct shmid_kernel *shp;
 struct vm_area_struct *shmd;
 int err = -EINVAL;
 unsigned int id;
 unsigned long addr;
 unsigned long len;

 down(&current->mm->mmap_sem);
 spin_lock(&shm_lock);
 if (shmid < 0)
  goto out;

 shp = shm_segs[id = (unsigned int) shmid % SHMMNI];
 if (shp == IPC_UNUSED || shp == IPC_NOID)
  goto out;
```

上面这段代码主要通过 `shmid` 标识符来找到共享内存描述符，上面说过系统中所有的共享内存到保存在 `shm_segs` 数组中。

```javascript
 if (!(addr = (ulong) shmaddr)) {
  if (shmflg & SHM_REMAP)
   goto out;
  err = -ENOMEM;
  addr = 0;
 again:
  if (!(addr = get_unmapped_area(addr, shp->u.shm_segsz))) // 获取一个空闲的虚拟内存空间
   goto out;
  if(addr & (SHMLBA - 1)) {
   addr = (addr + (SHMLBA - 1)) & ~(SHMLBA - 1);
   goto again;
  }
 } else if (addr & (SHMLBA-1)) {
  if (shmflg & SHM_RND)
   addr &= ~(SHMLBA-1);       /* round down */
  else
   goto out;
 }
```

上面的代码主要找到一个可用的虚拟内存地址，如果在调用 `shmat()` 函数时没有指定了虚拟内存地址，那么就通过 `get_unmapped_area()` 函数来获取一个可用的虚拟内存地址。

```javascript
 spin_unlock(&shm_lock);
 err = -ENOMEM;
 shmd = kmem_cache_alloc(vm_area_cachep, SLAB_KERNEL);
 spin_lock(&shm_lock);
 if (!shmd)
  goto out;
 if ((shp != shm_segs[id]) || (shp->u.shm_perm.seq != (unsigned int) shmid / SHMMNI)) {
  kmem_cache_free(vm_area_cachep, shmd);
  err = -EIDRM;
  goto out;
 }
```

上面的代码主要通过调用 `kmem_cache_alloc()` 函数创建一个 `vm_area_struct` 结构，在内存管理一章知道，`vm_area_struct` 结构用于管理进程的虚拟内存空间。

```javascript
 shmd->vm_private_data = shm_segs + id;
 shmd->vm_start = addr;
 shmd->vm_end = addr + shp->shm_npages * PAGE_SIZE;
 shmd->vm_mm = current->mm;
 shmd->vm_page_prot = (shmflg & SHM_RDONLY) ? PAGE_READONLY : PAGE_SHARED;
 shmd->vm_flags = VM_SHM | VM_MAYSHARE | VM_SHARED
    | VM_MAYREAD | VM_MAYEXEC | VM_READ | VM_EXEC
    | ((shmflg & SHM_RDONLY) ? 0 : VM_MAYWRITE | VM_WRITE);
 shmd->vm_file = NULL;
 shmd->vm_offset = 0;
 shmd->vm_ops = &shm_vm_ops;

 shp->u.shm_nattch++;     /* prevent destruction */
 spin_unlock(&shm_lock);
 err = shm_map(shmd);
 spin_lock(&shm_lock);
 if (err)
  goto failed_shm_map;

 insert_attach(shp,shmd);  /* insert shmd into shp->attaches */

 shp->u.shm_lpid = current->pid;
 shp->u.shm_atime = CURRENT_TIME;

 *raddr = addr;
 err = 0;
out:
 spin_unlock(&shm_lock);
 up(&current->mm->mmap_sem);
 return err;
 ...
}
```

上面的代码主要是设置刚创建的 `vm_area_struct` 结构的各个字段，比较重要的是设置其 `vm_ops` 字段为 `shm_vm_ops`，`shm_vm_ops` 定义如下：

```javascript
static struct vm_operations_struct shm_vm_ops = {
 shm_open,  /* open - callback for a new vm-area open */
 shm_close,  /* close - callback for when the vm-area is released */
 NULL,   /* no need to sync pages at unmap */
 NULL,   /* protect */
 NULL,   /* sync */
 NULL,   /* advise */
 shm_nopage,  /* nopage */
 NULL,   /* wppage */
 shm_swapout  /* swapout */
};
```

`shm_vm_ops` 的 `nopage` 回调为 `shm_nopage()` 函数，也就是说，当发生页缺失异常时将会调用此函数来恢复内存的映射。

从上面的代码可看出，`shmat()` 函数只是申请了进程的虚拟内存空间，而共享内存的物理空间并没有申请，那么在什么时候申请物理内存呢？答案就是当进程发生缺页异常的时候会调用 `shm_nopage()` 函数来恢复进程的虚拟内存地址到物理内存地址的映射。

##### shm_nopage() 函数实现

**shm_nopage() 函数是当发生内存缺页异常时被调用**的，代码如下：

```javascript
static struct page * shm_nopage(struct vm_area_struct * shmd, unsigned long address, int no_share)
{
 pte_t pte;
 struct shmid_kernel *shp;
 unsigned int idx;
 struct page * page;

 shp = *(struct shmid_kernel **) shmd->vm_private_data;
 idx = (address - shmd->vm_start + shmd->vm_offset) >> PAGE_SHIFT;

 spin_lock(&shm_lock);
again:
 pte = shp->shm_pages[idx]; // 共享内存的页表项
 if (!pte_present(pte)) {   // 如果内存页不存在
  if (pte_none(pte)) {
   spin_unlock(&shm_lock);
   page = get_free_highpage(GFP_HIGHUSER); // 申请一个新的物理内存页
   if (!page)
    goto oom;
   clear_highpage(page);
   spin_lock(&shm_lock);
   if (pte_val(pte) != pte_val(shp->shm_pages[idx]))
    goto changed;
  } else {
   ...
  }
  shm_rss++;
  pte = pte_mkdirty(mk_pte(page, PAGE_SHARED));   // 创建页表项
  shp->shm_pages[idx] = pte;                      // 保存共享内存的页表项
 } else
  --current->maj_flt;  /* was incremented in do_no_page */

done:
 get_page(pte_page(pte));
 spin_unlock(&shm_lock);
 current->min_flt++;
 return pte_page(pte);
 ...
}
```

shm_nopage() 函数的主要功能是当发生内存缺页时，申请新的物理内存页，并映射到共享内存中。由于使用共享内存时会映射到相同的物理内存页上，从而不同进程可以共用此块内存。

### 进程、线程间有哪些通信方式？

[参考](https://www.cnblogs.com/fanguangdexiaoyuer/p/10834737.html)

#### 通信方式之间的差异

因为那个根本原因，实际上只有进程间需要通信,同一进程的线程共享地址空间,没有通信的必要，但要做好同步/互斥,保护共享的全局变量。

而进程间通信无论是信号，管道pipe还是共享内存都是由操作系统保证的，是系统调用。

#### 进程通信

- **管道(pipe)** ：管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。
- **有名管道 (namedpipe)** ：有名管道也是半双工的通信方式，但是它允许无亲缘关系进程间的通信。
- **信号量(semaphore)**： **信号量是一个计数器**，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。
- **消息队列(messagequeue)**：消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。
- **信号 (sinal)**：信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。
- **共享内存(shared memory)**：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号量，配合使用，来实现进程间的同步和通信。
- **套接字(socket)**：套接口也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同设备及其间的进程通信。

#### 线程间的通信方式

- 锁机制：包括互斥锁、条件变量、读写锁

  - 互斥锁提供了以排他方式防止数据结构被并发修改的方法。 

  - 读写锁允许多个线程同时读共享数据，而对写操作是互斥的。 

  - 条件变量可以以原子的方式阻塞进程，直到某个特定条件为真为止。对条件的测试是在互斥锁的保护下进行的。条件变量始终与互斥锁一起使用。

    - wait/notify 等待

    - Volatile 内存共享

    - CountDownLatch 并发工具

    - CyclicBarrier 并发工具

- 信号量机制(Semaphore)：包括无名线程信号量和命名线程信号量。

- 信号机制(Signal)：类似进程间的信号处理。

线程间的通信目的主要是用于线程同步，所以线程没有像进程通信中的用于数据交换的通信机制。

### 操作系统中，虚拟地址与物理地址之间如何映射？

[参考](https://blog.51cto.com/u_15169172/2795114)

虚拟地址和物理地址的映射，不得不说一下在它俩之间其实还有一个线性地址的存在，那么进程想要访问真正的物理地址，首先要将虚拟地址转换为线性地址，然后经过MMU就可以将线性地址转换为真正的物理地址。

![一篇就让你了解进程的虚拟地址与物理地址是如何进行映射的_物联网](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/ad207dc3eca3aba9193a303cd62ebf49.png)

下面一步一步来进行讲解，先讲讲**虚拟地址和线性地址是如何进行转换的吧**：

转换过程中，就需要一个寄存器，那就是段寄存器，**段寄存器中存储的是描述符表的索引**，你可以把描述符表看成是一个数组，那么段寄存器中的索引，你可以当成是数组的下标，这下你明白了吧。

上面说的描述符表你可能有点懵，它是啥东西，那么，我来告诉你，描述符表里面存放的是描述符，而描述符中就存放了线性的地址的基地址，我讲到这里，大家终于看到了线性地址的身影，

描述符中既然存放了基地址，那么就可通过基地址加上虚拟地址这个偏移量来算出线性地址了。

![一篇就让你了解进程的虚拟地址与物理地址是如何进行映射的_物联网_02](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/16d177f0ceb2bdc7913a2cf7baeb9cbb.jpeg)

现在，我更想告诉大家一个结果，那就是虽然虚拟地址和线性地址是有转换关系的，但是在LINUX系统上，段描述符中的线性地址的基地址都是从0开始的，所以，会推算出，虚拟地址和线性地址是相等的，这回明白了吧，讲了半天虚拟地址和线性地址的转换，到头来原来虚拟地址和线性地址是相等的。

接下来，就讲讲线性地址是如何映射物理内存的，只需要一张图，就能看明白：

![一篇就让你了解进程的虚拟地址与物理地址是如何进行映射的_物联网_03](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/491101f0c5c2d3ea194d0be191b83920.jpeg)

依据以下步骤进行转换：

1. 从CR3寄存器中取出页目录的地址。

2. 根据线性地址中的前10位，找到页目录的索引。

3. 根据页目录项的值与中间10位相加后得到页表中的索引。

4. 将页的起始地址与最后的12位相加后得到最终的物理地址。

结论：

在Linux系统上，虚拟地址和线性地址是相等的。

**通过线性地址可以找到页目录中的页表，然后找到页表中的页表项，最终通过页表项和线性地址中的偏移，来找到最终的物理地址**。

### CPU L1, L2缓存是什么

[参考](https://zhuanlan.zhihu.com/p/31875174)、[参考](https://blog.csdn.net/u010632165/article/details/106795478)

现在的CPU中有好几个等级的缓存。通常L1和L2缓存都是每个CPU一个的, **L1缓存有分为L1i和L1d，分别用来存储指令和数据**。L2缓存是不区分指令和数据的。L3缓存多个核心共用一个，通常也不区分指令和数据。 还有一种缓存叫TLB，它主要用来缓存MMU使用的页表，通常我们讲缓存（cache)的时候是不算它的。

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/v2-0e77de9fe46e80c179204da1bf9ad6b2_r.jpg)

#### 缓存级别：`L1`，`L2`和`L3`

CPU缓存分为三个主要的**“级别”**，即`L1`，`L2`和`L3`。这里的层次结构是根据缓存速度来划分的。

- **L1（1级）高速缓存是计算机系统中存在的最快的内存**。就访问优先级而言，`L1`缓存具有CPU在完成特定任务时最可能需要的数据。

  就其大小而言，`L1`高速缓存通常最多可达`256KB`。但是，一些真正功能强大的CPU现在将其占用近`1MB`。现在，某些服务器芯片组（如`Intel`的高端`Xeon CPU`）具有`1-2MB`的一级缓存。

  `L1`缓存通常也分为两种方式，分为**指令缓存**和**数据缓存**。**指令高速缓存处理有关CPU必须执行的操作的信息，而数据高速缓存则保留要在其上执行操作的数据**。

![在这里插入图片描述](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/20200616210809475.png)

- **L2（2级）缓存比L1缓存慢，但大小更大**。它的大小通常在`256KB`到`8MB`之间，尽管更新，功能强大的CPU往往会超过此大小。**`L2`高速缓存保存下一步可能由CPU访问的数据**。在大多数现代CPU中，**`L1`和`L2`高速缓存位于CPU内核本身**，每个内核都有自己的高速缓存。
- **L3（3级）高速缓存是最大的高速缓存存储单元，也是最慢的一个**。它的范围从`4MB`到`50MB`以上。现代CPU在CPU裸片上具有用于`L3`高速缓存的专用空间，并且占用了很大一部分空间。

#### 缓存命中或未命中以及延迟

**数据会从RAM依次流到L3高速缓存，然后是L2，最后是L1**。

当处理器正在寻找要执行操作的数据时，它首先尝试在**L1高速缓存中**找到它。如果CPU能够找到它，则该情况称为**高速缓存命中**。然后，它继续在**L2和L3中找到它**。

如果**找不到数据**，它将尝试从主内存访问数据。这称为**高速缓存未命中**。

现在，众所周知，**高速缓存旨在加快主内存和CPU之间的数据传输**。

从内存访问数据所需的时间称为延迟，`L1`具有最低的延迟，是最快的，并且最接近核心，而`L3`具有最高的延迟。缓存未命中时，延迟会增加很多。这是因为CPU必须从主存储器中获取数据。

随着计算机变得越来越快和越来越好，我们看到延迟减少了。现在，我们拥有低延迟的`DDR4 RAM`，以及具有低访问时间的超高速`SSD`作为主要存储，这两项都大大降低了整体延迟。

以前，缓存设计曾经使`L2`和`L3`缓存位于CPU外部，这对**延迟产生了负面影响**。

然而，`CPU`制造工艺的进步使得在比以前更小的空间中安装数十亿个晶体管。因此，为缓存留出了更多空间，**这使缓存尽可能地靠近核心，从而大大减少了延迟**。

### 信号量是如何实现的？

[参考](http://c.biancheng.net/view/1232.html)

一个信号量 S 是个整型变量，它除了初始化外只能通过两个标准原子操作：wait () 和 signal() 来访问：

- 操作 wait() 最初称为 P（荷兰语proberen，测试）；
- 操作 signal() 最初称为 V（荷兰语verhogen，增加）；

#### 信号量的使用

操作系统通常**区分计数信号量与二进制信号量**。计数信号量的值不受限制，而二进制信号量的值只能为 0 或 1。因此，**二进制信号量类似于互斥锁**。事实上，在没有提供互斥锁的系统上，可以使用二进制信号量来提供互斥。

**计数信号量可以用于控制访问具有多个实例的某种资源**。信号量的初值为可用资源数量。当进程需要使用资源时，需要对该信号量执行 wait() 操作（减少信号量的计数)。当进程释放资源时，需要对该信号量执行 signal() 操作（增加信号量的计数）。当信号量的计数为 0 时，所有资源都在使用中。之后，需要使用资源的进程将会阻塞，直到计数大于 0。

我们也可以使用信号量来解决各种同步问题。例如，现有两个并发运行的进程：P1 有语句 S1 而 P2 有语句 S2。假设要求只有在 S1 执行后才能执行 S2。我们可以轻松实现这一要求：让 P1 和 P2 共享同一信号量 synch，并且初始化为 0。

在进程 P1 中，插入语句：

```
S1;
signal (synch);
```

在进程 P2 中，插入语句：

```
wait (synch);
S2;
```

因为 synch 初始化为 0，只有在 P1 调用 signal(synch) ，即 S1 语句执行之后，P2 才会执行 S2。

#### 信号量的实现

回想一下，互斥锁实现具有忙等待。刚才描述的信号量操作 wait() 和 signal()，也有同样问题。

为了克服忙等待需要，可以这样修改信号量操作 wait() 和 signal() 的定义：当一个进程执行操作 wait() 并且发现信号量值不为正时，它必须等待。然而，该进程不是忙等待而是阻塞自己。阻塞操作将一个进程放到与信号量相关的等待队列中，并且将该进程状态切换成等待状态。然后，控制转到 CPU 调度程序，以便选择执行另一个进程。

等待信号量 S 而阻塞的进程，在其他进程执行操作 signal() 后，应被重新执行。进程的重新执行是通过操作 wakeup() 来进行的，它将进程从等待状态改为就绪状态。然而，进程被添加到就绪队列。（取决于 CPU 调度算法，CPU 可能会也可能不会从正在运行的进程切换到新的就绪进程。）

为了实现这样定义的信号量，我们按如下定义信号量：

```
typedef struct {    int value;    struct process *list;} semaphore;
```

每个信号量都有一个整数 value 和一个进程链表 list。当一个进程必须等待信号量时，就被添加到进程链表。操作 signal() 从等待、进程链表上取走一个进程，并加以唤醒。

现在，信号量操作 wait() 可以定义如下：

```
wait(semaphore *S) {    S->value--;    if (S->value < 0) {        add this process to S->list;        block();    }}
```

而信号量操作 signal() 可定义如下：

```
signal(semaphore *S) {    S->value++;    if (S->value <= 0) {        remove a process P from S->list;        wakeup(P);    }}
```

操作 block() 挂起调用它的进程。操作 wakeup(P) 重新启动阻塞进程 P 的执行。这两个操作都是由操作系统作为基本系统调用来提供的。

注意，这样实现的信号量的值可以是负数，而在具有忙等待的信号量经典定义下，信号量的值不能为负。如果信号量的值为负，那么它的绝对值就是等待它的进程数。出现这种情况源于，在实现操作 wait() 时互换了递减和测试的顺序。

通过每个进程控制块 PCB 的一个链接字段，等待进程的链表可以轻松实现。每个信号量包括一个整数和一个 PCB 链表指针。向链表中增加和删除进程以便确保有限等待的一种方法采用 FIFO 队列，这里的信号量包括队列的首指针和尾指针。然而，一般来说，链表可以使用任何排队策略。信号量的正确使用不依赖于信号量链表的特定排队策略。

关键的是，信号量操作应原子执行。我们应保证：对同一信号量，没有两个进程可以同时执行操作 wait() 和 signal()。这是一个临界区问题。

对于单处理器环境，在执行操作 wait() 和 signal() 时，可以简单禁止中断。这种方案在单处理器环境下能工作，这是因为一旦中断被禁用，不同进程指令不会交织在一起。只有当前运行进程一直执行，直到中断 被重新启用并且调度程序重新获得控制。

对于多处理器环境，每个处理器的中断都应被禁止；否则，在不同处理器上不同的运行进程可能会以任意不同方式一起交织执行。每个处理器中断的禁止会很困难，也会严重影响性能。因此，SMP 系统应提供其他加锁技术，如 compare_and__swap() 或自旋锁，以确保 wait() 与 signal() 原子执行。

重要的是，对于这里定义的操作 wait() 和 signal()，我们并没有完全取消忙等待。我们只是将忙等待从进入区移到临界区。此外，我们将忙等待限制在操作 wait() 和 signal() 的临界区内，这些区比较短（如经合理编码，它们不会超过 10 条指令）。因此，临界区几乎不被占用，忙等待很少发生，而且所需时间很短。对于应用程序，存在一种完全不同的情况，即临界区可能很长（数分钟或数小时）或几乎总是被占用。在这种情况下，忙等待极为低效。

### [Linux常见的进程调度算法](https://www.cnblogs.com/alantu2018/p/8460451.html)

#### 先来先去服务（FCFS）：

优点：有利于长作业以及CPU繁忙的作业

缺点：不利于短作业以及I/O繁忙的作业

####  短作业(进程)优先调度算法SJ(P)F

优点：

- 比FCFS改善平均周转时间和平均带权周转时间，缩短作业的等待时间；
- 提高系统的吞吐量；

缺点：

- 对长作业非常不利，可能长时间得不到执行；
- 未能依据作业的紧迫程度来划分执行的优先级；
- 难以准确估计作业（进程）的执行时间，从而影响调度性能。

#### 最短剩余时间优先 shortest remaining time next（SRTN）

#### 轮转法

#### 多级反馈队列算法

### Linux 操作系统中为什么需要虚拟内存

[参考](https://draveness.me/whys-the-design-os-virtual-memory/)

- 虚拟内存可以结合磁盘和物理内存的优势为进程**提供看起来速度足够快并且容量足够大的存储**；
- 虚拟内存可以为进程**提供独立的内存空间并引入多层的页表结构**将虚拟内存翻译成物理内存，进程之间可以共享物理内存减少开销，也能**简化程序的链接、装载以及内存分配过程**；
- 虚拟内存可以**控制进程对物理内存的访问，隔离不同进程的访问权限，提高系统的安全性**；

### 零拷贝原理

[参考](https://juejin.cn/post/6995519558475841550)

零拷贝（Zero-Copy）是一种 `I/O` 操作优化技术，可以快速高效地将数据从文件系统移动到网络接口，而不需要将其从内核空间复制到用户空间。其在 `FTP` 或者 `HTTP` 等协议中可以显著地提升性能。但是需要注意的是，并不是所有的操作系统都支持这一特性，目前**只有在使用 `NIO` 和 `Epoll` 传输时才可使用该特性**。

需要注意，它不能用于实现了数据加密或者压缩的文件系统上，只有传输文件的原始内容。这类原始内容也包括加密了的文件内容。

传统 I/O 的工作方式是，数据读取和写入是从用户空间到内核空间来回复制，而内核空间的数据是通过操作系统层面的 I/O 接口从磁盘读取或写入。

代码通常如下，一般会**需要两个系统调用**：

```
read(file, tmp_buf, len);
write(socket, tmp_buf, len);
```

代码很简单，虽然就两行代码，但是这里面发生了不少的事情。

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/f6c3a1a5de3640aeb3b8a8771ff3a810%7Etplv-k3u1fbpfcp-zoom-in-crop-mark%3A3024%3A0%3A0%3A0.awebp)

首先，期间共**发生了 4 次用户态与内核态的上下文切换**，因为发生了两次系统调用，一次是 `read()` ，一次是 `write()`，每次系统调用都得先从用户态切换到内核态，等内核完成任务后，再从内核态切换回用户态。

上下文切换到成本并不小，一次切换需要耗时几十纳秒到几微秒，虽然时间看上去很短，但是在高并发的场景下，这类时间容易被累积和放大，从而影响系统的性能。

其次，还**发生了 4 次数据拷贝**，其中两次是 DMA 的拷贝，另外两次则是通过 CPU 拷贝的，下面说一下这个过程：

- `第一次拷贝`，把磁盘上的数据拷贝到操作系统内核的缓冲区里，这个拷贝的过程是通过 DMA 搬运的。
- `第二次拷贝`，把内核缓冲区的数据拷贝到用户的缓冲区里，于是我们应用程序就可以使用这部分数据了，这个拷贝到过程是由 CPU 完成的。
- `第三次拷贝`，把刚才拷贝到用户的缓冲区里的数据，再拷贝到内核的 socket 的缓冲区里，这个过程依然还是由 CPU 搬运的。
- `第四次拷贝`，把内核的 socket 缓冲区里的数据，拷贝到网卡的缓冲区里，这个过程又是由 DMA 搬运的。

这种简单又传统的文件传输方式，存在冗余的上文切换和数据拷贝，在高并发系统里是非常糟糕的，多了很多不必要的开销，会严重影响系统性能。

所以，**要想提高文件传输的性能，就需要减少「用户态与内核态的上下文切换」和「内存拷贝」的次数**。

#### 零拷贝技术原理

零拷贝主要是用来解决操作系统在处理 I/O 操作时，频繁复制数据的问题。关于零拷贝主要技术有 `mmap+write`、`sendfile`和`splice`等几种方式。

##### 虚拟内存

在了解零拷贝技术之前，先了解虚拟内存的概念。

所有现代操作系统都使用虚拟内存，使用虚拟地址取代物理地址，主要有以下几点好处：

- 多个虚拟内存可以指向同一个物理地址。
- 虚拟内存空间可以远远大于物理内存空间。

利用上述的第一条特性可以优化，可以把内核空间和用户空间的虚拟地址映射到同一个物理地址，这样在 I/O 操作时就不需要来回复制了。

如下图展示了虚拟内存的原理。

![image-20210812181924274](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f93635b183ef49828843c0f50518449a~tplv-k3u1fbpfcp-zoom-in-crop-mark:3024:0:0:0.awebp)

##### mmap/write 方式

使用`mmap/write`方式替换原来的传统I/O方式，就是利用了虚拟内存的特性。下图展示了`mmap/write`原理：

![image-20210812201839908](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d3747aca11884a1a85708c0163c79a99~tplv-k3u1fbpfcp-zoom-in-crop-mark:3024:0:0:0.awebp)

整个流程的核心区别就是，把数据读取到内核缓冲区后，应用程序进行写入操作时，**直接把内核的`Read Buffer`的数据复制到`Socket Buffer`以便写入**，这次内核之间的复制也是需要CPU的参与的。

上述流程就是**少了一个 CPU COPY，**提升了 I/O 的速度。不过发现上下文的切换还是4次并没有减少，这是因为还是要应用程序发起`write`操作。

> 那能不能减少上下文切换呢?这就需要`sendfile`方式来进一步优化了。

##### sendfile 方式

从 Linux 2.1 版本开始，Linux 引入了 `sendfile`来简化操作。`sendfile`方式可以替换上面的`mmap/write`方式来进一步优化。

`sendfile`将以下操作：

```java
  mmap();
  write();
替换为：
 sendfile();
```

这样就减少了上下文切换，因为少了一个应用程序发起`write`操作，直接发起`sendfile`操作。

下图展示了`sendfile`原理：

![image-20210812201905046](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/d221a3a90a754ca9842f6324455638ea~tplv-k3u1fbpfcp-zoom-in-crop-mark:3024:0:0:0.awebp)

`sendfile`方式只有三次数据复制（其中只有一次 CPU COPY）以及2次上下文切换。

> 那能不能把 CPU COPY 减少到没有呢？这样需要带有 `scatter/gather`的`sendfile`方式了。

##### 带有 scatter/gather 的 sendfile方式

Linux 2.4 内核进行了优化，提供了带有 `scatter/gather` 的 sendfile 操作，这个操作可以把最后一次 `CPU COPY` 去除。其原理就是**在内核空间 Read BUffer 和 Socket Buffer 不做数据复制，而是将 Read Buffer 的内存地址、偏移量记录到相应的 Socket Buffer 中，这样就不需要复制**。其本质和虚拟内存的解决方法思路一致，就是内存地址的记录。

下图展示了scatter/gather 的 sendfile 的原理：

![image-20210812201922193](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/133430c1aedc4e22a6e340efc29e4239~tplv-k3u1fbpfcp-zoom-in-crop-mark:3024:0:0:0.awebp)

scatter/gather 的 sendfile **只有两次数据复制（都是 DMA COPY）及 2 次上下文切换**。CUP COPY 已经完全没有。不过这一种收集复制功能是需要硬件及驱动程序支持的。

##### splice 方式

`splice` 调用和`sendfile` 非常相似，用户应用程序必须拥**有两个已经打开的文件描述符，一个表示输入设备，一个表示输出设备**。与`sendfile`不同的是，**`splice`允许任意两个文件互相连接，而并不只是文件与`socket`进行数据传输**。对于从一个文件描述符发送数据到`socket`这种特例来说，一直都是使用`sendfile`系统调用，而`splice`一直以来就只是一种机制，它并不仅限于`sendfile`的功能。也就是说 sendfile 是 splice 的一个子集。

在 Linux 2.6.17 版本引入了 splice，而在 Linux 2.6.23 版本中， sendfile 机制的实现已经没有了，但是其 API 及相应的功能还在，只不过 API 及相应的功能是利用了 splice 机制来实现的。

和 sendfile 不同的是，splice 不需要硬件支持。

#### 总结

无论是传统的 I/O 方式，还是引入了零拷贝之后，2 次 `DMA copy`是都少不了的。因为两次 DMA 都是依赖硬件完成的。所以，所谓的零拷贝，都是为了减少 CPU copy 及减少了上下文的切换。

下图展示了各种零拷贝技术的对比图：

|                     | CPU拷贝 | DMA拷贝 | 系统调用   | 上下文切换 |
| ------------------- | ------- | ------- | ---------- | ---------- |
| 传统方法            | 2       | 2       | read/write | 4          |
| 内存映射            | 1       | 2       | mmap/write | 4          |
| sendfile            | 1       | 2       | sendfile   | 2          |
| scatter/gather copy | 0       | 2       | sendfile   | 2          |
| splice              | 0       | 2       | splice     | 0          |

### [Linux 的 IO模型有哪些](https://zhuanlan.zhihu.com/p/127170201)

#### 一、基本概念

五种IO模型包括：**阻塞IO、非阻塞IO、IO多路复用、信号驱动IO、异步IO**。

首先需要了解下系统调用的几个函数和基本概念。

**1.1 简单介绍几个系统调用函数**

由于我对于C语言不熟悉，几个系统函数参考了一些文章，如果错误欢迎指出！

**recvfrom**

Linux系统提供给用户**用于接收网络IO的系统接口**。**从套接字上接收一个消息**，可同时应用于面向连接和无连接的套接字。

如果此系统调用返回值<0，并且 errno为EWOULDBLOCK或EAGAIN（套接字已标记为非阻塞，而接收操作被阻塞或者接收超时 ）时，连接正常，**阻塞**接收数据（这很关键，前4种IO模型都设计此系统调用）。

**select**

select系统调用**允许程序同时在多个底层文件描述符上，等待输入的到达或输出的完成**。以**数组**形式存储文件描述符，64位机器默认**2048**个。当有数据准备好时，无法感知具体是哪个流OK了，所以需要一个一个的遍历，函数的时间复杂度为**O(n)**。

**poll**

以**链表**形式存储文件描述符，没有长度限制。本质与select相同，函数的时间复杂度也为**O(n)**。

**epoll**

是基于事件驱动的，如果某个流准备好了，会以事件通知，知道具体是哪个流，因此不需要遍历，函数的时间复杂度为**O(1)**。

**sigaction**

用于设置对信号的处理方式，也可检验对某信号的预设处理方式。Linux使用**SIGIO信号**来实现IO异步通知机制。

**1.2 同步&异步**

同步和异步是针对应用程序和内核交互而言的，也可理解为被**被调用者（操作系统）**的角度来说。

同步是用户进程触发IO操作并等待或轮询的去查看是否就绪，而异步是指用户进程触发IO操作以后便开始做自己的事情，而当IO操作

已经完成的时候会得到IO完成的通知，需要CPU支持

**1.3 阻塞&非阻塞**

阻塞和非阻塞是针对于进程在访问数据的时候，也可理解为**调用者（程序）**角度来说。根据IO操作的就绪状态来采取的不同的方式。
阻塞方式下读取或写入方法将一直等待，而非阻塞方式下读取或写入方法会立即返回一个状态值。

下午撸代码饿了，好久没吃KFC了，决定去**整个全家桶** ，这一切都要从一个全家桶说起~

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/v2-323459f378bc493434f1f2b683f13951_b.jpg)

我跑去肯德基买全家桶，但是很不巧，轮到我时，全家桶**卖完了**，我只能等着新做一份 ...

#### 二、阻塞IO模型

学习过操作系统的知识后，可以知道：不管是网络IO还是磁盘IO，对于读操作而言，都是等到网络的某个数据分组到达后/数据**准备好**后，将数据**拷贝到内核空间的缓冲区中**，再从内核空间**拷贝到用户空间的缓冲区**。
有关操作系统的知识可以参考我之前写的操作系统相关文章~

拓展阅读：https://www.cnblogs.com/sunsky303/p/8962628.html

此时我已饥渴难耐，全程**盯着**后厨，等待着一分一秒（别多想 ），终于全家桶做好了，在此期间虽然什么事也没干，但是最后能吃到全家桶，我很幸福。

此处需要一个清新的脑回路，我就是程序，我想要全家桶，于是**发起了系统调用**，而后厨加工的过程就是在做**数据准备和拷贝**工作。全家桶最终到手，数据终于从内核空间拷贝到了用户空间。

简单看下**执行流程**：

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/v2-dd90b4423d0220a45f66c2880308f464_r.jpg)

接下来发挥看图说话的专长了：阻塞IO的执行过程是进程进行**系统调用**，**等待内核**将数据准备好并复制到用户态缓冲区后，进程**放弃使用CPU**并**一直阻塞**在此，直到数据准备好。

#### 三、**非阻塞IO模型**

此时我**每隔5分钟**询问全家桶好了没，在数次盘问后，终于出炉了。在每一次盘问之前，对于程序来说是**非阻塞的**，**占用CPU资源**，可以做其他事情。

每次应用程序**询问内核**是否有数据准备好。如果就绪，就进行**拷贝**操作；如果未就绪，就**不阻塞程序**，内核直接返回未就绪的返回值，等待用户程序下一个轮询。

![img](https://pic1.zhimg.com/v2-28c4499246deda788090a027672bb5c4_r.jpg)

大致经历两个阶段：

- **等待数据阶段**：未阻塞， 用户进程需要盲等，不停的去轮询内核。
- **数据复制阶段**：阻塞，此时进行数据复制。

在这两个阶段中，用户进程只有在数据复制阶段被阻塞了，而等待数据阶段没有阻塞，但是用户进程需要盲等，不停地轮询内核，看数据是否准备好。

#### 四、IO多路复用模型

排了很长的队，终于轮到我支付后，拿到了一张小票，上面有**号次**。当全家桶出炉后，会喊相应的号次来取。KFC营业员小姐姐打小票出号次的动作相当于操作系统**多开了个线程**，专门接收客户端的连接。我只关注叫到的是不是我的号，因此程序还需在服务端**注册我想监听的事件**类型。

多路复用一般都是用于网络IO，服务端与多个客户端的建立连接。下面是神奇的多路复用执行过程：

![img](https://pic4.zhimg.com/v2-22c97570f76d0e6974647bb328c6d17f_r.jpg)

相比于阻塞IO模型，多路复用只是多了一个**select/poll/epoll函数**。select函数会不断地轮询自己所负责的文件描述符/套接字的到达状态，当某个套接字就绪时，就对这个套接字进行处理。select负责**轮询等待**，recvfrom负责**拷贝**。当用户进程调用该select，select会监听所有注册好的IO，如果所有IO都没注册好，调用进程就阻塞。

对于客户端来说，一般**感受不到阻塞**，因为请求来了，可以用放到线程池里执行；但对于执行select的操作系统而言，是阻塞的，需要阻塞地**等待某个套接字变为可读**。

IO多路复用其实是阻塞在select，poll，epoll这类系统调用上的，复用的是执行select，poll，epoll的线程。

#### 五、信号驱动IO模型

跑KFC嫌麻烦，刚好有个会员，直接点份外卖，美滋滋。当外卖送达时，会收到取餐电话（信号）。在收到取餐电话之前，我可以愉快地吃鸡或者学习。

当数据报准备好的时候，内核会向应用程序**发送一个信号**，进程对信号进行**捕捉**，并且调用信号处理函数来获取数据报。

![img](https://pic1.zhimg.com/v2-40dfcff92e8be06b5a6be914c84d8650_r.jpg)

该模型也分为两个阶段：

- **数据准备阶段**：未阻塞，当数据准备完成之后，会主动的通知用户进程数据已经准备完成，对用户进程做一个回调。
- **数据拷贝阶段**：阻塞用户进程，等待数据拷贝。

信号驱动 IO（Signal Driven IO）：可以为 Socket 开启信号驱动 IO 功能，**应用进程需向内核注册一个信号处理程序**，该操作并立即返回。当内核中有数据准备好，会发送一个信号给应用进程，应用进程便可以在信号处理程序中发起 IO 系统调用，来完成数据读取了。

#### 六、异步IO模型

此时科技的发展已经超乎想象了，外卖机器人将全家桶自动送达并**转换成营养**快速注入我的体内，同时还能得到口感的满足。注入结束后，机器人会提醒我注入完毕。在这个期间我可以放心大胆的玩，甚至注射的时候也**不需要停下来**！

类比一下，就是用户进程发起系统调用后，立刻就可以开始去做其他的事情，然后直到I/O**数据准备好并复制完成后**，内核会给用户进程**发送通知**，告诉用户进程操作**已经完成**了。

![img](https://pic4.zhimg.com/v2-1c9e7ded90780eb753352c8d92d41ad7_r.jpg)

特点：

1. 异步I/O执行的两个阶段**都不会阻塞读写操作，**由内核完成。
2. 完成后内核将数据放到指定的缓冲区，**通知**应用程序来取。

#### 总结

从效率上来说，可以简单理解为阻塞IO<非阻塞IO<多路复用IO<信号驱动IO<异步IO。从同步和异步来说，**只有异步IO模型是异步的**，其他均为同步。

从上述五种 IO 模型可以看出，应用进程对内核发起 IO 系统调用后，内核会经过两个阶段来完成数据的传输：

- 第一阶段：等待数据。即应用进程发起 IO 系统调用后，会一直等待数据；当有数据传入服务器，会将数据放入内核空间，此时数据准备好。
- 第二阶段：将数据从内核空间复制到用户空间，并返回给应用程序成功标识。

![五种 IO 模型对比](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/1460000039898790)

前四种模型的第二阶段是相同的，都是处于阻塞状态，其主要区别在第一阶段。而异步 IO 模型则不同，应用进程在这两个阶段是完全不阻塞的。

| IO 模型      | 第一阶段       | 第二阶段 |
| ------------ | -------------- | -------- |
| 阻塞式IO     | 阻塞           | 阻塞     |
| 非阻塞式IO   | 非阻塞         | 阻塞     |
| IO多路程复用 | 阻塞（Select） | 阻塞     |
| 信号驱动式IO | 异步           | 阻塞     |
| 异步IO       | 异步           | 异步     |

### 面试官：你说说互斥锁、自旋锁、读写锁、悲观锁、乐观锁的应用场景

#### 互斥锁与自旋锁：谁更轻松自如？

**最底层的两种就是会「互斥锁和自旋锁」**，有很多高级的锁都是基于它们实现的，你可以认为它们是各种锁的地基，所以我们必须清楚它俩之间的区别和应用。

加锁的目的就是保证共享资源在任意时间里，只有一个线程访问，这样就可以避免多线程导致共享数据错乱的问题。

当已经有一个线程加锁后，其他线程加锁则就会失败，互斥锁和自旋锁对于加锁失败后的处理方式是不一样的：

- **互斥锁**加锁失败后，线程会**释放 CPU** ，给其他线程；
- **自旋锁**加锁失败后，线程会**忙等待**，直到它拿到锁；

##### **互斥锁**

互斥锁是一种「独占锁」，比如当线程 A 加锁成功后，此时互斥锁已经被线程 A 独占了，只要线程 A 没有释放手中的锁，线程 B 加锁就会失败，于是就会释放 CPU 让给其他线程，**既然线程 B 释放掉了 CPU，自然线程 B 加锁的代码就会被阻塞**。

**对于互斥锁加锁失败而阻塞的现象，是由操作系统内核实现的**。当加锁失败时，内核会将线程置为「睡眠」状态，等到锁被释放后，内核会在合适的时机唤醒线程，当这个线程成功获取到锁后，于是就可以继续执行。如下图：

<img src="https://raw.githubusercontent.com/Simin-hub/Picture/master/img/351ba3b20bc51f7b1a629843ed19b696.png" alt="img" style="zoom: 50%;" />

所以，**互斥锁加锁失败时，会从用户态陷入到内核态，让内核帮我们切换线程**，虽然简化了使用锁的难度，但是存在一定的性能开销成本。

那这个开销成本是什么呢？会有**两次线程上下文切换的成本**：

- 当线程加锁失败时，内核会把线程的状态从「运行」状态设置为「睡眠」状态，然后把 CPU 切换给其他线程运行；
- 接着，当锁被释放时，之前「睡眠」状态的线程会变为「就绪」状态，然后内核会在合适的时间，把 CPU 切换给该线程运行。

线程的上下文切换的是什么？当两个线程是属于同一个进程，**因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据。**

上下切换的耗时有大佬统计过，大概在几十纳秒到几微秒之间，如果你锁住的代码执行时间比较短，那可能上下文切换的时间都比你锁住的代码执行时间还要长。

所以，**如果你能确定被锁住的代码执行时间很短，就不应该用互斥锁，而应该选用自旋锁，否则使用互斥锁。**

##### 自旋锁

**自旋锁是通过 CPU 提供的 `CAS` 函数（*Compare And Swap*）**，**在「用户态」完成加锁和解锁操作，不会主动产生线程上下文切换**，所以相比互斥锁来说，会快一些，开销也小一些。

一般加锁的过程，包含两个步骤：

- 第一步，查看锁的状态，如果锁是空闲的，则执行第二步；
- 第二步，将锁设置为当前线程持有；

**CAS 函数就把这两个步骤合并成一条硬件级指令**，形成**原子指令**，这样就保证了这两个步骤是不可分割的，要么一次性执行完两个步骤，要么两个步骤都不执行。

使用自旋锁的时候，当发生多线程竞争锁的情况，加锁失败的线程会「忙等待」，直到它拿到锁。这里的「忙等待」可以用 `while` 循环等待实现，不过最好是**使用 CPU 提供的 `PAUSE` 指令来实现「忙等待」**，因为可以减少循环等待时的耗电量。

**忙等待**：一种进程执行状态。进程执行到一段循环程序的时候，由于循环判断条件不能满足而导致处理器反复循环，处于繁忙状态，该进程虽然繁忙但无法前进

自旋锁是最比较简单的一种锁，一直自旋，利用 CPU 周期，直到锁可用。**需要注意，在单核 CPU 上，需要抢占式的调度器（即不断通过时钟中断一个线程，运行其他线程）。否则，自旋锁在单 CPU 上无法使用，因为一个自旋的线程永远不会放弃 CPU。**

自旋锁开销少，在多核系统下一般不会主动产生线程切换，适合异步、协程等在用户态切换请求的编程方式，但如果被锁住的代码执行时间过长，自旋的线程会长时间占用 CPU 资源，所以自旋的时间和被锁住的代码执行的时间是成「正比」的关系，我们需要清楚的知道这一点。

自旋锁与互斥锁使用层面比较相似，但实现层面上完全不同：**当加锁失败时，互斥锁用「线程切换」来应对，自旋锁则用「忙等待」来应对**。

它俩是锁的最基本处理方式，更高级的锁都会选择其中一个来实现，比如读写锁既可以选择互斥锁实现，也可以基于自旋锁实现。

#### 读写锁：读和写还有优先级区分？

读写锁从字面意思我们也可以知道，它由「读锁」和「写锁」两部分构成，如果只读取共享资源用「读锁」加锁，如果要修改共享资源则用「写锁」加锁。

所以，**读写锁适用于能明确区分读操作和写操作的场景**。

读写锁的工作原理是：

- 当「写锁」没有被线程持有时，多个线程能够并发地持有读锁，这大大提高了共享资源的访问效率，因为「读锁」是用于读取共享资源的场景，所以多个线程同时持有读锁也不会破坏共享资源的数据。
- 但是，一旦「写锁」被线程持有后，读线程的获取读锁的操作会被阻塞，而且其他写线程的获取写锁的操作也会被阻塞。

所以说，写锁是独占锁，因为任何时刻只能有一个线程持有写锁，类似互斥锁和自旋锁，而读锁是共享锁，因为读锁可以被多个线程同时持有。

知道了读写锁的工作原理后，我们可以发现，**读写锁在读多写少的场景，能发挥出优势**。

另外，根据实现的不同，读写锁可以分为「读优先锁」和「写优先锁」。

**读优先锁**期望的是，读锁能被更多的线程持有，以便提高读线程的并发性，它的工作方式是：**当读线程 A 先持有了读锁，写线程 B 在获取写锁的时候，会被阻塞，并且在阻塞过程中，后续来的读线程 C 仍然可以成功获取读锁，最后直到读线程 A 和 C 释放读锁后，写线程 B 才可以成功获取写锁**。如下图：

<img src="https://raw.githubusercontent.com/Simin-hub/Picture/master/img/1197159b4c813abcc38ea40ff2a02ec8.png" alt="img" style="zoom:50%;" />

而**写优先锁**是优先服务写线程，其工作方式是：**当读线程 A 先持有了读锁，写线程 B 在获取写锁的时候，会被阻塞，并且在阻塞过程中，后续来的读线程 C 获取读锁时会失败，于是读线程 C 将被阻塞在获取读锁的操作，这样只要读线程 A 释放读锁后，写线程 B 就可以成功获取读锁**。如下图：

<img src="https://raw.githubusercontent.com/Simin-hub/Picture/master/img/e0b0a896ff304a57399df708020947e3.png" alt="img" style="zoom:50%;" />

读优先锁对于读线程并发性更好，但也不是没有问题。我们试想一下，如果一直有读线程获取读锁，那么写线程将永远获取不到写锁，这就造成了写线程「饥饿」的现象。

写优先锁可以保证写线程不会饿死，但是如果一直有写线程获取写锁，读线程也会被「饿死」。

既然不管优先读锁还是写锁，对方可能会出现饿死问题，那么我们就不偏袒任何一方，搞个「公平读写锁」。

**公平读写锁比较简单的一种方式是：用队列把获取锁的线程排队，不管是写线程还是读线程都按照先进先出的原则加锁即可，这样读线程仍然可以并发，也不会出现「饥饿」的现象。**

互斥锁和自旋锁都是最基本的锁，读写锁可以根据场景来选择这两种锁其中的一个进行实现。

------

#### 乐观锁与悲观锁：做事的心态有何不同？

前面提到的互斥锁、自旋锁、读写锁，都是属于悲观锁。

悲观锁做事比较悲观，它认为**多线程同时修改共享资源的概率比较高，于是很容易出现冲突，所以访问共享资源前，先要上锁**。

那相反的，如果多线程同时修改共享资源的概率比较低，就可以采用乐观锁。

乐观锁做事比较乐观，它假定冲突的概率很低，它的工作方式是：**先修改完共享资源，再验证这段时间内有没有发生冲突，如果没有其他线程在修改资源，那么操作完成，如果发现有其他线程已经修改过这个资源，就放弃本次操作**。

放弃后如何重试，这跟业务场景息息相关，虽然重试的成本很高，但是冲突的概率足够低的话，还是可以接受的。

可见，乐观锁的心态是，不管三七二十一，先改了资源再说。另外，你会发现**乐观锁全程并没有加锁，所以它也叫无锁编程**。

这里举一个场景例子：在线文档。

我们都知道在线文档可以同时多人编辑的，如果使用了悲观锁，那么只要有一个用户正在编辑文档，此时其他用户就无法打开相同的文档了，这用户体验当然不好了。

那实现多人同时编辑，实际上是用了乐观锁，它允许多个用户打开同一个文档进行编辑，编辑完提交之后才验证修改的内容是否有冲突。

怎么样才算发生冲突？这里举个例子，比如用户 A 先在浏览器编辑文档，之后用户 B 在浏览器也打开了相同的文档进行编辑，但是用户 B 比用户 A 提交改动，这一过程用户 A 是不知道的，当 A 提交修改完的内容时，那么 A 和 B 之间并行修改的地方就会发生冲突。

服务端要怎么验证是否冲突了呢？通常方案如下：

- 由于发生冲突的概率比较低，所以先让用户编辑文档，但是浏览器在下载文档时会记录下服务端返回的文档版本号；
- 当用户提交修改时，发给服务端的请求会带上原始文档版本号，服务器收到后将它与当前版本号进行比较，如果版本号一致则修改成功，否则提交失败。

实际上，我们常见的 SVN 和 Git 也是用了乐观锁的思想，先让用户编辑代码，然后提交的时候，通过版本号来判断是否产生了冲突，发生了冲突的地方，需要我们自己修改后，再重新提交。

乐观锁虽然去除了加锁解锁的操作，但是一旦发生冲突，重试的成本非常高，所以**只有在冲突概率非常低，且加锁成本非常高的场景时，才考虑使用乐观锁。**

------

#### 总结

开发过程中，最常见的就是互斥锁的了，互斥锁加锁失败时，会用「线程切换」来应对，当加锁失败的线程再次加锁成功后的这一过程，会有两次线程上下文切换的成本，性能损耗比较大。

如果我们明确知道被锁住的代码的执行时间很短，那我们应该选择开销比较小的自旋锁，因为自旋锁加锁失败时，并不会主动产生线程切换，而是一直忙等待，直到获取到锁，那么如果被锁住的代码执行时间很短，那这个忙等待的时间相对应也很短。

如果能区分读操作和写操作的场景，那读写锁就更合适了，它允许多个读线程可以同时持有读锁，提高了读的并发性。根据偏袒读方还是写方，可以分为读优先锁和写优先锁，读优先锁并发性很强，但是写线程会被饿死，而写优先锁会优先服务写线程，读线程也可能会被饿死，那为了避免饥饿的问题，于是就有了公平读写锁，它是用队列把请求锁的线程排队，并保证先入先出的原则来对线程加锁，这样便保证了某种线程不会被饿死，通用性也更好点。

互斥锁和自旋锁都是最基本的锁，读写锁可以根据场景来选择这两种锁其中的一个进行实现。

另外，互斥锁、自旋锁、读写锁都属于悲观锁，悲观锁认为并发访问共享资源时，冲突概率可能非常高，所以在访问共享资源前，都需要先加锁。

相反的，如果并发访问共享资源时，冲突概率非常低的话，就可以使用乐观锁，它的工作方式是，在访问共享资源时，不用先加锁，修改完共享资源后，再验证这段时间内有没有发生冲突，如果没有其他线程在修改资源，那么操作完成，如果发现有其他线程已经修改过这个资源，就放弃本次操作。

但是，一旦冲突概率上升，就不适合使用乐观锁了，因为它解决冲突的重试成本非常高。

不管使用的哪种锁，我们的加锁的代码范围应该尽可能的小，也就是加锁的粒度要小，这样执行速度会比较快。再来，使用上了合适的锁，就会快上加快了。

### 多进程和多线程的区别

[参考](https://blog.csdn.net/linraise/article/details/12979473)

| 维度           | 多进程                                                       | 多线程                                 | 总结     |
| -------------- | ------------------------------------------------------------ | -------------------------------------- | -------- |
| 数据共享、同步 | 数据是分开的:共享复杂，需要用IPC;同步简单                    | 多线程共享进程数据：共享简单；同步复杂 | 各有优势 |
| 内存、CPU      | 占用内存多，切换复杂，CPU利用率低                            | 占用内存少，切换简单，CPU利用率高      | 线程占优 |
| 创建销毁、切换 | 创建销毁、切换复杂，速度慢                                   | 创建销毁、切换简单，速度快             | 线程占优 |
| 编程调试       | 编程简单，调试简单                                           | 编程复杂，调试复杂                     | 进程占优 |
| 可靠性         | 进程间不会相互影响                                           | 一个线程挂掉将导致整个进程挂掉         | 进程占优 |
| 分布式         | 适应于多核、多机分布 ；如果一台机器不够，扩展到多台机器比较简单 | 适应于多核分布                         | 进程占优 |

| 子进程继承父进程的属性：                                     | 子线程继承主线程的属性：                                     |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| 实际用户ID，实际组ID，有效用户ID，有效组ID；附加组ID；进程组ID；会话ID；控制终端；设置用户ID标志和设置组ID标志；当前工作目录；根目录；文件模式创建屏蔽字（umask）；信号屏蔽和安排；针对任一打开文件描述符的在执行时关闭（close-on-exec）标志；环境；连接的共享存储段；存储映射；资源限制； | 进程中的所有信息对该进程的所有线程都是共享的；可执行的程序文本；程序的全局内存；堆内存；栈；文件描述符；信号的处理是进程中所有线程共享的（注意：如果信号的默认处理是终止该进程那么即是把信号传给某个线程也一样会将进程杀掉）； |
| 父子进程之间的区别：                                         | 子线程特有的：                                               |
| fork的返回值(=0子进程)；进程ID不同；两个进程具有不同的父进程ID；子进程的tms_utime,tms_stime,tms_cutime以及tms_ustime均被设置为0；不继承父进程设置的文件锁；子进程的未处理闹钟被清除；子进程的未处理信号集设置为空集； | 线程ID；一组寄存器值；栈；调度优先级和策略；信号屏蔽字；errno变量；线程私有数据； |

![img](https://img-blog.csdnimg.cn/2018122721302863)

1)需要频繁创建销毁的优先用线程。

实例：web服务器。来一个建立一个线程，断了就销毁线程。要是用进程，创建和销毁的代价是很难承受的。

2）需要进行大量计算的优先使用线程。
所谓大量计算，当然就是要消耗很多cpu，切换频繁了，这种情况先线程是最合适的。
实例：图像处理、算法处理

3）强相关的处理用线程，若相关的处理用进程。

什么叫强相关、弱相关？理论上很难定义，给个简单的例子就明白了。

一般的server需要完成如下任务：消息收发和消息处理。消息收发和消息处理就是弱相关的任务，而消息处理里面可能又分为消息解码、业务处理，这两个任务相对来说相关性就要强多了。因此消息收发和消息处理可以分进程设计，消息解码和业务处理可以分线程设计。

4）可能扩展到多机分布的用进程，多核分布的用线程。

5）都满足需求的情况下，用你最熟悉、最拿手的方式。

### 简述几个常用的 Linux 命令以及他们的功能

cat 用于在标准输出（监控器或屏幕）上查看文件内容

ls 会列举出当前工作目录的内容（文件或文件夹）。

mkdir 用于新建一个新目录

cd 切换文件路径，cd 将给定的文件夹（或目录）设置成当前工作目录。

rmdir 删除给定的目录。

rm 会删除给定的文件

cp 命令对文件进行复制

mv 命令对文件或文件夹进行移动，如果文件或文件夹存在于当前工作目录，还可以对文件或文件夹进行重命名。

tail 默认在标准输出上显示给定文件的最后10行内容，可以使用tail -n N 指定在标准输出上显示文件的最后N行内容。

less 按页或按窗口打印文件内容。在查看包含大量文本数据的大文件时是非常有用和高效的。你可以使用Ctrl+F向前翻页，Ctrl+B向后翻页。

grep 在给定的文件中搜寻指定的字符串。grep -i “” 在搜寻时会忽略字符串的大小写，而grep -r “” 则会在当前工作目录的文件中递归搜寻指定的字符串。

这个命令会在给定位置搜寻与条件匹配的文件。你可以使用find -name 的-name选项来进行区分大小写的搜寻，find -iname 来进行不区分大小写的搜寻。

tar命令能创建、查看和提取tar压缩文件。tar -cvf 是创建对应压缩文件，tar -tvf 来查看对应压缩文件，tar -xvf 来提取对应压缩文件。

gzip 命令创建和提取gzip压缩文件，还可以用gzip -d 来提取压缩文件。

unzip 对gzip文档进行解压。在解压之前，可以使用unzip -l 命令查看文件内容。

help会在终端列出所有可用的命令,可以使用任何命令的-h或-help选项来查看该命令的具体用法。图就省略啦，会有详细列表显示出来的。

whatis 会用单行来描述给定的命令，就是解释当前命令。

exit用于结束当前的终端会话。

ping 通过发送数据包ping远程主机(服务器)，常用与检测网络连接和服务器状态。

who能列出当前登录的用户名。

su 用于切换不同的用户。即使没有使用密码，超级用户也能切换到其它用户。

uname会显示出关于系统的重要信息，如内核名称、主机名、内核版本、处理机类型等等，使用uname -a可以查看所有信息。

df 查看文件系统中磁盘的使用情况–硬盘已用和可用的存储空间以及其它存储设备。你可以使用df -h将结果以人类可读的方式显示。

ps显示系统的运行进程。

top 命令会默认按照CPU的占用情况，显示占用量较大的进程,可以使用top -u 查看某个用户的CPU使用排名情况。

shutdown用于关闭计算机，而shutdown -r用于重启计算机。

### 进程空间从高位到低位都有些什么？

1、命令行参数和环境变量

2、栈

3、堆

4、未初始化的数据 (BSS段)

5、已初始化的数据

6、代码段

### 什么是缓冲区溢出？有什么危害？原因是什么？

[参考](https://blog.csdn.net/qq_35642036/article/details/82809845)

**冲区溢出是指当计算机向缓冲区填充数据时超出了缓冲区本身的容量，溢出的数据覆盖在合法数据上**。

​    危害有以下两点：

​    1、程序崩溃，导致拒绝服务

​    2、跳转并且执行一段恶意代码

​    **原因：造成缓冲区溢出的主要原因是程序中没有仔细检查用户输入**。

​    所谓缓冲区可以更抽象地理解为一段可读写的内存区域，**缓冲区攻击的最终目的就是希望系统能执行这块可读写内存中已经被蓄意设定好的恶意代码**。按照冯·诺依曼存储程序原理，程序代码是作为二进制数据存储在内存的，同样程序的数据也在内存中，因此直接从内存的二进制形式上是无法区分哪些是数据哪些是代码的，这也为缓冲区溢出攻击提供了可能。

​    当然，随便往[缓冲区](https://baike.baidu.com/item/缓冲区)中填东西造成它溢出一般只会出现**分段错误（Segmentation fault）**，而不能达到攻击的目的。最常见的手段是**通过制造缓冲区溢出使程序运行一个用户shell，再通过shell执行其它命令**。如果该程序属于root且有suid权限的话，攻击者就获得了一个有[root权限](https://baike.baidu.com/item/root权限)的shell，可以对系统进行任意操作了。

 

![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/20180922090258602) ![img](https://raw.githubusercontent.com/Simin-hub/Picture/master/img/20180922090259407)

​    由于栈是低地址方向增长的，因此局部数组buffer的指针在缓冲区的下方。当把data的数据拷贝到buffer内时，超过缓冲区区域的高地址部分数据会“淹没”原本的其他栈帧数据，根据淹没数据的内容不同，可能会有产生以下情况：

​    1、淹没了其他的局部变量。如果被淹没的局部变量是条件变量，那么可能会改变函数原本的执行流程。这种方式可以用于\**破解简单的软件验证\**。

​    2、淹没了ebp的值。修改了函数执行结束后要恢复的栈指针，将会导致栈帧失去平衡。

​    3、淹没了返回地址。这是栈溢出原理的核心所在，通过淹没的方式修改函数的返回地址，使程序代码执行“意外”的流程！

​    4、淹没参数变量。修改函数的参数变量也可能改变当前函数的执行结果和流程。

​    5、淹没上级函数的栈帧，情况与上述4点类似，只不过影响的是上级函数的执行。当然这里的前提是保证函数能正常返回，即函数地址不能被随意修改（这可能很麻烦！）。

​    如果在data本身的数据内就保存了一系列的指令的二进制代码，一旦栈溢出修改了函数的返回地址，并将该地址指向这段二进制代码的其他位置，那么就完成了基本的溢出攻击行为。

 

​    上述过程虽然理论上能完成栈溢出攻击行为，但是实际上很难实现。操作系统每次加载可执行文件到进程空间的位置都是无法预测的，因此栈的位置实际是不固定的，通过硬编码覆盖新返回地址的方式并不可靠。为了能准确定位shellcode的地址，需要借助一些额外的操作，其中最经典的是借助跳板的栈溢出方式。

​    根据前边所述，函数执行后，栈指针esp会恢复到压入参数时的状态，在图4中即data参数的地址。如果我们在函数的返回地址填入一个地址，该地址指向的内存保存了一条特殊的指令jmp esp——跳板。那么函数返回后，会执行该指令并跳转到esp所在的位置——即data的位置。我们可以将缓冲区再多溢出一部分，淹没data这样的函数参数，并在这里放上我们想要执行的代码！这样，不管程序被加载到哪个位置，最终都会回来执行栈内的代码。

 

<img src="https://img-blog.csdn.net/20180922090259597?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM1NjQyMDM2/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="img" style="zoom:50%;" />

### mmap 原理

[参考](mmap 原理)

#### 一、传统的读写文件

一般来说，修改一个文件的内容需要如下3个步骤：

- 把文件内容读入到内存中。
- 修改内存中的内容。
- 把内存的数据写入到文件中。

过程如图 1 所示：

![read-write.png](https://p6-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/5b5d56c88f4b49ddba0ed1b014928a49~tplv-k3u1fbpfcp-zoom-in-crop-mark:3024:0:0:0.awebp)

如果使用代码来实现上面的过程，代码如下：

```c
read(fd, buf, 1024);  // 读取文件的内容到buf
...                   // 修改buf的内容
write(fd, buf, 1024); // 把buf的内容写入到文件
```

从图 1 中可以看出，`页缓存(page cache)` 是读写文件时的中间层，内核使用 `页缓存` 与文件的数据块关联起来。所以应用程序读写文件时，实际操作的是 `页缓存`。

#### 二、使用 mmap 读写文件

从传统读写文件的过程中，我们可以发现有个地方可以优化：如果可以**直接在用户空间读写 `页缓存`**，那么就可以免去将 `页缓存` 的数据复制到**用户空间缓冲区**的过程。

那么，有没有这样的技术能实现上面所说的方式呢？答案是肯定的，就是 `mmap`。

使用 `mmap` 系统调用可以**将用户空间的虚拟内存地址与文件进行映射（绑定）**，对映射后的虚拟内存地址进行读写操作就如同对文件进行读写操作一样。原理如图 2 所示：

<img src="https://p9-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/35a55af52d3042c79613feb41fc662d3~tplv-k3u1fbpfcp-zoom-in-crop-mark:3024:0:0:0.awebp" alt="mmap.png" style="zoom: 67%;" />

前面我们介绍过，读写文件都需要经过 `页缓存`，所以 `mmap` 映射的正是文件的 `页缓存`，而非磁盘中的文件本身。由于 `mmap` 映射的是文件的 `页缓存`，所以就涉及到同步的问题，即 `页缓存` 会在什么时候把数据同步到磁盘。

Linux 内核并不会主动把 `mmap` 映射的 `页缓存` 同步到磁盘，而是需要用户主动触发。同步 `mmap` 映射的内存到磁盘有 4 个时机：

- 调用 `msync` 函数主动进行数据同步（主动）。
- 调用 `munmap` 函数对文件进行解除映射关系时（主动）。
- 进程退出时（被动）。
- 系统关机时（被动）。

##### 三、mmap的使用方式

下面我们介绍一下怎么使用 `mmap`，`mmap` 函数的原型如下：

```c
void *mmap(void *addr, size_t length, int prot, int flags, int fd, off_t offset);
```

下面介绍一下 `mmap` 函数的各个参数作用：

- `addr`：指定映射的虚拟内存地址，可以设置为 NULL，让 Linux 内核自动选择合适的虚拟内存地址。

- `length`：映射的长度。

- `prot`：映射内存的保护模式，可选值如下：

  - `PROT_EXEC`：可以被执行。

  1. `PROT_READ`：可以被读取。
  2. `PROT_WRITE`：可以被写入。
  3. `PROT_NONE`：不可访问。

- `flags`：指定映射的类型，常用的可选值如下：

  - `MAP_FIXED`：使用指定的起始虚拟内存地址进行映射。

  1. `MAP_SHARED`：与其它所有映射到这个文件的进程共享映射空间（可实现共享内存）。
  2. `MAP_PRIVATE`：建立一个写时复制（Copy on Write）的私有映射空间。
  3. `MAP_LOCKED`：锁定映射区的页面，从而防止页面被交换出内存。
  4. ...

- `fd`：进行映射的文件句柄。

- `offset`：文件偏移量（从文件的何处开始映射）。

介绍完 `mmap` 函数的原型后，我们现在通过一个简单的例子介绍怎么使用 `mmap`：

```c
int fd = open(filepath, O_RDWR, 0644);                           // 打开文件
void *addr = mmap(NULL, 8192, PROT_WRITE, MAP_SHARED, fd, 4096); // 对文件进行映射
```

在上面例子中，我们先通过 `open` 函数以可读写的方式打开文件，然后通过 `mmap` 函数对文件进行映射，映射的方式如下：

- `addr` 参数设置为 NULL，表示让操作系统自动选择合适的虚拟内存地址进行映射。
- `length` 参数设置为 8192 表示映射的区域为 2 个内存页的大小（一个内存页的大小为 4 KB）。
- `prot` 参数设置为 `PROT_WRITE` 表示映射的内存区为可读写。
- `flags` 参数设置为 `MAP_SHARED` 表示共享映射区。
- `fd` 参数设置打开的文件句柄。
- `offset` 参数设置为 4096 表示从文件的 4096 处开始映射。

`mmap` 函数会返回映射后的内存地址，我们可以通过此内存地址对文件进行读写操作。我们通过图 3 展示上面例子在内核中的结构：

<img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b59dc54fc6fc42a294e3cf1defc1a3b9~tplv-k3u1fbpfcp-zoom-in-crop-mark:3024:0:0:0.awebp" alt="mmap-address.png" style="zoom:67%;" />

##### 四、总结

本文主要介绍了 `mmap` 的原理和使用方式，通过本文我们可以知道，使用 `mmap` 对文件进行读写操作时可以减少内存拷贝的次数，并且可以减少系统调用的次数，从而提高对读写文件操作的效率。

由于内核不会主动同步 `mmap` 所映射的内存区中的数据，所以在某些特殊的场景下可能会出现数据丢失的情况（如断电）。为了避免数据丢失，在使用 `mmap` 的时候可以在适当时主动调用 `msync` 函数来同步映射内存区的数据。

### 简述操作系统中的缺页中断

[参考](https://www.nowcoder.com/questionTerminal/e5671c51ef704d5291a3af70ffc5c255?orderByHotValue=1&page=12&onlyReference=false)

1、 首先说明什么是缺页。内存管理时我们采用的是虚拟内存，虚拟内存并不能与实际内存建立完全的映射关系。**缺页就是虚拟内存无法与实际内存建立映射的一种情况**。我们通过页表的状态位判断是否产生缺页。缺页发生时，我们就需要将虚拟内存对应的外存中的那一页调入内存。而整个的实现过程是通过中断进行的。 

  2、 这里的缺页中断的流程与普通中断没有区别。**就是当系统发现缺页，从而产生中断。需要保存当前的状态，然后进入缺页中断处理程序，之后再恢复原来的状态，继续运行程序**。 

  3、 具体的缺页中断处理也要分为两类：**第一类是此时内存中还有空闲块，我们直接将缺页从外存中调入内存**；**第二类是内存已满，需要采用页面置换算法淘汰某页再进行调入**。

### 线程从进程继承了哪些资源？线程独享哪些资源？

[参考](https://blog.csdn.net/weixin_41983309/article/details/109029494)

#### 线程共享的资源包括：

（1） 进程代码段

（2） 进程的公有数据（利用这些数据，线程很容易实现相互之间的通讯）

（3） 进程的所拥有资源。

#### 线程独立的资源包括：

（1）**线程ID**：每个线程都有自己唯一的ID，用于区分不同的线程。

（2）**寄存器组的值**：当线程切换时，必须将原有的线程的寄存器集合的状态保存，以便重新切换时得以恢复。

（3）**线程的堆栈**：堆栈是保证线程独立运行所必须的。

（4）**错误返回码**：由于同一个进程中有很多个线程同时运行，可能某个线程进行系统调用后设置了error值，而在该线程还没有处理这个错误，另外一个线程就在此时被调度器投入运行，这样错误值就有可能被修改。所以，不同的线程应该拥有自己的错误返回码变量。

（5）**线程优先级**：线程调度的次序（并不是优先级大的一定会先执行，优先级大只是最先执行的机会大）。

### Linux 页大小是多少？

[参考](https://draveness.me/whys-the-design-linux-default-page/)

Linux 同时支持正常大小的内存页和大内存页（Huge Page）[1](https://draveness.me/whys-the-design-linux-default-page/#fn:1)，绝大多数处理器上的**内存页的默认大小都是 4KB**，虽然部分处理器会使用 8KB、16KB 或者 64KB 作为默认的页面大小，但是 4KB 的页面仍然是操作系统默认内存页配置的主流；除了正常的内存页大小之外，不同的处理器上也包含不同大小的大页面，我们在 x86 处理器上就可以使用 2MB 的内存页。

以下两个影响内存页大小的因素，它们分别是：

- 过小的页面大小会带来**较大的页表项增加寻址时 TLB**（Translation lookaside buffer）的查找时间和额外开销；
- 过大的页面大小会**浪费内存空间，造成内存碎片**，降低内存的利用率；

### select / poll / epoll 详解

[参考](https://imageslr.com/2020/02/27/select-poll-epoll.html)

进程可以通过 select、poll、epoll 发起 I/O 多路复用的系统调用，这些系统调用都是同步阻塞的：**如果传入的多个文件描述符中，有描述符就绪，则返回就绪的描述符；否则如果所有文件描述符都未就绪，就阻塞调用进程，直到某个描述符就绪，或者阻塞时长超过设置的 timeout 后，再返回**。I/O 多路复用内部使用*非阻塞 I/O* 检查每个描述符的就绪状态。

#### 什么是文件描述符 fd

文件描述符（file descriptor）是一个非负整数，从 0 开始。进程使用文件描述符来标识一个打开的文件。

系统为每一个进程维护了一个文件描述符表，表示该进程打开文件的记录表，而**文件描述符实际上就是这张表的索引**。当进程打开（`open`）或者新建（`create`）文件时，内核会在该进程的文件列表中新增一个表项，同时返回一个文件描述符 —— 也就是新增表项的下标。

一般来说，每个进程最多可以打开 64 个文件，`fd ∈ 0~63`。在不同系统上，最多允许打开的文件个数不同，Linux 2.4.22 强制规定最多不能超过 1,048,576。

每个进程默认都有 3 个文件描述符：0 (stdin)、1 (stdout)、2 (stderr)。

[这篇文章](https://github.com/labuladong/fucking-algorithm/blob/master/技术/linux进程.md)以图示的方式对文件描述符作了深入地讲解，可以进一步阅读。

#### select

缺点

1. 性能开销大
   1. 调用 `select` 时会陷入内核，这时需要将参数中的 `fd_set` 从用户空间拷贝到内核空间
   2. 内核需要遍历传递进来的所有 `fd_set` 的每一位，不管它们是否就绪
2. 同时能够监听的文件描述符数量太少。受限于 `sizeof(fd_set)` 的大小，在编译内核时就确定了且无法更改。一般是 1024，不同的操作系统不相同

#### 水平触发、边缘触发

`select` 只支持水平触发，`epoll` 支持水平触发和边缘触发。

水平触发（LT，Level Trigger）：当文件描述符就绪时，会触发通知，如果用户程序没有一次性把数据读/写完，下次还会发出可读/可写信号进行通知。

边缘触发（ET，Edge Trigger）：仅当描述符从未就绪变为就绪时，通知一次，之后不会再通知。

区别：边缘触发效率更高，**减少了事件被重复触发的次数**，函数不会返回大量用户程序可能不需要的文件描述符。

> 水平触发、边缘触发的名称来源：数字电路当中的电位水平，高低电平切换瞬间的触发动作叫边缘触发，而处于高电平的触发动作叫做水平触发。

#### 为什么边缘触发必须使用非阻塞 I/O？

关于这个问题的解答，强烈建议阅读[这篇文章](https://eklitzke.org/blocking-io-nonblocking-io-and-epoll)。下面是一些关键摘要：

- 每次通过 `read` 系统调用读取数据时，最多只能读取缓冲区大小的字节数；如果某个文件描述符一次性收到的数据超过了缓冲区的大小，那么需要对其 `read` 多次才能全部读取完毕

- `select` 可以使用阻塞 I/O

  。通过select获取到所有可读的文件描述符后，遍历每个文件描述符，read 一次数据（见上文select 示例）

  - 这些文件描述符都是可读的，因此即使 `read` 是阻塞 I/O，也一定可以读到数据，不会一直阻塞下去
  - `select` 采用水平触发模式，因此如果第一次 `read` 没有读取完全部数据，那么下次调用 `select` 时依然会返回这个文件描述符，可以再次 `read`
  - **`select` 也可以使用非阻塞 I/O**。当遍历某个可读文件描述符时，使用 `for` 循环调用 `read` **多次**，直到读取完所有数据为止（返回 `EWOULDBLOCK`）。这样做会多一次 `read` 调用，但可以减少调用 `select` 的次数

- 在epoll

  的边缘触发模式下，只会在文件描述符的可读/可写状态发生切换时，才会收到操作系统的通知

  - 因此，如果使用 `epoll` 的**边缘触发模式**，在收到通知时，**必须使用非阻塞 I/O，并且必须循环调用 `read` 或 `write` 多次，直到返回 `EWOULDBLOCK` 为止**，然后再调用 `epoll_wait` 等待操作系统的下一次通知
  - 如果没有一次性读/写完所有数据，那么在操作系统看来这个文件描述符的状态没有发生改变，将不会再发起通知，调用 `epoll_wait` 会使得该文件描述符一直等待下去，服务端也会一直等待客户端的响应，业务流程无法走完
  - 这样做的好处是每次调用 `epoll_wait` 都是**有效**的——保证数据全部读写完毕了，等待下次通知。在水平触发模式下，如果调用 `epoll_wait` 时数据没有读/写完毕，会直接返回，再次通知。因此边缘触发能显著减少事件被触发的次数
  - 为什么 `epoll` 的**边缘触发模式不能使用阻塞 I/O**？很显然，边缘触发模式需要循环读/写一个文件描述符的所有数据。如果使用阻塞 I/O，那么一定会在最后一次调用（没有数据可读/写）时阻塞，导致无法正常结束

#### 三者对比

- `select`：调用开销大（需要复制集合）；集合大小有限制；需要遍历整个集合找到就绪的描述符
- `poll`：poll 采用数组的方式存储文件描述符，没有最大存储数量的限制，其他方面和 select 没有区别
- `epoll`：调用开销小（不需要复制）；集合大小无限制；采用回调机制，不需要遍历整个集合

`select`、`poll` 都是在用户态维护文件描述符集合，因此每次需要将完整集合传给内核；`epoll` 由操作系统在内核中维护文件描述符集合，因此只需要在创建的时候传入文件描述符。

此外 `select` 只支持水平触发，`epoll` 支持边缘触发。

#### 适用场景

当连接数较多并且有很多的不活跃连接时，epoll 的效率比其它两者高很多。当连接数较少并且都十分活跃的情况下，由于 epoll 需要很多回调，因此性能可能低于其它两者。
